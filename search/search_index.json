{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hey there, I'm Codey Nham Chan Vi, your 1-on-1 Dev(Sec)Ops Coach.","text":"<p>So, you're looking to learn more about me. Well, I'm a Senior Dev(Sec)Ops Engineer at Tekos Interactive, and honestly, I love what I do. Basically, I'm all about making sure your systems are not only running smoothly but also super secure. I've been tinkering with IT for over 16 years, and the last 4+ years have been full of Pure DevSecOps magic!</p>"},{"location":"#what-gets-me-excited","title":"What Gets Me Excited?","text":"<p>Honestly, I get a kick out of building stuff that just works. You know, those systems are always up and secure and just make life easier. Here\u2019s what I\u2019m good at:</p> <ul> <li>Automating almost everything: Because who has time for manual work? But need to decide what to automate and what not to automate.</li> <li>Making deployments a breeze: CI/CD pipelines? That's my jam.</li> <li>Security from the get-go: I weave security into every step; GitOps helps me most.</li> <li>Containers and Kubernetes: Think of me as a container whisperer.</li> <li>Configuration Management: I love monolith.</li> </ul>"},{"location":"#my-tech-toolbox","title":"My Tech Toolbox","text":"<ul> <li>Cloud Stuff: I speak the AWS language now and am learning to speak Azure and GCP.</li> <li>Containers: Docker and Kubernetes are my best friends.</li> <li>Infrastructure as Code: Terraform and Terraspace keep things organized.</li> <li>Immutable Deployment: GitOps by ArgoCD keeps my brain free.</li> <li>CI/CD: GitHub Actions and ArgoCD make life easy.</li> <li>Security Tools: SAST and DAST? Check!</li> <li>Keeping an Eye On Things: The ELK stack helps me stay on top of everything.</li> <li>Automation: Python, Bash, Ansible, and Packer are my trusty sidekicks.</li> <li>Compliance: I make sure we play by the rules.</li> </ul>"},{"location":"#some-projects-im-proud-of","title":"Some Projects I'm Proud Of","text":""},{"location":"#project-1-fully-automated-dental-saas-platform-with-iac-cm-cicd-gitops-eks-on-aws","title":"Project 1: Fully automated Dental SaaS Platform with IaC, CM, CI/CD, GitOps, EKS on AWS.","text":"<ul> <li>I built up all environments with Terraform/OpenTofu and Terraspace.</li> <li>I built a super slick CI/CD pipeline for microservices using GitHub Actions and ArgoCD.</li> <li>I threw in some security tools to keep things safe.</li> </ul>"},{"location":"#project-2-fully-automated-single-instance-deployment-with-iac-terraspaceopentofu-configuration-management-ansible-packer-cicd-github-actions-with-backup-and-monitoring-solution-on-aws","title":"Project 2: Fully automated single instance deployment with IaC (Terraspace/OpenTofu), Configuration Management (Ansible, Packer), CI/CD (Github Actions) with backup and monitoring solution on AWS","text":"<ul> <li>I built up the entire Dev(Sec)Ops workflow to deliver production.</li> <li>I built a smooth CI/CD pipeline for monoliths using Github Actions.</li> </ul>"},{"location":"#project-3-standardize-terraform-ansible-project-code-with-templating-tools","title":"Project 3: Standardize Terraform, Ansible, Project code with templating tools.","text":"<ul> <li>I set up the Copier to template all the Deployment workflows.</li> <li>Making standard for all the setup to reduce human errors.</li> <li>I deployed new infrastructure faster than 3x times.</li> </ul>"},{"location":"#project-4-essential-cyber-hygiene-program-cis-controls-ig1","title":"Project 4: Essential Cyber Hygiene Program (CIS Controls - IG1).","text":"<ul> <li>I set up the whole Security Roadmap and implemented 56 controls.</li> <li>Conduct the Security Awareness program for all staff.</li> </ul>"},{"location":"#my-gold-stars-certifications","title":"My \"Gold Stars\" (Certifications)","text":"<ul> <li>Certified Kubernetes Administrator</li> <li>AWS Certified Cloud Practitioner</li> <li>VMWare vSphere and vCenter 6.0</li> <li>SQL Server 2008, MS Sharepoint 2010</li> <li>CCNA, CCNP</li> <li>MCSA, MCSA, SCCM, SCOM</li> </ul>"},{"location":"#lets-connect","title":"Let's Connect!","text":"<p>If you are a System Admin (Windows or Linux), Network Engineer, Security Engineer, DBA, or even IT Helpdesk and want to get started as a Junior Dev(Sec)Ops Engineer, hit me up on . Let's make some magic happen!</p>"},{"location":"lhtl/","title":"Lhtl","text":""},{"location":"lhtl/#viec-hoc-la-gi","title":"Vi\u1ec7c H\u1ecdc L\u00e0 G\u00ec?","text":"T\u1ed5ng h\u1ee3p \u00fd ch\u00ednh <p>Ch\u1ebf \u0111\u1ed9 T\u1eadp Trung, ch\u1ebf \u0111\u1ed9 Lan To\u1ea3, S\u1ef1 Ch\u1ea7n Ch\u1edd, Pomodoro, Tr\u00ed Nh\u1edb Ng\u1eafn H\u1ea1n, Tr\u00ed Nh\u1edb D\u00e0i H\u1ea1n, Nh\u1eafc L\u1ea1i Ng\u1eaft Qu\u00e3ng, Gi\u1ea5c Ng\u1ee7</p> C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <ul> <li>Hai ch\u1ebf \u0111\u1ed9 t\u01b0 duy - T\u1eadp Trung v\u00e0 Lan To\u1ea3</li> <li>Ch\u1ebf \u0111\u1ed9 T\u1eadp Trung l\u00e0 khi t\u1eadp trung to\u00e0n b\u1ed9 t\u00e2m tr\u00ed, s\u1ef1 ch\u00fa \u00fd v\u00e0o m\u1ed9t vi\u1ec7c n\u00e0o \u0111\u00f3 nh\u1eb1m c\u1ed1 g\u1eafng hi\u1ec3u ho\u1eb7c l\u00e0m.</li> <li>Ch\u1ebf \u0111\u1ed9 Lan To\u1ea3 l\u00e0 ch\u1ebf \u0111\u1ed9 tho\u1ea3i m\u00e1i, khi c\u01a1 th\u1ec3 v\u00e0 t\u00e2m tr\u00ed kh\u00f4ng c\u00f2n t\u1eadp trung v\u00e0 \u0111\u1ec3 n\u00e3o b\u1ed9 gi\u1ea3i quy\u1ebft ho\u1eb7c t\u1ea1o k\u1ebft n\u1ed1i c\u00e1c m\u1eabu ki\u1ebfn th\u1ee9c v\u1edbi nhau m\u1ed9t c\u00e1ch ng\u1eabu nhi\u00ean</li> <li>S\u1ef1 ch\u1ea7n ch\u1edd l\u00e0 khi b\u1ea1n mu\u1ed1n l\u00e0m vi\u1ec7c g\u00ec kh\u00f3 ho\u1eb7c g\u1eb7p m\u1ed9t k\u00edch th\u00edch n\u00e0o \u0111\u00f3 (tin nh\u1eafn, email, \u00e2m thanh,..) th\u00ec n\u00e3o c\u1ee7a b\u1ea1n s\u1ebd chuy\u1ec3n h\u01b0\u1edbng h\u00e0nh \u0111\u1ed9ng c\u1ee7a b\u1ea1n sang l\u00e0m m\u1ed9t vi\u1ec7c d\u1ec5 ch\u1ecbu h\u01a1n (facebook, tiktok, ch\u01a1i game,...)</li> <li>S\u1eed d\u1ee5ng Pomodoro \u0111\u1ec3 \u1ee9ng d\u1ee5ng ch\u1ebf \u0111\u1ed9 T\u1eadp Trung (25 ph\u00fat) xem k\u1ebd ch\u1ebf \u0111\u1ed9 Lan To\u1ea3 (5 ph\u00fat) \u0111\u1ec3 t\u0103ng kh\u1ea3 n\u0103ng nh\u1edb v\u00e0 hi\u1ec3u, kh\u1eafc ph\u1ee5c s\u1ef1 ch\u1ea7n ch\u1edd c\u0169ng nh\u01b0 th\u01b0 gi\u00e3n t\u00e2m tr\u00ed.</li> <li>Tr\u00ed Nh\u1edb Ng\u1eafn H\u1ea1n nh\u01b0 m\u1ed9t b\u1ea3n \u0111en ch\u1ea5t l\u01b0\u1ee3ng k\u00e9m, ki\u1ebfn th\u01b0c m\u1edbi \u0111\u01b0\u1ee3c ghi l\u00ean b\u1ea3n m\u1edd nh\u1ea1t d\u1ec5 phai v\u00e0 bi\u1ebfn m\u1ea5t.</li> <li>Tr\u00ed Nh\u1edb D\u00e0i H\u1ea1n nh\u01b0 m\u1ed9t nh\u00e0 kho kh\u00f4ng l\u1ed3, ki\u1ebfn th\u1ef1c \u0111\u01b0\u1ee3c l\u01b0u trong nh\u1eefng g\u00f3i h\u00e0ng tr\u1ea3i r\u1ed9ng kh\u1eafp nh\u00e0 kho, vi\u1ec7c truy xu\u1ea5t g\u00f3i h\u00e0ng c\u1ea7n r\u1ea5t nhi\u1ec1u th\u1eddi gian.</li> <li>S\u1ef1 d\u1ee5ng Nh\u1eafc L\u1ea1i C\u00e1ch Qu\u00e3ng \u0111\u1ec3 chuy\u1ec3n ki\u1ebfn th\u1ee9c t\u1eeb Tr\u00ed Nh\u1edb Ng\u1eafn H\u1ea1n v\u00e0 Tr\u00ed Nh\u1edb D\u00e0i H\u1ea1n b\u1eb1ng c\u00e1ch T\u1eadp Trung h\u1ecdc 1 l\u1ea7n, nh\u1eafc l\u1ea1i 1 ng\u00e0y sau, nh\u1eafc l\u1ea1i 1 tu\u1ea7n sau, nh\u0103c l\u1ea1i \u2153/6 th\u00e1ng sau.</li> <li>Gi\u1ea5c ng\u1ee7 gi\u00fap \u0111\u00e0o th\u1ea3i \u0111\u1ed9c t\u1ed1 khi ch\u00fang ta th\u1ee9c, gi\u00fap c\u00e1c t\u1ebf b\u00e0o n\u00e3o k\u1ebft n\u1ed1i d\u1ec5 d\u00e0ng h\u01a1n, ngo\u00e0i ra, khi ng\u1ee7 ch\u00fang ta s\u1ebd r\u01a1i v\u00e0o ch\u1ebf \u0111\u1ed9 Lan To\u1ea3 s\u1ebd gi\u00fap c\u1ee7ng c\u1ed1 ki\u1ebfn th\u1ee9c v\u00e0 hi\u1ec3u v\u1ea5n \u0111\u1ec1 c\u0169ng nh\u01b0 vi\u1ec7c t\u00ecm ra gi\u1ea3i ph\u00e1p cho c\u00e1c v\u1ea5n \u0111\u1ec1 kh\u00f3 m\u1ed9t c\u00e1ch ng\u1eabu nhi\u00ean.</li> </ul> Ch\u1ebf \u0111\u1ed9 T\u1eadp Trung l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>L\u00e0 khi b\u1ea1n t\u1eadp trung ch\u0103m ch\u00fa v\u00e0o m\u1ed9t vi\u1ec7c n\u00e0o \u0111\u00f3 m\u00e0 b\u1ea1n \u0111ang c\u1ed1 g\u1eafng \u0111\u1ec3 hi\u1ec3u ho\u1eb7c t\u1eadp trung l\u00e0m m\u1ed9t vi\u1ec7c n\u00e0o \u0111\u00f3 quen thu\u1ed9c.</p> <p>V\u00ed d\u1ee5</p> <p>Tia laser t\u1eadp trung n\u0103ng l\u01b0\u1ee3ng v\u00e0o m\u1ed9t \u0111i\u1ec3m duy nh\u1ea5t, \u0111\u1ed1t ch\u00e1y m\u1ecdi v\u1eadt c\u1ea3n. Ch\u1ebf \u0111\u1ed9 t\u1eadp trung c\u0169ng v\u1eady, gi\u00fap b\u1ea1n \"\u0111\u00e1nh b\u1ea1i\" m\u1ecdi v\u1ea5n \u0111\u1ec1 b\u1eb1ng s\u1ef1 t\u1eadp trung cao \u0111\u1ed9.</p> <p>V\u00ed d\u1ee5</p> <p>Nh\u00e0 leo n\u00fai t\u1eadp trung v\u00e0o t\u1eebng b\u01b0\u1edbc ch\u00e2n, v\u01b0\u1ee3t qua m\u1ecdi ch\u01b0\u1edbng ng\u1ea1i \u0111\u1ec3 \u0111\u1ea1t \u0111\u1ebfn \u0111\u1ec9nh cao. Ch\u1ebf \u0111\u1ed9 t\u1eadp trung gi\u00fap b\u1ea1n ki\u00ean tr\u00ec gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1, t\u1eebng b\u01b0\u1edbc \u0111\u1ea1t \u0111\u01b0\u1ee3c m\u1ee5c ti\u00eau.</p> <p>V\u00ed d\u1ee5</p> <p>Ng\u01b0\u1eddi l\u00ednh b\u1eafn t\u1ec9a c\u1ea7n s\u1ef1 t\u1eadp trung tuy\u1ec7t \u0111\u1ed1i \u0111\u1ec3 b\u1eafn tr\u00fang m\u1ee5c ti\u00eau. Ch\u1ebf \u0111\u1ed9 t\u1eadp trung c\u0169ng v\u1eady, gi\u00fap b\u1ea1n \"b\u1eafn tr\u00fang\" v\u1ea5n \u0111\u1ec1 m\u1ed9t c\u00e1ch ch\u00ednh x\u00e1c.</p> <p>V\u00ed d\u1ee5</p> <p>V\u1eadn \u0111\u1ed9ng vi\u00ean ch\u1ea1y n\u01b0\u1edbc r\u00fat c\u1ea7n d\u1ed3n h\u1ebft s\u1ee9c l\u1ef1c \u0111\u1ec3 v\u1ec1 \u0111\u00edch trong th\u1eddi gian ng\u1eafn nh\u1ea5t. Ch\u1ebf \u0111\u1ed9 t\u1eadp trung gi\u00fap b\u1ea1n ho\u00e0n th\u00e0nh cu\u1ed9c vi\u1ec7c m\u1ed9t c\u00e1ch nhanh ch\u00f3ng v\u00e0 hi\u1ec7u qu\u1ea3.</p> <p>V\u00ed d\u1ee5</p> <p>Th\u00e1m t\u1eed  t\u1eadp trung v\u00e0o t\u1eebng manh m\u1ed1i, l\u1ea7n theo d\u1ea5u v\u1ebft \u0111\u1ec3 t\u00ecm ra hung th\u1ee7. Ch\u1ebf \u0111\u1ed9 t\u1eadp trung gi\u00fap b\u1ea1n \"ph\u00e1 \u00e1n\" nh\u1eefng v\u1ea5n \u0111\u1ec1 h\u00f3c b\u00faa b\u1eb1ng c\u00e1ch ph\u00e2n t\u00edch v\u00e0 suy lu\u1eadn logic.</p> Ch\u1ebf \u0111\u1ed9 Lan To\u1ea3 l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>L\u00e0 ki\u1ec3u suy ngh\u0129 tho\u1ea3i m\u00e1i h\u01a1n nhi\u1ec1u so v\u1edbi Ch\u1ebf \u0110\u1ed9 T\u1eadp Trung, trong ch\u1ebf \u0111\u1ed9 Lan To\u1ea3 c\u00e1c th\u00f4ng tin r\u1eddi r\u1ea1c \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i ng\u1eabu nhi\u00ean v\u1edbi nhau t\u1ea1o n\u00ean nh\u1eefng \u00fd t\u01b0\u1edfng s\u00e1ng t\u1ea1o kh\u00f4ng ng\u1edd t\u1edbi.</p> <p>V\u00ed d\u1ee5</p> <p>Nh\u01b0 \"con ong\" \u0111i t\u00ecm m\u1eadt, ong bay l\u01b0\u1ee3n t\u1eeb b\u00f4ng hoa n\u00e0y sang b\u00f4ng hoa kh\u00e1c, thu th\u1eadp m\u1eadt ng\u1ecdt. Ch\u1ebf \u0111\u1ed9 lan to\u1ea3 c\u0169ng v\u1eady, gi\u00fap b\u1ea1n \"thu th\u1eadp\" nh\u1eefng \u00fd t\u01b0\u1edfng m\u1edbi m\u1ebb t\u1eeb nhi\u1ec1u ngu\u1ed3n kh\u00e1c nhau.</p> <p>V\u00ed d\u1ee5</p> <p>Nh\u01b0 \"ng\u01b0\u1eddi ngh\u1ec7 s\u0129\" s\u00e1ng t\u00e1c, kh\u00f4ng ng\u1eebng t\u00ecm ki\u1ebfm c\u1ea3m h\u1ee9ng cu\u1ed9c s\u1ed1ng xung quanh \u0111\u1ec3 s\u00e1ng t\u00e1c ra nh\u1eefng t\u00e1c ph\u1ea9m ngh\u1ec7 thu\u1eadt \u0111\u1ed9c \u0111\u00e1o. Ch\u1ebf \u0111\u1ed9 lan to\u1ea3 gi\u00fap b\u1ea1n \"ch\u1eaft l\u1ecdc\" nh\u1eefng \u00fd t\u01b0\u1edfng s\u00e1ng t\u1ea1o t\u1eeb nh\u1eefng tr\u1ea3i nghi\u1ec7m c\u1ee7a b\u1ea3n th\u00e2n.</p> <p>V\u00ed d\u1ee5</p> <p>Nh\u01b0 \"nh\u00e0 khoa h\u1ecdc\" kh\u00e1m ph\u00e1, kh\u00f4ng ng\u1eebng t\u00ecm t\u00f2i, kh\u00e1m ph\u00e1 nh\u1eefng \u0111i\u1ec1u b\u00ed \u1ea9n c\u1ee7a th\u1ebf gi\u1edbi. Ch\u1ebf \u0111\u1ed9 lan to\u1ea3 gi\u00fap b\u1ea1n \"m\u1edf r\u1ed9ng\" ki\u1ebfn th\u1ee9c, kh\u00e1m ph\u00e1 nh\u1eefng l\u0129nh v\u1ef1c m\u1edbi m\u1ebb.</p> K\u1ebft h\u1ee3p hai ch\u1ebf \u0111\u1ed9 T\u1eadp Trung v\u00e0 Lan To\u1ea3? <p>B\u1ea1n c\u00f3 bao gi\u1edd t\u1eadp trung gi\u1ea3i quy\u1ebft m\u1ed9t v\u1ea5n \u0111\u1ec1 kh\u00f3, th\u1eed \u0111\u1ee7 c\u00e1ch nh\u01b0ng v\u1eabn ch\u01b0a c\u00f3 gi\u1ea3i ph\u00e1p, r\u1ed3i ng\u00e0y h\u00f4m sau, sau m\u1ed9t gi\u1ea5c ng\u1ee7 ngon l\u00e0nh, gi\u1ea3i ph\u00e1p t\u1ef1 nhi\u00ean xu\u1ea5t hi\u1ec7n trong \u0111\u1ea7u b\u1ea1n?</p> C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>C\u00e1c nh\u00e0 th\u1ea7n kinh h\u1ecdc ch\u1ec9 ra r\u1eb1ng trong m\u1ed9t th\u1eddi \u0111i\u1ec3m b\u1ea1n ch\u1ec9 c\u00f3 th\u1ec3 \u1edf m\u1ed9t trong hai ch\u1ebf \u0111\u1ed9, kh\u00f4ng th\u1ec3 \u1edf hai d\u1ea1ng th\u1ee9c t\u01b0 duy c\u00f9ng m\u1ed9t l\u00fac. Gi\u1ed1ng nh\u01b0 m\u1ed9t \u0111\u1ed3ng xu, ch\u00fang ta c\u00f3 th\u1ec3 nh\u00ecn th\u1ea5y ho\u1eb7c m\u1eb7t n\u00e0y ho\u1eb7c m\u1eb7t kia c\u1ee7a \u0111\u1ed3ng xu. Ch\u1ee9 kh\u00f4ng th\u1ec3 th\u1ea5y c\u1ea3 hai m\u1eb7t c\u00f9ng m\u1ed9t l\u00fac. Tuy nhi\u00ean, ch\u00fang ta c\u00f3 th\u1ec3 chuy\u1ec3n d\u1ed5i tu\u1ea7n t\u1ef1 hai d\u1ea1ng th\u1ee9c t\u01b0 duy \u0111\u1ec3 ph\u00e1t huy t\u1ed1i \u0111a t\u01b0 duy.</p> <p>V\u00ed d\u1ee5</p> <p>Nh\u01b0 \"\u00e2m v\u00e0 d\u01b0\u01a1ng\" c\u1ee7a v\u0169 tr\u1ee5, ch\u1ebf \u0111\u1ed9 T\u1eadp Trung v\u00e0 Lan To\u1ea3 gi\u1ed1ng nh\u01b0 \u00e2m v\u00e0 d\u01b0\u01a1ng c\u1ee7a v\u0169 tr\u1ee5, hai m\u1eb7t \u0111\u1ed1i l\u1eadp nh\u01b0ng l\u1ea1i b\u1ed5 sung cho nhau. Khi b\u1ea1n k\u1ebft h\u1ee3p c\u1ea3 hai ch\u1ebf \u0111\u1ed9 t\u01b0 duy m\u1ed9t c\u00e1ch h\u00e0i ho\u00e0, b\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c s\u1ef1 c\u00e2n b\u1eb1ng v\u00e0 th\u00e0nh c\u00f4ng trong h\u1ecdc t\u1eadp v\u00e0 c\u00f4ng vi\u1ec7c.</p> <p>V\u00ed d\u1ee5</p> <p>Nh\u01b0 \"hai b\u00e1nh xe\" c\u1ee7a chi\u1ebfc xe \u0111\u1ea1p, ch\u1ebf \u0111\u1ed9 T\u00e2ph trung v\u00e0 Lan To\u1ea3 gi\u1ed1ng nh\u01b0 hai b\u00e1nh xe c\u1ee7a chi\u1ebfc xe \u0111\u1ea1p, gi\u00fap n\u00f3 di chuy\u1ec3n m\u1ed9t c\u00e1ch \u1ed5n \u0111\u1ecbnh v\u00e0 an to\u00e0n. Khi b\u1ea1n s\u1eed d\u1ee5ng c\u1ea3 hai ch\u1ebf \u0111\u1ed9 t\u01b0 duy m\u1ed9t c\u00e1ch c\u00e2n b\u1eb1ng, b\u1ea1n c\u00f3 th\u1ec3 gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3 v\u00e0 s\u00e1ng t\u1ea1o.    </p> S\u1eed d\u1ee5ng ch\u1ebf \u0111\u1ed9 T\u1eadp Trung v\u00e0 Lan To\u1ea3 nh\u01b0 th\u1ebf n\u00e0o? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Khi b\u1ea1n h\u1ecdc \u0111i\u1ec1u g\u00ec \u0111\u00f3 m\u1edbi m\u1ebb, \u0111\u1eb7c bi\u1ec7t l\u00e0 \u0111i\u1ec1u g\u00ec \u0111\u00f3 h\u01a1i kh\u00f3 h\u01a1n m\u1ed9t ch\u00fat t\u00e2m tr\u00ed b\u1ea1n c\u1ea7n c\u00f3 th\u1ec3 \u0111i \u0111i l\u1ea1i l\u1ea1i gi\u1eefa hai ch\u1ebf \u0111\u1ed9 h\u1ecdc kh\u00e1c nhau. \u0110\u00f3 l\u00e0 \u0111i\u1ec1u gi\u00fap b\u1ea1n h\u1ecdc hi\u1ec7u qu\u1ea3. B\u1ea1n c\u00f3 th\u1ec3 ngh\u0129 v\u1ec1 \u0111i\u1ec1u \u0111\u00f3 g\u1ea7n t\u01b0\u01a1ng t\u1ef1 nh\u01b0 vi\u1ec7c x\u00e2y d\u1ef1ng s\u1ee9c m\u1ea1nh c\u1ee7a b\u1ea1n b\u1eb1ng c\u00e1ch c\u1eed t\u1ea1. B\u1ea1n s\u1ebd kh\u00f4ng bao gi\u1edd l\u1eadp k\u1ebf ho\u1ea1ch thi c\u1eed t\u1ea1 b\u1eb1ng c\u00e1ch \u0111\u1ee3i cho \u0111\u1ebfn ng\u00e0y tr\u01b0\u1edbc khi thi v\u00e0 d\u00e0nh c\u1ea3 ng\u00e0y h\u00f4m \u0111\u00f3 l\u00e0m vi\u1ec7c nh\u01b0 m\u1ed9t con qu\u00e1i v\u1eadt. \u00dd t\u00f4i l\u00e0 n\u00f3 kh\u00f4ng x\u1ea3y ra theo c\u00e1ch nh\u01b0 v\u1eady \u0110\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c c\u1ea5u tr\u00fac c\u01a1 b\u1eafp, b\u1ea1n c\u1ea7n ph\u1ea3i l\u00e0m vi\u1ec7c m\u1ed7i ng\u00e0y m\u1ed9t \u00edt, d\u1ea7n d\u1ea7n \u0111\u1ec3 cho c\u01a1 b\u1eafp c\u1ee7a b\u1ea1n ph\u00e1t tri\u1ec3n T\u01b0\u01a1ng t\u1ef1, \u0111\u1ec3 x\u00e2y d\u1ef1ng c\u1ea5u tr\u00fac th\u1ea7n kinh, b\u1ea1n c\u1ea7n ph\u1ea3i l\u00e0m vi\u1ec7c m\u1ed7i ng\u00e0y m\u1ed9t \u00edt, d\u1ea7n d\u1ea7n \u0111\u1ec3 b\u1ea1n t\u1ef1 ph\u00e1t tri\u1ec3n gi\u00e1 \u0111\u1ee1 th\u1ea7n kinh \u0111\u1ec3 l\u1eafng nghe t\u00e2m tr\u00ed c\u1ee7a b\u1ea1n, m\u1ed7i ng\u00e0y m\u1ed9t \u00edt v\u00e0 \u0111\u00f3 l\u00e0 m\u01b0u m\u1eb9o.</p> <p>Salvador Dali</p> <p>M\u1ed9t h\u1ecda s\u0129 si\u00eau th\u1ef1c r\u1ea5t n\u1ed5i ti\u1ebfng c\u1ee7a th\u1ebf k\u1ef7 20. \u00d4ng ta l\u00e0 m\u1ed9t ng\u01b0\u1eddi hoang d\u00e3 v\u00e0 \u0111i\u00ean kh\u00f9ng theo \u0111\u00fang ngh\u0129a B\u1ea1n c\u00f3 th\u1ec3 th\u1ea5y \u00f4ng \u1ea5y v\u1edbi con m\u00e8o c\u01b0ng c\u1ee7a m\u00ecnh Babou. Dali \u0111\u00e3 c\u00f3 m\u1ed9t k\u1ef9 thu\u1eadt th\u00fa v\u1ecb gi\u00fap \u00f4ng ta \u0111\u1ea1t t\u1edbi vi\u1ec7c v\u1ebd tranh si\u00eau th\u1ef1c s\u00e1ng t\u1ea1o m\u1ed9t c\u00e1ch k\u1ef3 l\u1ea1 \u00d4ng \u1ea5y th\u01b0 gi\u00e3n tr\u00ean gh\u1ebf v\u00e0 \u0111\u1ec3 cho t\u00e2m tr\u00ed c\u1ee7a m\u00ecnh t\u1ef1 do th\u01b0\u1eddng v\u1eabn m\u01a1 h\u1ed3 ngh\u0129 v\u1ec1 nh\u1eefng g\u00ec m\u00e0 tr\u01b0\u1edbc \u0111\u00e2y \u00f4ng \u1ea5y \u0111\u00e3 t\u1eadp trung v\u00e0o. \u00d4ng \u1ea5y c\u00f3 chi\u1ebfc ch\u00eca kh\u00f3a trong tay, \u0111u \u0111\u01b0a n\u00f3 ngay tr\u00ean s\u00e0n nh\u00e0 V\u00e0 khi \u00f4ng ta \u0111i v\u00e0o gi\u1ea5c m\u01a1 c\u1ee7a m\u00ecnh, ng\u1ee7 thi\u1ebfp \u0111i, th\u00ec chi\u1ebfc ch\u00eca kh\u00f3a s\u1ebd r\u01a1i kh\u1ecfi tay v\u00e0 ti\u1ebfng \u0111\u1ed9ng s\u1ebd \u0111\u00e1nh th\u1ee9c \u00f4ng ta, v\u1eeba \u0111\u00fang l\u00fac m\u00e0 \u00f4ng ta c\u00f3 th\u1ec3 thu th\u1eadp l\u1ea1i nh\u1eefng m\u1ed1i li\u00ean h\u1ec7 trong ch\u1ebf \u0111\u1ed9 khuy\u1ebfch t\u00e1n \u0111\u00f3 v\u00e0 c\u00e1c \u00fd t\u01b0\u1edfng trong t\u00e2m tr\u00ed c\u1ee7a m\u00ecnh V\u00e0 \u00f4ng ta quay tr\u1edf l\u1ea1i ch\u1ebf \u0111\u1ed9 t\u1eadp trung mang theo nh\u1eefng m\u1ed1i li\u00ean h\u1ec7 m\u1edbi \u0111\u00e3 c\u00f3 \u0111\u01b0\u1ee3c khi trong ch\u1ebf \u0111\u1ed9 khuy\u1ebfch t\u00e1n</p> <p>Thomas Edison</p> <p>Theo truy\u1ec1n thuy\u1ebft, \u0111i\u1ec1u m\u00e0 Edison th\u01b0\u1eddng l\u00e0m l\u00e0 ng\u1ed3i v\u00e0 th\u01b0 gi\u00e3n tr\u00ean gh\u1ebf, gi\u1eef v\u00f2ng bi trong tay \u00d4ng th\u1ea3 l\u1ecfng \u0111\u1ec3 cho t\u00e2m tr\u00ed m\u00ecnh t\u1ef1 do m\u1eb7c d\u00f9 th\u01b0\u1eddng xuy\u00ean \u1ee9ng bi\u1ebfn l\u1ea1i m\u1ed9t c\u00e1ch tho\u1ea3i m\u00e1i h\u01a1n nhi\u1ec1u v\u1edbi nh\u1eefng \u0111i\u1ec1u m\u00e0 \u00f4ng \u0111\u00e3 t\u1eadp trung v\u00e0o tr\u01b0\u1edbc \u0111\u00e2y. Khi Edison ng\u1ee7 thi\u1ebfp \u0111i, v\u00f2ng bi s\u1ebd r\u01a1i xu\u1ed1ng v\u00e0 ch\u1ea1m \u0111\u1ea5t k\u00eau vang nh\u01b0 v\u1edbi Dali. V\u00e0 \u0111\u00e1nh th\u1ee9c Edison v\u00e0 \u00f4ng \u0111\u00e3 \u0111i v\u1edbi nh\u1eefng \u00fd t\u01b0\u1edfng c\u1ee7a m\u00ecnh t\u1eeb ch\u1ebf \u0111\u1ed9 khuy\u1ebfch t\u00e1n, s\u1eb5n s\u00e0ng \u0111\u01b0a ch\u00fang v\u1ec1 ch\u1ebf \u0111\u1ed9 t\u1eadp trung v\u00e0 x\u00e2y d\u1ef1ng tr\u00ean \u0111\u00f3.</p> Ki\u1ec3u h\u1ecdc c\u00f3 m\u1ee5c ti\u00eau/m\u1ee5c \u0111\u00edch c\u1ee5 th\u1ec3? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Nh\u01b0 ch\u00fa chu\u1ed9t Jerry \"ch\u1ea1y tr\u1ed1n\" m\u00e8o Tom</p> <p>Jerry lu\u00f4n c\u00f3 m\u1ee5c ti\u00eau r\u00f5 r\u00e0ng l\u00e0 \"tho\u00e1t kh\u1ecfi\" s\u1ef1 truy \u0111u\u1ed5i c\u1ee7a Tom. Ch\u00fa chu\u1ed9t n\u00e0y l\u00ean k\u1ebf ho\u1ea1ch, s\u1eed d\u1ee5ng m\u1ecdi \"th\u1ee7 \u0111o\u1ea1n\" v\u00e0 t\u1eadp trung cao \u0111\u1ed9 \u0111\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c m\u1ee5c ti\u00eau c\u1ee7a m\u00ecnh. Ki\u1ec3u h\u1ecdc n\u00e0y c\u0169ng v\u1eady, b\u1ea1n x\u00e1c \u0111\u1ecbnh r\u00f5 m\u1ee5c ti\u00eau h\u1ecdc t\u1eadp v\u00e0 \"v\u1ea1ch ra\" chi\u1ebfn l\u01b0\u1ee3c c\u1ee5 th\u1ec3 \u0111\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c m\u1ee5c ti\u00eau \u0111\u00f3.</p> <p>Nh\u01b0 \"Luffy\" t\u00ecm ki\u1ebfm kho b\u00e1u One Piece</p> <p>Luffy c\u00f3 m\u1ee5c ti\u00eau r\u00f5 r\u00e0ng l\u00e0 t\u00ecm ra kho b\u00e1u One Piece v\u00e0 tr\u1edf th\u00e0nh Vua H\u1ea3i T\u1eb7c. C\u1eadu \u1ea5y \"chi\u00eau m\u1ed9\" \u0111\u1ed3ng \u0111\u1ed9i, \"v\u01b0\u1ee3t qua\" mu\u00f4n v\u00e0n th\u1eed th\u00e1ch v\u00e0 \"ti\u1ebfn v\u1ec1\" \u0111\u00edch \u0111\u1ebfn c\u1ee7a m\u00ecnh. Ki\u1ec3u h\u1ecdc n\u00e0y c\u0169ng v\u1eady, b\u1ea1n \"trang b\u1ecb\" cho m\u00ecnh nh\u1eefng ki\u1ebfn th\u1ee9c c\u1ea7n thi\u1ebft, \"v\u01b0\u1ee3t qua\" nh\u1eefng kh\u00f3 kh\u0103n v\u00e0 \"h\u01b0\u1edbng \u0111\u1ebfn\" m\u1ee5c ti\u00eau h\u1ecdc t\u1eadp c\u1ee7a m\u00ecnh.</p> Ki\u1ec3u h\u1ecdc ch\u1ec9 v\u00ec th\u00edch h\u1ecdc? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Nh\u01b0 \"Naruto\" luy\u1ec7n t\u1eadp nh\u1eabn thu\u1eadt</p> <p>Naruto luy\u1ec7n t\u1eadp nh\u1eabn thu\u1eadt kh\u00f4ng ch\u1ec9 \u0111\u1ec3 tr\u1edf th\u00e0nh Hokage m\u00e0 c\u00f2n v\u00ec ni\u1ec1m \u0111am m\u00ea v\u00e0 s\u1ef1 y\u00eau th\u00edch v\u1edbi nh\u1eabn thu\u1eadt. C\u1eadu \u1ea5y kh\u00f4ng ng\u1eebng \"kh\u00e1m ph\u00e1\", \"th\u1eed nghi\u1ec7m\" v\u00e0 \"ph\u00e1t tri\u1ec3n\" nh\u1eefng k\u1ef9 n\u0103ng m\u1edbi. Ki\u1ec3u h\u1ecdc n\u00e0y c\u0169ng v\u1eady, b\u1ea1n h\u1ecdc h\u1ecfi v\u00ec ni\u1ec1m vui v\u00e0 s\u1ef1 h\u1ee9ng th\u00fa, kh\u00f4ng \u0111\u1eb7t n\u1eb7ng v\u1ea5n \u0111\u1ec1 m\u1ee5c ti\u00eau.</p> <p>Nh\u01b0 \"Goku\" luy\u1ec7n t\u1eadp v\u00f5 thu\u1eadt</p> <p>Goku luy\u1ec7n t\u1eadp v\u00f5 thu\u1eadt kh\u00f4ng ch\u1ec9 \u0111\u1ec3 tr\u1edf n\u00ean m\u1ea1nh m\u1ebd h\u01a1n m\u00e0 c\u00f2n v\u00ec ni\u1ec1m \u0111am m\u00ea v\u00e0 s\u1ef1 y\u00eau th\u00edch v\u1edbi v\u00f5 thu\u1eadt. Ki\u1ec3u h\u1ecdc n\u00e0y c\u0169ng v\u1eady, b\u1ea1n h\u1ecdc h\u1ecfi v\u00ec \"th\u00edch th\u00fa\" v\u1edbi qu\u00e1 tr\u00ecnh chinh ph\u1ee5c ki\u1ebfn th\u1ee9c v\u00e0 \"th\u1ec3 hi\u1ec7n\" kh\u1ea3 n\u0103ng c\u1ee7a b\u1ea3n th\u00e2n.</p> S\u1ef1 ch\u1ea7n ch\u1edd l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Nh\u01b0 \"c\u00e2y l\u01b0\u1eddi\" \u0111\u00e2m ch\u1ed3i</p> <p>C\u00e2y l\u01b0\u1eddi kh\u00f4ng ch\u1ecbu \"v\u01b0\u01a1n m\u00ecnh\" \u0111\u00f3n \u00e1nh n\u1eafng, c\u1ee9 \"\u00ec \u1ea1ch\" m\u00e3i m\u1ed9t ch\u1ed7. Ch\u1ebf \u0111\u1ed9 ch\u1ea7n ch\u1eeb c\u0169ng v\u1eady, khi\u1ebfn b\u1ea1n \"m\u1eafc k\u1eb9t\" trong \"v\u0169ng l\u1ea7y\" tr\u00ec ho\u00e3n, kh\u00f4ng th\u1ec3 \"b\u1ee9t ph\u00e1\" \u0111\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c m\u1ee5c ti\u00eau.</p> <p>Nh\u01b0 \"con m\u00e8o\" ng\u1ee7 qu\u00ean</p> <p>Con m\u00e8o \"ch\u1ea7n ch\u1eeb\" kh\u00f4ng ch\u1ecbu \"b\u1eaft chu\u1ed9t\", cu\u1ed1i c\u00f9ng \"b\u1ecf l\u1ee1\" b\u1eefa \u0103n ngon. Ch\u1ebf \u0111\u1ed9 ch\u1ea7n ch\u1eeb c\u0169ng v\u1eady, khi\u1ebfn b\u1ea1n \"m\u1ea5t \u0111i\" nh\u1eefng c\u01a1 h\u1ed9i \"t\u1ed1t \u0111\u1eb9p\", \"h\u1ed1i ti\u1ebfc\" v\u00ec \u0111\u00e3 kh\u00f4ng \"n\u1eafm b\u1eaft\" k\u1ecbp th\u1eddi.</p> T\u1ea1i sao b\u1ea1n l\u1ea1i ch\u1ea7n ch\u1edd? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Khi b\u1ea1n b\u1eaft \u0111\u1ea7u l\u00e0m m\u1ed9t vi\u1ec7c b\u1ea1n th\u1eadt s\u1ef1 kh\u00f4ng mu\u1ed1n l\u00e0m, d\u01b0\u1eddng nh\u01b0 b\u1ea1n k\u00edch ho\u1ea1t nh\u1eefng v\u00f9ng c\u1ee7a n\u00e3o b\u1ed9 c\u00f3 li\u00ean quan \u0111\u1ebfn \u0111au. M\u1ed9t c\u00e1ch t\u1ef1 nhi\u00ean, n\u00e3o c\u1ee7a b\u1ea1n c\u1ed1 t\u00ecm m\u1ed9t c\u00e1ch \u0111\u1ec3 ng\u01b0ng k\u00edch th\u00edch \u0111au b\u1eb1ng c\u00e1ch chuy\u1ec3n s\u1ef1 ch\u00fa \u00fd c\u1ee7a b\u1ea1n qua m\u1ed9t vi\u1ec7c m\u00e0 b\u1ea1n th\u01b0\u1eddng c\u1ea3m th\u1ea5y h\u1ea1nh ph\u00fac h\u01a1n (l\u01b0\u1edbt facebook, tiktok, ch\u01a1i game,...) Tuy nhi\u00ean, c\u00e1c nh\u00e0 nghi\u00ean c\u1ee9u ph\u00e1t hi\u1ec7n r\u1eb1ng kh\u00f4ng l\u00e2u sau khi ng\u01b0\u1eddi ta b\u1eaft \u0111\u1ea7u th\u1ef1c s\u1ef1 l\u00e0m c\u00e1i m\u00e0 h\u1ecd kh\u00f4ng th\u00edch, s\u1ef1 \u0111au/kh\u00f3 ch\u1ecbu v\u1ec1 th\u1ea7n kinh bi\u1ebfn m\u1ea5t.</p> Pomodoro chinh ph\u1ee5c s\u1ef1 ch\u1ea7n ch\u1edd? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Pomodoro l\u00e0 ph\u01b0\u01a1ng ph\u00e1p qu\u1ea3n l\u00fd th\u1eddi gian, v\u1ec1 c\u01a1 b\u1ea3n, Pomodoro k\u1ebft h\u1ee3p s\u1eed d\u1ee5ng ch\u1ebf \u0111\u1ed9 T\u1eadp Trung v\u00e0 ch\u1ebf \u0111\u1ed9 Lan To\u1ea3 trong m\u1ed9t kho\u1ea3ng th\u1eddi gian ng\u1eafn, th\u01b0\u1eddng l\u00e0 25 ph\u00fat (ch\u1ebf \u0111\u1ed9 T\u1eadp Trung) v\u00e0 5 ph\u00fat (ch\u1ebf \u0111\u1ed9 Lan To\u1ea3). Sau m\u1ed7i 4 Pomodoro, b\u1ea1n s\u1ebd c\u00f3 m\u1ed9t kho\u1ea3ng ngh\u1ec9 d\u00e0i h\u01a1n, kho\u1ea3ng 15-20 ph\u00fat.</p> <p>K\u1ef9 thu\u1eadt Pomodoro c\u00f3 th\u1ec3 gi\u00fap b\u1ea1n \"ch\u1ed1ng l\u1ea1i\" s\u1ef1 ch\u1ea7n ch\u1eeb v\u00ec: * Chia nh\u1ecf c\u00f4ng vi\u1ec7c: Thay v\u00ec ph\u1ea3i \u0111\u1ed1i m\u1eb7t v\u1edbi m\u1ed9t c\u00f4ng vi\u1ec7c l\u1edbn v\u00e0 ph\u1ee9c t\u1ea1p, Pomodoro chia nh\u1ecf n\u00f3 th\u00e0nh c\u00e1c ph\u1ea7n nh\u1ecf h\u01a1n, d\u1ec5 qu\u1ea3n l\u00fd h\u01a1n. \u0110i\u1ec1u n\u00e0y gi\u00fap b\u1ea1n c\u1ea3m th\u1ea5y \u00edt \"ng\u1ea1i\" h\u01a1n khi b\u1eaft \u0111\u1ea7u v\u00e0 gi\u1ea3m nguy c\u01a1 b\u1ecb \"cho\u00e1ng ng\u1ee3p\" b\u1edfi c\u00f4ng vi\u1ec7c. * T\u1ea1o \u0111\u1ed9ng l\u1ef1c: M\u1ed7i pomodoro l\u00e0 m\u1ed9t \"th\u1eed th\u00e1ch\" nh\u1ecf m\u00e0 b\u1ea1n c\u00f3 th\u1ec3 d\u1ec5 d\u00e0ng v\u01b0\u1ee3t qua. Khi ho\u00e0n th\u00e0nh m\u1ed7i pomodoro, b\u1ea1n s\u1ebd c\u1ea3m th\u1ea5y \"th\u00e0nh c\u00f4ng\" v\u00e0 c\u00f3 th\u00eam \u0111\u1ed9ng l\u1ef1c \u0111\u1ec3 ti\u1ebfp t\u1ee5c. * T\u0103ng c\u01b0\u1eddng s\u1ef1 t\u1eadp trung: Th\u1eddi gian l\u00e0m vi\u1ec7c ng\u1eafn (25 ph\u00fat) gi\u00fap b\u1ea1n t\u1eadp trung cao \u0111\u1ed9 v\u00e0o c\u00f4ng vi\u1ec7c, tr\u00e1nh b\u1ecb xao nh\u00e3ng b\u1edfi nh\u1eefng y\u1ebfu t\u1ed1 b\u00ean ngo\u00e0i. * Gi\u1ea3m c\u0103ng th\u1eb3ng: C\u00e1c kho\u1ea3ng ngh\u1ec9 ng\u1eafn gi\u00fap b\u1ea1n th\u01b0 gi\u00e3n, gi\u1ea3m c\u0103ng th\u1eb3ng v\u00e0 \"l\u00e0m m\u1edbi\" tinh th\u1ea7n. \u0110i\u1ec1u n\u00e0y gi\u00fap b\u1ea1n duy tr\u00ec s\u1ef1 t\u1eadp trung v\u00e0 n\u0103ng su\u1ea5t l\u00e0m vi\u1ec7c trong su\u1ed1t c\u1ea3 ng\u00e0y. * T\u1ea1o th\u00f3i quen: Pomodoro gi\u00fap b\u1ea1n t\u1ea1o th\u00f3i quen l\u00e0m vi\u1ec7c v\u00e0 ngh\u1ec9 ng\u01a1i \u0111\u1ec1u \u0111\u1eb7n, t\u1eeb \u0111\u00f3 gi\u00fap b\u1ea1n qu\u1ea3n l\u00fd th\u1eddi gian hi\u1ec7u qu\u1ea3 h\u01a1n v\u00e0 gi\u1ea3m thi\u1ec3u s\u1ef1 ch\u1ea7n ch\u1eeb.</p> <p>Nh\u01b0 \"c\u00e2y c\u00e0 chua\" ch\u00edn \u0111\u1ecf</p> <p>Pomodoro l\u00e0 \"qu\u1ea3 c\u00e0 chua\" ch\u00edn \u0111\u1ecf, t\u01b0\u1ee3ng tr\u01b0ng cho s\u1ef1 \"t\u1eadp trung\" v\u00e0 \"n\u0103ng su\u1ea5t\". Khi b\u1ea1n \"h\u00e1i\" \u0111\u01b0\u1ee3c nhi\u1ec1u qu\u1ea3 pomodoro, c\u00f3 ngh\u0129a l\u00e0 b\u1ea1n \u0111\u00e3 ho\u00e0n th\u00e0nh nhi\u1ec1u c\u00f4ng vi\u1ec7c m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3.</p> <p>Nh\u01b0 vi\u1ec7c x\u00e2y m\u1ed9t b\u1ee9c t\u01b0\u1eddng</p> <p>Khi b\u1ea1n h\u1ecdc, \u0111i\u1ec1u m\u00e0 b\u1ea1n mu\u1ed1n l\u00e0m l\u00e0 h\u1ecdc \u0111\u01b0\u1ee3c c\u00e1i g\u00ec \u0111\u00f3. H\u00e3y h\u1ebft s\u1ee9c c\u1ed1 g\u1eafng h\u1ecdc \u0111i\u1ec1u \u0111\u00f3 b\u1eb1ng c\u00e1ch t\u1eadp trung ch\u0103m ch\u00fa (vi\u00ean g\u1ea1ch). Sau \u0111\u00f3 ngh\u1ec9 gi\u1ea3i lao ho\u1eb7c \u00edt nh\u1ea5t l\u00e0 thay \u0111\u1ed5i s\u1ef1 t\u1eadp trung c\u1ee7a b\u1ea1n v\u00e0o \u0111i\u1ec1u g\u00ec \u0111\u00f3 kh\u00e1c m\u1ed9t l\u00e1t (v\u1eefa/h\u1ed3). Trong th\u1eddi gian d\u01b0\u1eddng nh\u01b0 th\u01b0 d\u00e3n n\u00e0y ch\u1ebf \u0111\u1ed9 khuy\u1ebfch t\u00e1n \u1edf n\u00e3o b\u1ea1n c\u00f3 c\u01a1 h\u1ed9i ti\u1ebfp t\u1ee5c l\u00e0m vi\u1ec7c \u1edf m\u1ee9c n\u1ec1n t\u1ea3ng v\u00e0 gi\u00fap b\u1ea1n hi\u1ec3u kh\u00e1i ni\u1ec7m c\u1ee7a b\u1ea1n. V\u1eefa th\u1ea7n kinh c\u1ee7a b\u1ea1n, c\u1ee7a b\u1ea1n, theo m\u1ed9t ngh\u0129a n\u00e0o \u0111\u00f3 c\u00f3 c\u01a1 h\u1ed9i kh\u00f4 l\u1ea1i. N\u1ebfu kh\u00f4ng l\u00e0m nh\u01b0 v\u1eady, n\u1ebfu thay v\u00e0o \u0111\u00f3 b\u1ea1n l\u1ea1i h\u1ecdc m\u1ed9t c\u00e1ch nh\u1ed3i nh\u00e9t, th\u00ec c\u01a1 s\u1edf ki\u1ebfn th\u1ee9c c\u1ee7a b\u1ea1n s\u1ebd tr\u00f4ng gi\u1ed1ng nh\u01b0 m\u1ed9t m\u1edb b\u00f2ng bong v\u1edbi m\u1ecdi th\u1ee9 l\u1eabn l\u1ed9n v\u00e0 m\u1ed9t n\u1ec1n t\u1ea3ng y\u1ebfu k\u00e9m.</p> Tr\u00ed nh\u1edb d\u00e0i h\u1ea1n l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Nh\u01b0 \"\u1ed5 c\u1ee9ng HDD\" dung l\u01b0\u1ee3ng si\u00eau l\u1edbn</p> <p>Ch\u1ee9a \u0111\u1ef1ng to\u00e0n b\u1ed9 d\u1eef li\u1ec7u tuy nhi\u00ean vi\u1ec7c truy xu\u1ea5t th\u00f4ng tin kh\u00f3 v\u00e0 ch\u1eadm.</p> <p>Nh\u01b0 \"nh\u00e0 kho\" kh\u00f4ng l\u1ed3</p> <p>Nh\u01b0 m\u1ed9t nh\u00e0 kho kh\u1ed5ng l\u1ed3, n\u01a1i ch\u1ee9a r\u1ea5t nhi\u1ec1u ki\u1ec7n h\u00e0ng, m\u1ed7i ki\u1ec7n h\u00e0ng l\u00e0 m\u1ed9t m\u1eabu ki\u1ebfn th\u1ee9c, k\u00fd \u1ee9c c\u1ee7a ch\u00fang ta. Mu\u1ed1n l\u1ea5y m\u1ed9t ki\u1ec7n h\u00e0ng t\u1eeb kho s\u1ebd c\u1ea7n th\u1eddi gian t\u00ecm ki\u1ebfm v\u00e0 mang ra.</p> <p>Nh\u01b0 \"th\u01b0 vi\u1ec7n\" si\u00eau l\u1edbn</p> <p>Nh\u01b0 m\u1ed9t th\u01b0 vi\u1ec7n, n\u01a1i ch\u1ee9a r\u1ea5t nhi\u1ec1u s\u00e1ch thu\u1ed9c r\u1ea5t nhi\u1ec1u ch\u1ee7 \u0111\u1ec1, m\u1ed7i cu\u1ed1n s\u00e1ch l\u00e0 m\u1ed9t m\u00e2\u0169 ki\u1ebfn th\u1ee9c v\u00e0 k\u00fd \u1ee9c c\u1ee7a ch\u00fang ta. Mu\u1ed1n l\u1ea5y m\u1ed9t cu\u1ed1n s\u00e1ch t\u1eeb th\u01b0 vi\u1ec7n, ta c\u1ea7n t\u00ecm ki\u1ebfm v\u00e0 \u0111i t\u1edbi khu v\u1ef1c \u0111\u1ec3 s\u00e1ch v\u00e0 l\u1ea5y xu\u1ed1ng \u0111\u1ecdc.</p> Tr\u00ed nh\u1edb ng\u1eafn h\u1ea1n l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Theo c\u00e1c nh\u00e0 nghi\u00ean c\u1ee9u th\u00ec m\u1ed7i ng\u01b0\u1eddi c\u00f3 4 c\u00e1i khe trong b\u1ed9 nh\u1edb ng\u1eafn h\u1ea1n, m\u1ed7i khe c\u00f3 th\u1ec3 k\u1ebft n\u1ed1i t\u1edbi m\u1ed9t m\u1eabu ki\u1ebfn th\u1ee9c n\u00e0o \u0111\u00f3. !!! example Nh\u01b0 \"b\u1ea3ng \u0111en\" c\u0169     Nh\u01b0 m\u1ed9t c\u00e1i b\u1ea3ng \u0111en c\u0169, c\u00e1c th\u00f4ng tin ghi tr\u00ean b\u1ea3ng \u0111en th\u01b0\u1eddng r\u1ea5t m\u1edd nh\u1ea1t v\u00e0 d\u1ec5 b\u1ecb xo\u00e1 m\u1ea5t. !!! example Nh\u01b0 \"m\u1eabu gi\u1ea5y nh\u00e1p\" d\u00f9ng m\u1ed9t l\u1ea7n     M\u1ea9u gi\u1ea5y nh\u00e1p d\u00f9ng \u0111\u1ec3 \"ghi l\u1ea1i\" th\u00f4ng tin t\u1ea1m th\u1eddi, sau \u0111\u00f3 s\u1ebd \"v\u1ee9t b\u1ecf\". Tr\u00ed nh\u1edb ng\u1eafn h\u1ea1n c\u0169ng v\u1eady, \"l\u01b0u tr\u1eef\" th\u00f4ng tin trong \"m\u1ed9t kho\u1ea3ng th\u1eddi gian ng\u1eafn\", sau \u0111\u00f3 s\u1ebd \"qu\u00ean\" \u0111i \u0111\u1ec3 \"nh\u01b0\u1eddng ch\u1ed7\" cho th\u00f4ng tin m\u1edbi. !!! example Nh\u01b0 \"n\u00e3o c\u00e1 v\u00e0ng\" 7 gi\u00e2y     Ng\u01b0\u1eddi ta th\u01b0\u1eddng n\u00f3i c\u00e1 v\u00e0ng ch\u1ec9 c\u00f3 tr\u00ed nh\u1edb 7 gi\u00e2y. Tr\u00ed nh\u1edb ng\u1eafn h\u1ea1n c\u0169ng v\u1eady, \"l\u01b0u gi\u1eef\" th\u00f4ng tin trong \"th\u1eddi gian r\u1ea5t ng\u1eafn\", n\u1ebfu kh\u00f4ng \u0111\u01b0\u1ee3c \"\u00f4n l\u1ea1i\" s\u1ebd \"qu\u00ean ngay\".</p> Chuy\u1ec3n tr\u00ed nh\u1edb ng\u1eafn h\u1ea1n th\u00e0nh tr\u00ed nh\u1edb l\u00e2u d\u00e0i? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Tr\u00ed nh\u1edb l\u00e2u d\u00e0i l\u00e0 quan tr\u1ecdng b\u1edfi v\u00ec n\u00f3 l\u00e0 n\u01a1i b\u1ea1n l\u01b0u gi\u1eef nh\u1eefng kh\u00e1i ni\u1ec7m v\u00e0 k\u1ef9 thu\u1eadt c\u01a1 b\u1ea3n th\u01b0\u1eddng \u0111\u01b0\u1ee3c c\u00f3 trong b\u1ea5t c\u1ee9 \u0111i\u1ec1u g\u00ec m\u00e0 b\u1ea1n \u0111ang h\u1ecdc. Khi b\u1ea1n g\u1eb7p ph\u1ea3i \u0111i\u1ec1u g\u00ec m\u1edbi, b\u1ea1n th\u01b0\u1eddng s\u1eed d\u1ee5ng tr\u00ed nh\u1edb ng\u1eafn h\u1ea1n \u0111\u1ec3 x\u1eed l\u00fd n\u00f3. N\u1ebfu b\u1ea1n mu\u1ed1n chuy\u1ec3n th\u00f4ng tin \u0111\u00f3 th\u00e0nh tr\u00ed nh\u1edb l\u00e2u d\u00e0i c\u1ee7a b\u1ea1n, th\u00ec th\u01b0\u1eddng ph\u1ea3i m\u1ea5t th\u1eddi gian v\u00e0 r\u00e8n luy\u1ec7n. \u0110\u1ec3 gi\u00fap qu\u00e1 tr\u00ecnh n\u00e0y, h\u00e3y d\u00f9ng m\u1ed9t k\u1ef9 thu\u1eadt \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Nh\u1eafc L\u1ea1i C\u00e1ch Qu\u00e3ng  !!! example Nh\u01b0 \"gieo m\u1ea7m\" v\u00e0 \"ch\u0103m s\u00f3c\" c\u00e2y     Tr\u00ed nh\u1edb ng\u1eafn h\u1ea1n gi\u1ed1ng nh\u01b0 \"h\u1ea1t gi\u1ed1ng\" m\u1edbi gieo, c\u1ea7n \u0111\u01b0\u1ee3c \"ch\u0103m s\u00f3c\" v\u00e0 \"t\u01b0\u1edbi t\u1eafm\" th\u01b0\u1eddng xuy\u00ean \u0111\u1ec3 \"n\u1ea3y m\u1ea7m\" v\u00e0 \"ph\u00e1t tri\u1ec3n\" th\u00e0nh \"c\u00e2y c\u1ed5 th\u1ee5\" v\u1eefng ch\u1eafc (Tr\u00ed nh\u1edb l\u00e2u d\u00e0i). !!! example Nh\u01b0 \"t\u00ecm \u0111\u01b0\u1eddng\" t\u1edbi c\u00f4ng ty m\u1edbi     Tr\u00ed nh\u1edb ng\u1eafn h\u1ea1n gi\u1ed1ng nh\u01b0 ng\u00e0y \u0111\u1ea7u b\u1ea1n t\u00ecm \u0111\u01b0\u1eddng t\u1edbi c\u00f4ng ty m\u1edbi, l\u00fac \u0111\u1ea7u b\u1ea1n c\u00f2n c\u1ea7n xem Google Maps,tuy nhi\u00ean sau v\u00e0i ng\u00e0y, b\u1ea1n s\u1ebd \"quen\" \u0111\u01b0\u1eddng t\u1edbi c\u00f4ng ty m\u1ed9t c\u00e1ch t\u1ef1 nhi\u00ean v\u00e0 nh\u01b0 m\u1ed9t th\u00f3i quen.</p> Nh\u1eafc L\u1ea1i C\u00e1ch Qu\u00e3ng? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>K\u1ef9 thu\u1eadt n\u00e0y g\u1ed3m vi\u1ec7c nh\u1eafc l\u1ea1i \u0111i\u1ec1u m\u00e0 b\u1ea1n \u0111ang c\u1ed1 ghi nh\u1edb, nh\u01b0ng \u0111i\u1ec1u b\u1ea1n mu\u1ed1n l\u00e0m l\u00e0 \u0111\u1ec3 c\u00e1ch qu\u00e3ng vi\u1ec7c nh\u1eafc l\u1ea1i n\u00e0y nhi\u1ec1u h\u01a1n. Nh\u1eafc l\u1ea1i m\u1ed9t t\u1eeb v\u1ef1ng m\u1edbi ho\u1eb7c m\u1ed9t k\u1ef9 thu\u1eadt gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1, v\u00ed d\u1ee5, qua m\u1ed9t s\u1ed1 ng\u00e0y. Vi\u1ec7c k\u00e9o \u0111\u00e0i s\u1ef1 r\u00e8n luy\u1ec7n c\u1ee7a b\u1ea1n qua v\u00e0i ng\u00e0y qu\u1ea3 l\u00e0 c\u00f3 t\u1ea1o ra s\u1ef1 kh\u00e1c bi\u1ec7t. Nghi\u00ean c\u1ee9u \u0111\u00e3 cho th\u1ea5y n\u1ebfu b\u1ea1n c\u1ed1 g\u1eafng g\u1eafn c\u00e1c th\u1ee9 v\u00e0o tr\u00ed nh\u1edb c\u1ee7a b\u1ea1n b\u1eb1ng c\u00e1ch nh\u1eafc l\u1ea1i \u0111i\u1ec1u g\u00ec \u0111\u00f3 20 l\u1ea7n trong m\u1ed9t bu\u1ed5i t\u1ed1i, v\u00ed d\u1ee5, n\u00f3 s\u1ebd kh\u00f4ng d\u00ednh \u0111\u01b0\u1ee3c t\u1ed1t nh\u01b0 l\u00e0 n\u1ebfu b\u1ea1n r\u00e8n luy\u1ec7n ng\u1ea7n \u1ea5y l\u1ea7n trong v\u00e0i ng\u00e0y. \u0110i\u1ec1u n\u00e0y l\u00e0 gi\u1ed1ng nh\u01b0 vi\u1ec7c x\u00e2y t\u01b0\u1eddng g\u1ea1ch m\u00e0 ch\u00fang ta \u0111\u00e3 th\u1ea5y tr\u01b0\u1edbc \u0111\u00e2y. N\u1ebfu b\u1ea1n kh\u00f4ng d\u00e0nh th\u1eddi gian cho v\u1eefa kh\u00f4, t\u1ee9c l\u00e0, th\u1eddi gian \u0111\u1ec3 cho nh\u1eefng m\u1ed1i k\u1ebft n\u1ed1i kh\u00e1i qu\u1ea3t h\u00ecnh th\u00e0nh v\u00e0 c\u1ee7ng c\u1ed1 th\u00ec b\u1ea1n s\u1ebd kh\u00f4ng c\u00f3 m\u1ed9t c\u1ea5u tr\u00fac t\u1ed1t. !!! example Nh\u01b0 \"t\u01b0\u1edbi n\u01b0\u1edbc\" cho c\u00e2y     B\u1ea1n kh\u00f4ng th\u1ec3 t\u01b0\u1edbi 20 l\u1ea7n trong m\u1ed9t t\u1ed1i v\u00e0 mong c\u00e2y s\u1ebd l\u1edbn kho\u1ebb, ng\u01b0\u1ee3c l\u1ea1i c\u00e2y s\u1ebd b\u1ecb \u00fang n\u01b0\u1edbc v\u00e0 ch\u1ebft ng\u1ed9t. Thay v\u00e0o \u0111\u00f3, m\u1ed7i ng\u00e0y v\u00e0o m\u1ed9t th\u1eddi \u0111i\u1ec3m b\u1ea1n s\u1ebd t\u1edbi 1 l\u1ea7n v\u00e0 quan s\u00e1t c\u00e2y l\u1edbn l\u00ean t\u1eebng ng\u00e0y. K\u1ef9 thu\u1eadt Nh\u1eafc L\u1ea1i C\u00e1ch Qu\u00e3ng c\u0169ng v\u1eady, m\u1ed7i ng\u00e0y b\u1ea1n \u00f4n l\u1ea1i ki\u1ebfn th\u1ee9c 1 l\u1ea7n trong nhi\u1ec1u ng\u00e0y th\u00ec ki\u1ebfn th\u1ee9c s\u1ebd \u0111\u01b0\u1ee3c in \u0111\u1eadm v\u00e0o Tr\u00ed Nh\u1edb D\u00e0i H\u1ea1n. !!! example Nh\u01b0 \"t\u00ecm \u0111\u01b0\u1eddng\" t\u1edbi c\u00f4ng ty m\u1edbi     Con \u0111\u01b0\u1eddng \u0111i \u0111\u1ebfn c\u00f4ng ty m\u1edbi c\u1ea7n \u0111\u01b0\u1ee3c \"\u0111i l\u1ea1i\" nhi\u1ec1u l\u1ea7n \u0111\u1ec3 \"kh\u1eafc s\u00e2u\" v\u00e0o tr\u00ed nh\u1edb. Ki\u1ebfn th\u1ee9c c\u0169ng v\u1eady, c\u1ea7n \u0111\u01b0\u1ee3c \"\u00f4n l\u1ea1i\" nhi\u1ec1u l\u1ea7n, \"\u0111i l\u1ea1i\" ki\u1ebfn th\u1ee9c th\u01b0\u1eddng xuy\u00ean \u0111\u1ec3 \"ghi nh\u1edb\" l\u00e2u d\u00e0i.</p> <p>x\u00e2y t\u01b0\u1edfng g\u1ea1ch</p> <p>N\u1ebfu ch\u1ec9 trong m\u1ed9t ng\u00e0y b\u1ea1n x\u00e2y to\u00e0n b\u1ed9 m\u1ed9t b\u1ee9c t\u01b0\u1eddng cao th\u00ec b\u01b0\u1edbc t\u01b0\u1eddng c\u00f3 th\u1ec3 b\u1ecb \u0111\u1ed5 th\u00e0nh m\u1ed9t m\u1edb h\u1ed7n \u0111\u1ed9n, thay v\u00e0o \u0111\u00f3, b\u1ea1n x\u00e2y m\u1ed9t ph\u1ea7n v\u00e0 \u0111\u1ee3i cho v\u1eefa/h\u1ed3 kh\u00f4 sau \u0111\u00f3 x\u00e2y ti\u1ebfp th\u00ec b\u1ee9c t\u01b0\u1eddng s\u1ebd v\u1eefng ch\u1eafc.</p> T\u1ea1i sao Nh\u1eafc L\u1ea1i C\u00e1ch Qu\u00e3ng hi\u1ec7u qu\u1ea3? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Nh\u1eafc l\u1ea1i c\u00e1ch qu\u00e3ng l\u00e0 m\u1ed9t k\u1ef9 thu\u1eadt h\u1ecdc t\u1eadp hi\u1ec7u qu\u1ea3, d\u1ef1a tr\u00ean nguy\u00ean t\u1eafc \"qu\u00ean l\u00e3ng\" c\u1ee7a n\u00e3o b\u1ed9. Thay v\u00ec \"nh\u1ed3i nh\u00e9t\" ki\u1ebfn th\u1ee9c trong m\u1ed9t l\u1ea7n, b\u1ea1n s\u1ebd \"chia nh\u1ecf\" qu\u00e1 tr\u00ecnh h\u1ecdc t\u1eadp v\u00e0 \"\u00f4n l\u1ea1i\" ki\u1ebfn th\u1ee9c theo nh\u1eefng \"kho\u1ea3ng th\u1eddi gian\" kh\u00e1c nhau. * T\u1eadn d\u1ee5ng \"qu\u00ean l\u00e3ng\": Khi b\u1ea1n \u00f4n l\u1ea1i ki\u1ebfn th\u1ee9c ngay tr\u01b0\u1edbc khi qu\u00ean, n\u00e3o b\u1ed9 s\u1ebd \"c\u1ee7ng c\u1ed1\" l\u1ea1i tr\u00ed nh\u1edb v\u00e0 \"chuy\u1ec3n\" th\u00f4ng tin t\u1eeb tr\u00ed nh\u1edb ng\u1eafn h\u1ea1n sang tr\u00ed nh\u1edb d\u00e0i h\u1ea1n. * Ti\u1ebft ki\u1ec7m th\u1eddi gian: Thay v\u00ec ph\u1ea3i \"h\u1ecdc l\u1ea1i\" t\u1eeb \u0111\u1ea7u, b\u1ea1n ch\u1ec9 c\u1ea7n \"\u00f4n l\u1ea1i\" nh\u1eefng \u0111i\u1ec3m ch\u00ednh, gi\u00fap ti\u1ebft ki\u1ec7m th\u1eddi gian v\u00e0 c\u00f4ng s\u1ee9c. * T\u0103ng c\u01b0\u1eddng tr\u00ed nh\u1edb: Nh\u1eafc l\u1ea1i c\u00e1ch qu\u00e3ng gi\u00fap b\u1ea1n \"ghi nh\u1edb\" ki\u1ebfn th\u1ee9c l\u00e2u d\u00e0i h\u01a1n, \"s\u1eed d\u1ee5ng\" ch\u00fang m\u1ed9t c\u00e1ch linh ho\u1ea1t v\u00e0 hi\u1ec7u qu\u1ea3.</p> N\u00e3o ch\u00fang ta s\u1ebd l\u00e0m g\u00ec khi ch\u00fang ta \u0111ang ng\u1ee7? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Vi\u1ec7c th\u1ee9c d\u1eady thu\u1ea7n tu\u00fd t\u1ea1o ra c\u00e1c ch\u1ea5t \u0111\u1ed9c h\u1ea1i trong n\u00e3o, mu\u1ed1n lo\u1ea1i b\u1ecf c\u00e1c ch\u1ea5t \u0111\u1ed9c h\u1ea1i trong n\u00e3o \u0111\u01a1n gi\u1ea3n l\u00e0 ch\u00fang ta ch\u1ec9 c\u1ea7n ng\u1ee7.</p> <p>Example</p> <p>Hai b\u00ean b\u1edd k\u00e8 t\u01b0\u1ee3ng trung cho c\u00e1c t\u1ebf b\u00e0o n\u00e3o, c\u00f2n r\u00e1c l\u00e0 ch\u1ea5t \u0111\u01b0\u1ee3c trong n\u00e3o. Khi ng\u1ee7, c\u00e1c t\u1ebf b\u00e0o n\u00e3o \u0111\u01b0\u1ee3c co l\u1ea1i l\u00e0m t\u0103ng kho\u1ea3ng c\u00e1ch gi\u1eefa c\u00e1c t\u1ebf b\u00e0o n\u00e3o, nh\u01b0 vi\u1ec7c ch\u00fang ta m\u1edf r\u1ed9ng k\u00eanh ra, l\u00fac n\u00e0y th\u00ec r\u00e1c s\u1ebd kh\u00f4ng c\u00f2n t\u00edch t\u1ee5 n\u1eefa m\u00e0 s\u1ebd \u0111\u01b0\u1ee3c tr\u00f4i \u0111i, gi\u1eef cho k\u00eanh s\u1ea1ch s\u1ebd.</p> <p>Example</p> <p>C\u0169ng t\u01b0\u01a1ng t\u1ef1 khi b\u1ea1n h\u00ecnh dung d\u00f2ng xe \u0111\u00f4ng \u0111\u00fac tr\u00ean m\u1ed9t con \u0111\u01b0\u1eddng, n\u1ebfu ch\u00fang ta gia t\u0103ng kho\u1ea3ng c\u00e1ch hai b\u00ean l\u1ec1 \u0111\u01b0\u1eddng th\u00ec con \u0111\u01b0\u1eddng s\u1ebd th\u00f4ng tho\u00e1ng h\u01a1n.</p> Thi\u1ebfu ng\u1ee7 s\u1ebd c\u00f3 t\u00e1c h\u1ea1i g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Vi\u1ec7c ng\u1ee7 nghe c\u00f3 v\u1ebb l\u00e3ng ph\u00ed th\u1eddi gian, th\u1ef1c t\u1ebf ng\u1ee7 \u0111\u1ee7 gi\u1ea5c gi\u00fap n\u00e3o b\u1ea1n s\u1ea1ch s\u1ebd v\u00e0 kho\u1ebb m\u1ea1nh. T\u01b0\u1edfng t\u01b0\u1edfng khi b\u1ea1n thi\u1ebfu ng\u1ee7, n\u00e3o b\u1ea1n ch\u1ee9a \u0111\u1ea7y \u0111\u1ed9c t\u1ed1 trong n\u00e3o, c\u00e1c \u0111\u1ed9c t\u1ed1 s\u1ebd c\u1ea3n tr\u1ee3 vi\u1ec7c k\u1ebft n\u1ed1i gi\u1eefa c\u00e1c t\u1ebf b\u00e0o n\u00e3o v\u1edbi nhau l\u00e0m cho b\u1ea1n kh\u00f3 t\u1eadp trung ho\u1eb7c gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 kh\u00f3. Ngo\u00e0i ra, ng\u1ee7 qu\u00e1 \u00edt trong th\u1eddi gian d\u00e0i c\u0169ng c\u00e1c tri\u1ec7u ch\u1ee9ng nh\u01b0 \u0111au \u0111\u1ea7u, tr\u1ea7m c\u1ea3m, \u0111au tim, ti\u1ec3u \u0111\u01b0\u1eddng v\u00e0 \u0111\u01a1n gian l\u00e0 b\u1ea1n s\u1ebd ch\u1ebft s\u1edbm. B\u00ean c\u1ea1nh \u0111\u00f3, gi\u1ea5c ng\u1ee7 kh\u00f4ng nh\u1eefng t\u1ea9y s\u1ea1ch c\u00e1c \u0111\u1ed9c t\u1ed1 trong n\u00e3o m\u00e0 gi\u1ea5c ng\u1ee7 c\u00f2n \u0111\u00f3ng vai tr\u00f2 quan tr\u1ecdng trong tr\u00ed nh\u1edb v\u00e0 vi\u1ec7c h\u1ecdc.</p> Gi\u1ea5c ng\u1ee7 trong tr\u00ed nh\u1edb v\u00e0 vi\u1ec7c h\u1ecdc? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>C\u00f3 v\u1ebb trong khi ng\u1ee7, n\u00e3o b\u1ea1n s\u1eafp x\u1ebfp ng\u0103n n\u1eafp c\u00e1c \u00fd t\u01b0\u1edfng v\u00e0 kh\u00e1i ni\u1ec7m m\u00e0 b\u1ea1n ngh\u0129 \u0111\u1ebfn ho\u1eb7c \u0111ang h\u1ecdc. N\u00e3o xo\u00e1 \u0111i nh\u1eefng ph\u1ea7n \u00edt quan tr\u1ecdng c\u1ee7a tr\u00ed nh\u1edb v\u00e0 \u0111\u1ed3ng th\u1eddi c\u1ee7ng c\u1ed1 nh\u1eefng v\u00f9ng m\u00e0 b\u1ea1n \u0111ang c\u1ea7n h\u1ecdc v\u00e0 mu\u1ed1n nh\u1edb. Gi\u1ea5c ng\u1ee7 c\u0169ng \u0111\u01b0\u1ee3c bi\u1ebft l\u00e0 l\u00e0m t\u0103ng kh\u1ea3 n\u0103ng trong vi\u1ec7c gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 kh\u00f3 v\u00e0 hi\u1ec3u \u0111i\u1ec1u m\u00e0 b\u1ea1n \u0111ang c\u1ed1 h\u1ecdc. Khi ng\u1ee7, b\u1ea1n ho\u00e0n to\u00e0n ch\u1ea5m d\u1ee9t tr\u1ea1ng th\u00e1i \u00fd th\u1ee9c v\u00e0 chuy\u1ec3n sang tr\u1ea1ng th\u00e1i ti\u1ec1m th\u1ee9c n\u01a1i m\u00e0 c\u00e1c ph\u1ea7n n\u00e3o kh\u00e1c ho\u1ea1t \u0111\u1ed9ng m\u1ea1nh khi b\u1ea1n \u0111ang ng\u1ee7. V\u00e0 \u0111\u00f3 c\u0169ng l\u00e0 k\u1ebft qu\u1ea3 c\u1ee7a ch\u1ebf \u0111\u1ed9 Lan To\u1ea3 ho\u1ea1t \u0111\u1ed9ng, tuy nhi\u00ean, b\u1ea1n ph\u1ea3i th\u1eadt s\u1ef1 \u1edf ch\u1ebf \u0111\u1ed9 T\u1eadp Trung tr\u01b0\u1edbc \u0111\u00f3.  N\u1ebfu b\u1ea1n t\u1eadp trung h\u1ecdc ngay tr\u01b0\u1edbc khi ng\u1ee7 tr\u01b0a ho\u1eb7c \u0111i ng\u1ee7 v\u00e0o bu\u1ed5i t\u1ed1i th\u00ec b\u1ea1n s\u1ebd t\u0103ng c\u01a1 h\u1ed9i n\u1eb1m m\u01a1 v\u1ec1 n\u00f3. C\u00e0ng t\u00e2m ni\u1ec7m v\u1ec1 vi\u1ec7c m\u01a1 v\u1ec1 n\u00f3 th\u00ec b\u1ea1n c\u00e0ng t\u0103ng kh\u1ea3 n\u0103ng m\u01a1 v\u1ec1 n\u00f3. M\u01a1 v\u1ec1 nh\u1eefng g\u00ec b\u1ea1n \u0111ang h\u1ecdc c\u00f3 th\u1ec3 l\u00e0m t\u0103ng c\u01b0\u1eddng kh\u1ea3 n\u0103ng hi\u1ec3u c\u1ee7a b\u1ea1n v\u1ec1 n\u00f3. Cho n\u00ean mu\u1ed1n nh\u1edb v\u00e0 hi\u1ec3u s\u00e2u th\u00ec sau khi h\u1ecdc t\u00e2p trung b\u1ea1n n\u00ean ch\u1ee3p m\u1eaft m\u1ed9t ch\u00fat.</p>"},{"location":"lhtl/#chunking","title":"Chunking","text":"Chunk v\u00e0 Chunking l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Chunk ngh\u0129a l\u00e0 c\u1ee5m/m\u1eabu/\u0111o\u1ea1n t\u1eeb ng\u1eef c\u1ea3nh, c\u00f2n Chunking ngh\u0129a l\u00e0 vi\u1ec7c h\u1ecdc theo c\u1ee5m/m\u1eabu/\u0111o\u1ea1n th\u00f4ng qua ng\u1eef c\u1ea3nh. Khi b\u1ea1n t\u1eadp trung ch\u00fa \u00fd v\u00e0o m\u1ed9t th\u1ee9 g\u00ec \u0111\u00f3 th\u00ec g\u1ea7n nh\u01b0 b\u1ea1n c\u00f3 1 con b\u1ea1ch tu\u1ed9c v\u1edbi 4 x\u00fac tu tr\u01b0\u1ee3t qua 4 khe c\u1ee7a b\u1ed9 nh\u1edb ng\u1eafn h\u1ea1n gi\u00fap b\u1ea1n k\u1ebft n\u1ed1i v\u1edbi nh\u1eefng th\u00f4ng tin m\u00e0 b\u1ea1n c\u00f3 th\u1ec3 c\u00f3 trong nhi\u1ec1u ph\u1ea7n c\u1ee7a n\u00e3o. T\u1eadp trung s\u1ef1 ch\u00fa \u00fd \u0111\u1ec3 b\u1ea1n k\u1ebft n\u1ed1i c\u00e1c ph\u1ea7n c\u1ee7a n\u00e3o \u0111\u1ec3 n\u1ed1i c\u00e1c \u00fd t\u01b0\u1edfng v\u1edbi nhau l\u00e0 m\u1ed9t ph\u1ea7n quan tr\u1ecdng trong ch\u1ebf \u0111\u1ed9 t\u1eadp trung c\u1ee7a vi\u1ec7c h\u1ecdc. N\u00f3 c\u0169ng th\u01b0\u1eddng l\u00e0 \u0111i\u1ec1u gi\u00fap b\u1ea1n b\u1eaft \u0111\u1ea7u h\u00ecnh th\u00e0nh m\u1ed9t Chunk. \u0110i\u1ec1u n\u00e0y kh\u00e1c v\u1edbi c\u00e1c k\u1ebft n\u1ed1i ng\u1eabu nhi\u00ean trong ch\u1ebf \u0111\u1ed9 Lan To\u1ea3.</p> <p>T\u1ee9c gi\u1eadn, c\u0103ng th\u1eb3ng, ho\u1eb7c s\u1ee3 h\u00e3i</p> <p>Th\u00fa v\u1ecb l\u00e0 khi b\u1ea1n b\u1ecb c\u0103ng th\u1eb3ng, con b\u1ea1ch tu\u1ed9c ch\u00fa \u00fd c\u1ee7a b\u1ea1n b\u1eaft \u0111\u1ea7u m\u1ea5t kh\u1ea3 n\u0103ng t\u1ea1o ra m\u1ed9t s\u1ed1 k\u1ebft n\u1ed1i \u0111\u00f3. \u0110\u00f3 l\u00e0 t\u1ea1i sao n\u00e3o b\u1ea1n kh\u00f4ng c\u00f3 v\u1ebb l\u00e0m vi\u1ec7c \u1ed5n khi b\u1ea1n t\u1ee9c gi\u1eadn, c\u0103ng th\u1eb3ng, ho\u1eb7c s\u1ee3 h\u00e3i.</p> L\u00e0m sao \u0111\u1ec3 tinh th\u00f4ng m\u1ed9t l\u0129nh v\u1ef1c? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>M\u1ed9t trong nh\u1eefng b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean \u0111\u1ec3 \u0111\u1ea1t t\u1edbi s\u1ef1 tinh th\u00f4ng trong c\u00e1c ch\u1ee7 \u0111\u1ec1 h\u1ecdc thu\u1eadt l\u00e0 t\u1ea1o ra c\u00e1c \u0111o\u1ea1n kh\u00e1i ni\u1ec7m, nh\u1eefng b\u01b0\u1edbc nh\u1ea3y tr\u00ed tu\u1ec7 k\u1ebft n\u1ed1i c\u00e1c bit th\u00f4ng tin ph\u00e2n t\u00e1n th\u00f4ng qua \u00fd ngh\u0129a. Kh\u00e1i ni\u1ec7m v\u1ec1 c\u00e1c \u0111o\u1ea1n th\u1ea7n kinh c\u0169ng \u00e1p d\u1ee5ng trong th\u1ec3 thao, \u00e2m nh\u1ea1c khi\u00eau v\u0169, th\u1eadt s\u1ef1 l\u00e0 v\u1ec1 b\u1ea5t c\u1ee9 \u0111i\u1ec1u g\u00ec m\u00e0 con ng\u01b0\u1eddi c\u00f3 th\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c t\u1edbi.</p> <p>V\u1ec1 c\u01a1 b\u1ea3n, m\u1ed9t \u0111o\u1ea1n ngh\u0129a l\u00e0 m\u1ed9t m\u1ea1ng l\u01b0\u1edbi c\u00e1c t\u1ebf b\u00e0o th\u1ea7n kinh \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 k\u00edch th\u00edch c\u00f9ng nhau sao cho b\u1ea1n c\u00f3 th\u1ec3 ngh\u0129 m\u1ed9t \u00fd ho\u1eb7c th\u1ef1c hi\u1ec7n m\u1ed9t h\u00e0nh \u0111\u1ed9ng m\u1ed9t c\u00e1ch tr\u00f4i ch\u1ea3y v\u00e0 hi\u1ec7u qu\u1ea3. Nh\u1eafc l\u1ea1i v\u00e0 th\u1ef1c h\u00e0nh t\u1eadp trung, s\u00e1ng t\u1ea1o ra nh\u1eefng d\u1ea5u v\u1ebft tr\u00ed \u00f3c m\u1ea1nh m\u1ebd, gi\u00fap b\u1ea1n t\u1ea1o ra c\u00e1c \u0111o\u1ea1n.</p> <p>Con \u0111\u01b0\u1eddng t\u1edbi s\u1ef1 tinh th\u00f4ng \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng t\u1eebng t\u00ed m\u1ed9t, nh\u1eefng \u0111o\u1ea1n nh\u1ecf c\u00f3 th\u1ec3 tr\u1edf th\u00e0nh l\u1edbn h\u01a1n, v\u00e0 m\u1ecdi s\u1ef1 tinh th\u00f4ng d\u00f9ng l\u00e0m c\u01a1 s\u1edf cho nh\u1eefng gi\u1ea3i th\u00edch s\u00e1ng t\u1ea1o h\u01a1n khi b\u1ea1n d\u1ea7n tr\u1edf n\u00ean l\u00e0m ch\u1ee7 c\u00e1c t\u00e0i li\u1ec7u. N\u00f3i c\u00e1ch kh\u00e1c, nh\u01b0 b\u1ea1n s\u1ebd th\u1ea5y sau \u0111\u00e2y th\u1ef1c h\u00e0nh v\u00e0 nh\u1eafc l\u1ea1i trong vi\u1ec7c x\u00e2y d\u1ef1ng c\u00e1c \u0111o\u1ea1n kh\u00f4ng ph\u1ea3i l\u00e0 t\u1ea5t c\u1ea3 nh\u1eefng g\u00ec m\u00e0 b\u1ea1n c\u1ea7n \u0111\u1ec3 tr\u1edf th\u00e0nh m\u1ed9t ng\u01b0\u1eddi th\u1ef1c s\u1ef1 l\u00e0m ch\u1ee7 nh\u1eefng t\u00e0i li\u1ec7u m\u00e0 b\u1ea1n h\u1ecdc. Vi\u1ec7c ph\u00e2n \u0111o\u1ea1n gi\u00fap n\u00e3o b\u1ea1n l\u00e0m vi\u1ec7c hi\u1ec7u qu\u1ea3 h\u01a1n. M\u1ed9t khi b\u1ea1n ph\u00e2n \u0111o\u1ea1n m\u1ed9t \u00fd t\u01b0\u1edfng, m\u1ed9t kh\u00e1i ni\u1ec7m ho\u1eb7c m\u1ed9t h\u00e0nh \u0111\u1ed9ng b\u1ea1n kh\u00f4ng bi\u1ebft c\u1ea7n ph\u1ea3i nh\u1edb m\u1ecdi chi ti\u1ebft c\u01a1 b\u1ea3n nh\u1ecf nh\u1ea5t. B\u1ea1n \u0111\u00e3 c\u00f3 \u00fd t\u01b0\u1edfng ch\u00ednh, \u0111o\u1ea1n suy ngh\u0129, v\u00e0 \u0111i\u1ec1u \u0111\u00f3 l\u00e0 \u0111\u1ee7. !!! example Nh\u01b0 \"\u0111\u00e1nh r\u0103ng\" m\u1ed7i s\u00e1ng th\u1ee9c d\u1eady     B\u1ea1n ch\u1ec9 ngh\u0129 \u0111\u01a1n gi\u1ea3n, nh\u01b0 l\u00e0, t\u00f4i s\u1ebd \u0111\u00e1nh r\u0103ng, nh\u01b0ng th\u1eadt kinh ng\u1ea1c khi b\u1ea1n nh\u1eadn ra c\u1ea3 m\u1ed9t chu\u1ed7i th\u1ee7 t\u1ee5c ph\u1ee9c t\u1ea1p g\u1ed3m nh\u1eefng ho\u1ea1t \u0111\u1ed9ng c\u01a1 b\u1ea3n di\u1ec5n ra v\u1edbi m\u1ed9t \u0111o\u1ea1n suy ngh\u0129 \u0111\u01a1n gi\u1ea3n \u0111\u00f3.</p> L\u00e0m sao \u0111\u1ec3 h\u00ecnh th\u00e0nh m\u1ed9t Chunk? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <ol> <li>B\u01b0\u1edbc 1: t\u1eadp trung to\u00e0n b\u1ed9 s\u1ef1 ch\u00fa \u00fd c\u1ee7a b\u1ea1n v\u00e0o nh\u1eefng th\u00f4ng tin m\u00e0 b\u1ea1n mu\u1ed1n h\u00ecnh th\u00e0nh Chunk.</li> <li> <p>B\u01b0\u1edbc 2: hi\u1ec3u \u00fd t\u01b0\u1edfng c\u01a1 b\u1ea3n m\u00e0 b\u1ea1n \u0111ang c\u1ed1 g\u1eafng h\u00ecnh th\u00e0nh Chunk, d\u00f9 \u0111\u00f3 l\u00e0 hi\u1ec3u m\u1ed9t kh\u00e1i ni\u1ec7m ho\u1eb7c m\u1ed9t b\u1ea3n ch\u1ea5t c\u1ee7a m\u1ed9t lo\u1ea1i v\u1ea5n \u0111\u1ec1 to\u00e1n h\u1ecdc c\u1ee5 th\u1ec3.</p> <p>T\u1ed5ng h\u1ee3p \u00fd ch\u00ednh</p> <p>T\u00ecm ra \u00fd t\u01b0\u1edfng ch\u00ednh c\u1ee7a c\u00e1c \u00fd t\u01b0\u1edfng</p> <p>Tuy nhi\u00ean, vi\u1ec7c hi\u1ec3u c\u00e1ch gi\u1ea3i quy\u1ebft m\u1ed9t v\u1ea5n \u0111\u1ec1 kh\u00f4ng c\u00f3 ngh\u0129a l\u00e0 b\u1ea1n c\u00f3 th\u1ec3 t\u1ef1 gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1. Vi\u1ec7c g\u1ea5p s\u00e1ch l\u1ea1i v\u00e0 t\u1ef1 ki\u1ec3m tra xem li\u1ec7u b\u1ea1n, t\u1ef1 b\u1ea1n c\u00f3 th\u1ec3 gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 m\u00e0 b\u1ea1n ngh\u0129 b\u1ea1n hi\u1ec3u kh\u00f4ng s\u1ebd l\u00e0m t\u0103ng t\u1ed1c vi\u1ec7c h\u1ecdc c\u1ee7a b\u1ea1n. B\u1ea1n ph\u1ea3i th\u1ef1c s\u1ef1 l\u00e0m \u0111i\u1ec1u \u0111\u00f3.</p> <p>Nh\u00ecn ng\u01b0\u1eddi kh\u00e1c v\u1ebd kh\u00f4ng c\u00f3 ngh\u0129a b\u1ea1n th\u1ef1c s\u1ef1 c\u00f3 th\u1ec3 t\u1ea1o ra t\u00e1c ph\u1ea9m \u0111\u00f3.</p> <p>Nghe m\u1ed9t b\u00e0i h\u00e1t kh\u00f4ng c\u00f3 ngh\u0129a l\u00e0 b\u1ea1n th\u1ef1c s\u1ef1 h\u00e1t \u0111\u01b0\u1ee3c b\u00e0i \u0111\u00f3.</p> <p>Ch\u1ec9 v\u00ec b\u1ea1n nh\u00ecn th\u1ea5y n\u00f3, hay th\u1eadm ch\u00ed l\u00e0 b\u1ea1n hi\u1ec3u n\u00f3, \u0111i\u1ebfu \u0111\u00f3 kh\u00f4ng c\u00f3 ngh\u0129a l\u00e0 b\u1ea1n c\u00f3 th\u1ec3 th\u1ef1c s\u1ef1 l\u00e0m \u0111\u01b0\u1ee3c n\u00f3. Ch\u1ec9 c\u00f3 t\u1ef1 b\u1ea1n l\u00e0m m\u1edbi gi\u00fap t\u1ea1o ra nh\u1eefng m\u1eabu th\u1ea7n kinh l\u00e0m n\u1ec1n t\u1ea3ng cho s\u1ef1 tinh th\u00f4ng th\u1ef1c s\u1ef1</p> </li> <li> <p>B\u01b0\u1edbc 3: ki\u1ebfm \u0111\u01b0\u1ee3c ng\u1eef c\u1ea3nh, \u0111\u1ec3 bi\u1ebft \u0111\u01b0\u1ee3c khi n\u00e0o s\u1eed d\u1ee5ng v\u00e0 khi n\u00e0o kh\u00f4ng s\u1eed d\u1ee5ng c\u00e1ch gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1.</p> <p>L\u01b0\u1edbt nhanh hai ph\u00fat h\u00ecnh \u1ea3nh v\u00e0 m\u1ee5c l\u1ee5c m\u1ed9t ch\u01b0\u01a1ng tr\u01b0\u1edbc khi b\u1eaft \u0111\u00e2u h\u1ecdc \u0111\u1ec3 n\u1eafm \u0111\u01b0\u1ee3c b\u1ee9c tranh to\u00e0n c\u1ea3nh</p> <p>Nh\u0169ng lo\u1ea1i ho\u1ea1t \u0111\u1ed9ng n\u00e0y c\u00f3 th\u1ec3 gi\u00fap b\u1ea1n bi\u1ebft ch\u1ed5 s\u1eafp \u0111\u1eb7t Chunk m\u00e0 b\u1ea1n \u0111ang x\u00e2y d\u1ef1ng, l\u00e0m sao \u0111\u1ec3 c\u00e1c Chunk li\u00ean quan t\u1edbi nhau.</p> </li> </ol> <p>H\u1ecdc c\u00e1c m\u00f4n ngh\u1ec7 thu\u1eadt</p> <p>Nh\u01b0 t\u1eadp \u0111\u00e1nh m\u1ed9t b\u1ea3n nh\u1ea1c ghitar, tr\u01b0\u1edbc ti\u00ean, \u0111\u1ea1i \u0111a s\u1ed1 s\u1ebd nghe b\u1ea3n nh\u1ea1c m\u1ed9t l\u1ea7n ho\u1eb7c xem ai \u0111\u00f3 bi\u1ec3u di\u1ec5n m\u1ed9t l\u1ea7n, r\u1ed3i b\u1ea1n b\u1eaft \u0111\u00e2u t\u1eadp t\u1eebng \u0111o\u1ea1n nh\u1ecf \u0111\u1ebfn khi th\u00e0nh th\u1ee5c r\u1ed3i chuy\u1ec3n qua \u0111o\u1ea1n kh\u00e1c, cu\u1ed1i c\u00f9ng b\u1ea1n d\u1ea7n d\u1ea7n n\u1ed1i c\u00e1c \u0111o\u1ea1n nh\u1ecf \u0111\u00e3 t\u1eadp v\u00e0 \u0111\u00e1nh m\u1ed9t b\u1ea3n nh\u1ea1c ho\u00e0n ch\u1ec9nh. T\u01b0\u01a1ng t\u1ef1 nh\u01b0 vi\u1ec7c t\u1eadp h\u00e1t, t\u1eadp nh\u1ea3y, v\u1ebd,...</p> <p>H\u1ecdc c\u00e1c m\u00f4n th\u1ec3 thao</p> <p>Nh\u01b0 t\u1eadp ch\u01a1i b\u00f3ng \u0111\u00e1, tr\u01b0\u1edbc ti\u00ean, c\u00e1c b\u1ea1n s\u1ebd t\u1eadp t\u1eebng k\u1ef9 n\u0103ng nh\u1ecf t\u1eeb vi\u1ec7c gi\u1eef b\u00f3ng, d\u1eaft b\u00f3ng, chuy\u1ec1n b\u00f3ng ho\u1eb7c s\u00fat. Sau \u0111\u00f3 b\u1ea1n s\u1ebd t\u1eadp nh\u1eefng k\u1ef9 n\u0103ng ph\u1ed1i h\u1ee3p \u0111\u1ec3 c\u00f3 th\u1ec3 v\u00e0o s\u00e2n thi \u0111\u1ea5u.</p> <p>H\u1ecdc To\u00e1n v\u00e0 Khoa H\u1ecdc</p> <p>Th\u01b0\u1eddng th\u00ec m\u1ed7i v\u1ea5n \u0111\u1ec1 ho\u1eb7c kh\u00e1i ni\u1ec7m s\u1ebd \u0111i v\u1edbi \u0111\u00e1p \u00e1n c\u00f3 s\u1eb5n, vi\u1ec7c b\u1ea1n c\u1ea7n l\u00e0m l\u00e0 t\u00ecm hi\u1ec3u t\u1ea1i sao m\u1ed7i b\u01b0\u1edbc l\u1ea1i l\u00e0m nh\u01b0 v\u1eady. Tuy nhi\u00ean l\u1ea1i kh\u00f4ng c\u00f3 g\u00ec n\u00f3i v\u1ec1 s\u1ef1 k\u1ebft n\u1ed1i gi\u1eefa c\u00e1c b\u01b0\u1edbc. T\u1ee9c l\u00e0 v\u1ec1 vi\u1ec7c  t\u1ea1i sao b\u01b0\u1edbc c\u1ee5 th\u1ec3 n\u00e0y l\u1ea1i l\u00e0 \u0111i\u1ec1u ti\u1ebfp theo m\u00e0 b\u1ea1n n\u00ean l\u00e0m nh\u01b0 v\u1eady. C\u00e1ch h\u1ecdc m\u00e1y m\u00f3c nh\u01b0 v\u1eady c\u1ea7n tr\u00e1nh, b\u1ea1n c\u1ea7n hi\u1ec3u \u0111\u01b0\u1ee3c b\u01b0\u1edbc tranh t\u1ed5ng th\u1ec3 v\u00e0 s\u00e1ng t\u1ea1o c\u00e1ch t\u1edbi \u0111\u00edch th\u00f4ng qua t\u1eebng b\u01b0\u1edbc c\u1ee5 th\u1ec3.</p> T\u1ea7m quan tr\u1ecdng c\u1ee7a vi\u1ec7c nh\u1edb l\u1ea1i? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Nghi\u00ean c\u1ee9u c\u1ee7a Karpicke cho th\u1ea5y vi\u1ec7c nh\u1edb l\u1ea1i sau khi nghi\u00ean c\u1ee9u m\u1ed9t t\u00e0i li\u1ec7u sau \u0111\u00f3 nghi\u00ean c\u1ee9u l\u1ea1i v\u00e0 nh\u1edb l\u1ea1i n\u00f3 m\u1ed9t l\u1ea7n n\u1eefa. \u0110\u00f3 l\u00e0, h\u1ecd c\u1ed1 \u0111\u00e3 c\u1ed1 g\u1eafng nh\u1edb nh\u1eefng \u00fd ch\u00ednh v\u00e0 \u0111i\u1ec1u n\u00e0y gi\u00fap nh\u1edb l\u00e2u h\u01a1n v\u00e0 h\u1ecdc s\u00e2u h\u01a1n.</p> <p>Vi\u1ec7c l\u1eadp b\u1ea3n \u0111\u1ed3 kh\u00e1i ni\u1ec7m, v\u1ebd c\u00e1c bi\u1ec3u \u0111\u1ed3 ch\u1ec9 ra quan h\u1ec7 c\u00e1c kh\u00e1i ni\u1ec7m m\u1edbi l\u00e0 c\u00e1ch t\u1ed1t \u0111\u1ec3 t\u1ed5ng h\u1ee3p tuy nhi\u00ean n\u1ebfu c\u00e1c kh\u1ed1i c\u01a1 b\u1ea3n ch\u01b0a \u0111\u01b0\u1ee3c nh\u00fang v\u00e0o trong n\u00e3o, th\u00ec c\u00e1c bi\u1ec3u \u0111\u1ed3 kh\u00f4ng th\u1ec3 ho\u1ea1t \u0111\u1ed9ng</p> <p>Nh\u01b0 em b\u00e9 t\u1eadp ch\u1ea1y trong khi ch\u01b0a bi\u1ebft b\u00f2</p> \u1ea2o T\u01b0\u1edfng v\u1ec1 N\u0103ng L\u1ef1c trong h\u1ecdc t\u1eadp? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>\u0110\u00f3 l\u00e0 khi b\u1ea1n s\u1eed d\u1ee5ng ph\u01b0\u01a1ng ph\u00e1p h\u1ecdc kh\u00f4ng hi\u1ec7u qu\u1ea3, ch\u00fang \u0111\u00e1nh l\u1eeba t\u00e2m tr\u00ed c\u1ee7a b\u1ea1n ngh\u0129 r\u1eb1ng b\u1ea1n \u0111ang h\u1ecdc m\u1ed9t c\u00e1i g\u00ec \u0111\u00f3, trong khi b\u1ea1n ch\u1ec9 ch\u1ee7 y\u1ebfu l\u00e0 l\u00e3ng ph\u00ed th\u1eddi gian c\u1ee7a m\u00ecnh.</p> <p>Nguy\u00ean nh\u00e2n m\u00e0 h\u1ecdc sinh v\u1eabn th\u00edch ti\u1ebfp t\u1ee5c \u0111\u1ecdc l\u1ea1i nh\u1eefng ch\u00fa th\u00edch c\u1ee7a m\u00ecnh ho\u1eb7c v\u1edf, l\u00e0 v\u00ec khi h\u1ecd c\u00f3 s\u00e1ch ho\u1eb7c GOOGLE m\u1edf ngay tr\u01b0\u1edbc m\u1eb7t h\u1ecd, ch\u00fang cung c\u1ea5p \u1ea3o t\u01b0\u1edfng r\u1eb1ng t\u00e0i li\u1ec7u c\u0169ng n\u1eb1m trong \u0111\u1ea7u h\u1ecd. Nh\u01b0ng kh\u00f4ng ph\u1ea3i th\u1ebf b\u1edfi v\u00ec n\u00f3 c\u00f3 th\u1ec3 d\u1ec5 \u0111ang h\u01a1n \u0111\u1ec3 nh\u00ecn v\u00e0o m\u1ed9t cu\u1ed1n s\u00e1ch thay v\u00ec nh\u1edb l\u1ea1i, h\u1ecdc sinh kh\u0103ng kh\u0103ng gi\u1eef \u1ea3o t\u01b0\u1edfng h\u1ecdc b\u1eb1ng c\u00e1ch m\u00e0 \u0111\u01a1n gi\u1ea3n l\u00e0 kh\u00f4ng hi\u1ec7u qu\u1ea3 cho l\u1eafm.</p> Ki\u1ec3m tra nh\u1ecf v\u00e0 gi\u00e1 tr\u1ecb c\u1ee7a ph\u1ea1m l\u1ed7i C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Trong m\u1ed9t v\u00e0i \u00fd ngh\u0129a, \u0111\u00f3 ch\u00ednh l\u00e0 nh\u1eefng g\u00ec m\u00e0 vi\u1ec7c nh\u1edb l\u1ea1i \u0111ang th\u1ef1c hi\u1ec7n. cho ph\u00e9p b\u1ea1n bi\u1ebft \u0111\u01b0\u1ee3c b\u1ea1n c\u00f3 th\u1ef1c s\u1ef1 n\u1eafm ch\u1eafc m\u1ed9t \u00fd t\u01b0\u1edfng. N\u1ebfu b\u1ea1n m\u1eafc l\u1ed7i trong vi\u1ec7c b\u1ea1n \u0111ang l\u00e0m, \u0111\u00f3 th\u1ef1c s\u1ef1 l\u00e0 m\u1ed9t vi\u1ec7c t\u1ed1t. B\u1ea1n mu\u1ed1n c\u1ed1 g\u1eafng kh\u00f4ng l\u1eb7p l\u1ea1i l\u1ed7i, d\u0129 nhi\u00ean r\u1ed3i, nh\u01b0ng l\u1ed7i r\u1ea5t \u0111\u00e1ng gi\u00e1 \u0111\u1ec3 m\u1eafc ph\u1ea3i trong nh\u1eefng b\u00e0i t\u1ef1 ki\u1ec3m tra nh\u1ecf c\u1ee7a b\u1ea1n tr\u01b0\u1edbc khi l\u00e0m b\u00e0i ki\u1ec3m tra n\u00e2ng cao th\u1ef1c s\u1ef1. B\u1edfi v\u00ec ch\u00fang cho ph\u00e9p b\u1ea1n s\u1eeda ch\u1eefa v\u00e0 b\u1ea1n l\u1ea5p \u0111\u1ea7y l\u1ed7 h\u1ed5ng ki\u1ebfn th\u1ee9c t\u1eeb t\u1eeb. L\u1ed7 sai gi\u00fap s\u01b0\u1ea3 l\u1ed7i suy ngh\u0129 c\u1ee7a b\u1ea1n, v\u00ec th\u1ebf b\u1ea1n c\u00f3 th\u1ec3 h\u1ecdc t\u1ed1t h\u01a1n v\u00e0 l\u00e0m t\u1ed1t h\u01a1n.</p> Thay \u0111\u1ed5i \u0111\u1ecba \u0111i\u1ec3m h\u1ecdc t\u1eadp C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Theo nghi\u00ean c\u1ee9u cho th\u1ea5y n\u1ebfu b\u1ea1n chu\u1ea9n b\u1ecb m\u1ed9t k\u1ef3 thi th\u01b0\u1eddng s\u1ebd t\u1ed5 tr\u01b0\u1edbc trong ph\u00f2ng thi, vi\u1ec7c b\u1ea1n h\u1ecdc tr\u01b0\u1edbc \u0111\u00f3 \u1edf m\u1ed9t n\u01a1i nh\u1ea5t \u0111\u1ecbnh c\u00f3 th\u1ec3 s\u1ebd neo cho b\u1ea1n v\u1ec1 \u0111\u1ecba \u0111i\u1ec3m h\u1ecdc v\u00e0 khi b\u1ea1n v\u00e0o ph\u00f2ng thi s\u1ebd t\u1ea1o th\u00e0nh r\u00e0o c\u1ea3n t\u00e2m l\u00fd do b\u1ea1n \u0111\u00e3 neo \u0111\u1ecba \u0111i\u1ec3m h\u1ecdc t\u1eadp, m\u1ed9t c\u00e1ch gi\u1ea3i quy\u1ebft l\u00e0 \u0111\u1eebng \u0111\u1ec3 neo v\u00e0o m\u1ed9t \u0111\u1ecba \u0111i\u1ec3m nh\u1ea5t \u0111\u1ecbnh, b\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i \u0111\u1ecba \u0111i\u1ec3m h\u1ecdc t\u1eadp t\u1eeb s\u1edf th\u00edch c\u1ee7a m\u00ecnh.</p> C\u00e1c ph\u01b0\u01a1ng ph\u00e1p h\u1ecdc t\u1eadp \u00edt hi\u1ec7u qu\u1ea3? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Vi\u1ec7c h\u1ecdc thu\u1ed9c l\u00f2ng ho\u1eb7c \u0111\u1ecdc \u0111i \u0111\u1ecdc l\u1ea1i th\u1ee5 \u0111\u1ed9ng nhi\u1ec1u l\u1ea7n to\u00e0n b\u1ed9 t\u00e0i li\u1ec7u.</p> \u1ee8ng d\u1ee5ng h\u1ec7 th\u1ed1ng Flashcards trong vi\u1ec7c h\u1ecdc? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>M\u1ed9t m\u1eb7t ghi c\u00e2u h\u1ecfi v\u00e0 m\u1eb7t kia ghi c\u00e2u tr\u1ea3 l\u1eddi. C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n. Sau \u0111\u00f3 ki\u1ec3m tra nh\u1edb l\u1ea1i v\u1edbi \u0111\u00e1p \u00e1n.  L\u00ean l\u1ecbch c\u00e1ch 1 ng\u00e0y, 1 tu\u1ea7n , \u2153/6 th\u00e1ng nh\u1eafc l\u1ea1i (Nh\u1eafc L\u1ea1i Ng\u1eaft Qu\u00e3ng)</p> Acetylcholine? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <ol> <li>L\u00e0 ch\u1ea5t d\u1eabn truy\u1ec1n th\u1ea7n kinh \u1edf c\u1ea3 h\u1ec7 th\u1ed1ng th\u1ea7n kinh trung \u01b0\u01a1ng v\u00e0 th\u1ea7n kinh ngo\u1ea1i vi.</li> <li>L\u00e0 hormone n\u1ed9i ti\u1ebft, \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p v\u00e0 ti\u1ebft ra b\u1edfi c\u00e1c t\u1ebf b\u00e0o bi\u1ec3u m\u00f4 ph\u1ebf qu\u1ea3n \u0111\u01b0\u1eddng th\u1edd.</li> </ol> <p>Acetylcholine \u0111\u00f3ng vai tr\u00f2 h\u00ecnh th\u00e0nh \u0111\u1ed9ng l\u1ef1c, k\u00edch th\u00edch, s\u1ef1 ch\u00fa \u00fd, h\u1ecdc t\u1eadp v\u00e0 tr\u00ed nh\u1edb, v\u00e0 gi\u1ea5c ng\u1ee7 REM (giai \u0111o\u1ea1n ng\u1ee7 m\u01a1) giai \u0111o\u1ea1n quan tr\u1ecdng cho vi\u1ec7c c\u1ee7ng c\u1ed1 tr\u00ed nh\u1edb v\u00e0 h\u1ecdc t\u1eadp.</p> <p>B\u1ec7nh Alzheimer</p> <p>Do suy gi\u1ea3m \u0111\u01b0\u1eddng cholinergic nghi\u00eam tr\u1ecdng trong th\u1ea7n kinh trung \u01b0\u01a1ng c\u00f3 li\u00ean quan kh\u1edfi ph\u00e1t b\u1ec7nh Ahzheimer.</p> <p>M\u1ed9t s\u1ed1 lo\u1ea1i thu\u1ed1c tr\u1eeb s\u00e2u v\u00e0 kh\u00ed t\u1ec3</p> <p>Thu\u1ed1c v\u00e0 c\u00e1c ch\u1ea5t l\u00e0m gi\u00e1n \u0111o\u1ea1n ch\u1ee9c ng\u0103n Acetylcholine c\u00f3 th\u1ec3 c\u00f3 t\u00e1c \u0111\u1ed9ng ti\u00eau c\u1ef1c \u0111\u1ebfn c\u01a1 th\u1ec3 v\u00e0 th\u1eadm ch\u00ed d\u1eabn \u0111\u1ebfn t\u1eed vong.</p> <p>N\u1ecdc \u0111\u1ed9c c\u1ee7a nh\u1ec7n Go\u00e1 ph\u1ee5 \u0111en</p> <p>N\u1ecdc \u0111\u1ed9c c\u1ee7a nh\u1ec7n g\u00f3a ph\u1ee5 \u0111en ho\u1ea1t \u0111\u1ed9ng b\u1eb1ng c\u00e1ch gi\u1ea3i ph\u00f3ng acetylcholine. Khi b\u1ecb c\u1eafn, n\u1ed3ng \u0111\u1ed9 acetylcholine c\u1ee7a n\u1ea1n nh\u00e2n t\u0103ng cao \u0111\u1ed9t ng\u1ed9t, d\u1eabn \u0111\u1ebfn co th\u1eaft c\u01a1, t\u00ea li\u1ec7t v\u00e0 th\u1eadm ch\u00ed t\u1eed vong.</p> T\u0103ng c\u01b0\u1eddng Acetylcholine m\u1ed9t c\u00e1ch t\u1ef1 nhi\u00ean? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <ul> <li>Ch\u1ebf \u0111\u1ed9 \u0103n u\u1ed1ng l\u00e0nh m\u1ea1nh: \u0102n c\u00e1c th\u1ef1c ph\u1ea9m gi\u00e0u choline, m\u1ed9t ch\u1ea5t dinh d\u01b0\u1ee1ng c\u1ea7n thi\u1ebft \u0111\u1ec3 s\u1ea3n xu\u1ea5t acetylcholine, nh\u01b0 tr\u1ee9ng, th\u1ecbt, c\u00e1, c\u00e1c lo\u1ea1i \u0111\u1eadu v\u00e0 rau xanh.</li> <li>T\u1eadp th\u1ec3 d\u1ee5c th\u01b0\u1eddng xuy\u00ean: Ho\u1ea1t \u0111\u1ed9ng th\u1ec3 ch\u1ea5t gi\u00fap t\u0103ng c\u01b0\u1eddng s\u1ea3n xu\u1ea5t acetylcholine v\u00e0 c\u1ea3i thi\u1ec7n ch\u1ee9c n\u0103ng n\u00e3o b\u1ed9.</li> <li>Ng\u1ee7 \u0111\u1ee7 gi\u1ea5c: Gi\u1ea5c ng\u1ee7 gi\u00fap n\u00e3o b\u1ed9 s\u1ea3n xu\u1ea5t acetylcholine v\u00e0 c\u1ee7ng c\u1ed1 tr\u00ed nh\u1edb.</li> <li>H\u1ecdc t\u1eadp v\u00e0 th\u1eed th\u00e1ch b\u1ea3n th\u00e2n: H\u1ecdc t\u1eadp nh\u1eefng \u0111i\u1ec1u m\u1edbi m\u1ebb v\u00e0 th\u1eed th\u00e1ch b\u1ea3n th\u00e2n trong c\u00e1c ho\u1ea1t \u0111\u1ed9ng tr\u00ed \u00f3c gi\u00fap t\u0103ng c\u01b0\u1eddng s\u1ea3n xu\u1ea5t acetylcholine v\u00e0 c\u1ea3i thi\u1ec7n ch\u1ee9c n\u0103ng nh\u1eadn th\u1ee9c.</li> </ul> Dopamine? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>L\u00e0 ch\u1ea5t d\u1eabn truy\u1ec1n th\u1ea7n kinh quan tr\u1ecdng, \u0111\u00f3ng vai tr\u00f2 quan tr\u1ecdng trong nhi\u1ec1u ch\u1ee9c n\u0103ng c\u1ee7a n\u00e3o b\u1ed9, bao g\u1ed3m h\u1ecdc t\u1eadp.</p> <p>Dopamine \u0111\u00f3ng vai tr\u00f2 quan tr\u1ecdng trong vi\u1ec7c h\u1ecdc t\u1eadp, \u0111\u1eb7c bi\u1ec7t l\u00e0 h\u1ecdc t\u1eadp d\u1ef1a tr\u00ean ph\u1ea7n th\u01b0\u1edfng. Khi ch\u00fang ta h\u1ecdc \u0111\u01b0\u1ee3c \u0111i\u1ec1u g\u00ec \u0111\u00f3 m\u1edbi m\u1ebb ho\u1eb7c \u0111\u1ea1t \u0111\u01b0\u1ee3c m\u1ee5c ti\u00eau h\u1ecdc t\u1eadp, n\u00e3o b\u1ed9 s\u1ebd gi\u1ea3i ph\u00f3ng dopamine, t\u1ea1o ra c\u1ea3m gi\u00e1c h\u1ea1nh ph\u00fac v\u00e0 kho\u00e1i c\u1ea3m. C\u1ea3m gi\u00e1c n\u00e0y s\u1ebd th\u00fac \u0111\u1ea9y ch\u00fang ta ti\u1ebfp t\u1ee5c h\u1ecdc t\u1eadp v\u00e0 t\u00ecm ki\u1ebfm nh\u1eefng ki\u1ebfn th\u1ee9c m\u1edbi.</p> T\u0103ng c\u01b0\u1eddng Dopamine m\u1ed9t c\u00e1ch t\u1ef1 nhi\u00ean? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <ul> <li>\u0110\u1eb7t m\u1ee5c ti\u00eau h\u1ecdc t\u1eadp c\u1ee5 th\u1ec3 v\u00e0 \u0111\u1ea1t \u0111\u01b0\u1ee3c ch\u00fang: Khi b\u1ea1n \u0111\u1ea1t \u0111\u01b0\u1ee3c m\u1ee5c ti\u00eau, n\u00e3o b\u1ed9 s\u1ebd gi\u1ea3i ph\u00f3ng dopamine, t\u1ea1o \u0111\u1ed9ng l\u1ef1c cho b\u1ea1n ti\u1ebfp t\u1ee5c h\u1ecdc t\u1eadp.</li> <li>H\u1ecdc t\u1eadp theo nh\u00f3m ho\u1eb7c tham gia c\u00e1c ho\u1ea1t \u0111\u1ed9ng h\u1ecdc t\u1eadp th\u00fa v\u1ecb: H\u1ecdc t\u1eadp c\u00f9ng v\u1edbi b\u1ea1n b\u00e8 ho\u1eb7c tham gia c\u00e1c ho\u1ea1t \u0111\u1ed9ng h\u1ecdc t\u1eadp th\u00fa v\u1ecb s\u1ebd gi\u00fap b\u1ea1n c\u1ea3m th\u1ea5y h\u1ee9ng th\u00fa v\u00e0 vui v\u1ebb h\u01a1n, t\u1eeb \u0111\u00f3 t\u0103ng c\u01b0\u1eddng dopamine.</li> <li>S\u1eed d\u1ee5ng c\u00e1c ph\u01b0\u01a1ng ph\u00e1p h\u1ecdc t\u1eadp hi\u1ec7u qu\u1ea3: Khi b\u1ea1n h\u1ecdc t\u1eadp hi\u1ec7u qu\u1ea3, b\u1ea1n s\u1ebd c\u1ea3m th\u1ea5y t\u1ef1 tin v\u00e0 \u0111\u1ea1t \u0111\u01b0\u1ee3c k\u1ebft qu\u1ea3 t\u1ed1t h\u01a1n, t\u1eeb \u0111\u00f3 t\u0103ng c\u01b0\u1eddng dopamine.</li> <li>Ng\u1ee7 \u0111\u1ee7 gi\u1ea5c v\u00e0 t\u1eadp th\u1ec3 d\u1ee5c th\u01b0\u1eddng xuy\u00ean: Gi\u1ea5c ng\u1ee7 v\u00e0 t\u1eadp th\u1ec3 d\u1ee5c gi\u00fap n\u00e3o b\u1ed9 s\u1ea3n xu\u1ea5t dopamine m\u1ed9t c\u00e1ch t\u1ef1 nhi\u00ean.      </li> </ul> Serotonin? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Serotonin l\u00e0 m\u1ed9t ch\u1ea5t d\u1eabn truy\u1ec1n th\u1ea7n kinh quan tr\u1ecdng, \u0111\u00f3ng vai tr\u00f2 then ch\u1ed1t trong vi\u1ec7c \u0111i\u1ec1u ch\u1ec9nh t\u00e2m tr\u1ea1ng, gi\u1ea5c ng\u1ee7, s\u1ef1 th\u00e8m \u0103n, h\u1ed7 tr\u1ee3 ti\u00eau ho\u00e1 v\u00e0 \u0111\u00f4ng m\u00e1u.</p> <p>Serotonin c\u0169ng c\u00f3 t\u00e1c \u0111\u1ed9ng \u0111\u1ebfn cu\u1ed9c s\u1ed1ng x\u00e3 h\u1ed9i.</p> <p>Kh\u1ec9 \u0111\u1ea7u \u0111\u00e0n c\u00f3 m\u1ee9c Serotonin cao nh\u1ea5t, nh\u1eefng con kh\u1ec9 \u1edf th\u1ee9 h\u1ea1ng th\u1ea5p c\u00f3 m\u1ee9c Serotonin th\u1ea5p nh\u1ea5t</p> <p>Serotonin c\u0169ng li\u00ean quan \u0111\u1ebfn h\u00e0nh vi li\u1ec1u l\u0129nh.</p> <p>Nh\u1eefng con kh\u1ec9 v\u1edbi m\u1ee9c Serotonin th\u1ea5p th\u01b0\u1eddng c\u00f3 nhi\u1ec1u h\u00e0nh vi li\u1ec1u l\u0129nh h\u01a1n nh\u01b0ng con c\u00f3 m\u1ee9c Serotonin cao</p> <p>Nh\u1eefng t\u00f9 nh\u00e2n v\u00ec t\u1ed9i b\u1ea1o l\u1ef1c th\u01b0\u1eddng c\u00f3 m\u1ee9c \u0111\u1ed9 Serotonin th\u1ea5p nh\u1ea5t trong x\u00e3 h\u1ed9i</p> T\u0103ng c\u01b0\u1eddng Serotonin m\u1ed9t c\u00e1ch t\u1ef1 nhi\u00ean? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <ul> <li>Ti\u1ebfp x\u00fac v\u1edbi \u00e1nh s\u00e1ng m\u1eb7t tr\u1eddi: \u00c1nh s\u00e1ng m\u1eb7t tr\u1eddi gi\u00fap c\u01a1 th\u1ec3 s\u1ea3n xu\u1ea5t serotonin. H\u00e3y d\u00e0nh th\u1eddi gian m\u1ed7i ng\u00e0y \u0111\u1ec3 ra ngo\u00e0i tr\u1eddi v\u00e0 t\u1eadn h\u01b0\u1edfng \u00e1nh n\u1eafng.</li> <li>T\u1eadp th\u1ec3 d\u1ee5c th\u01b0\u1eddng xuy\u00ean: Ho\u1ea1t \u0111\u1ed9ng th\u1ec3 ch\u1ea5t gi\u00fap t\u0103ng c\u01b0\u1eddng s\u1ea3n xu\u1ea5t serotonin v\u00e0 c\u1ea3i thi\u1ec7n t\u00e2m tr\u1ea1ng.</li> <li>Ch\u1ebf \u0111\u1ed9 \u0103n u\u1ed1ng l\u00e0nh m\u1ea1nh: \u0102n c\u00e1c th\u1ef1c ph\u1ea9m gi\u00e0u tryptophan, m\u1ed9t lo\u1ea1i axit amin c\u1ea7n thi\u1ebft \u0111\u1ec3 s\u1ea3n xu\u1ea5t serotonin, nh\u01b0 th\u1ecbt, c\u00e1, tr\u1ee9ng, s\u1eefa, c\u00e1c lo\u1ea1i h\u1ea1t v\u00e0 \u0111\u1eadu.</li> <li>Thi\u1ec1n \u0111\u1ecbnh v\u00e0 th\u01b0 gi\u00e3n: C\u00e1c k\u1ef9 thu\u1eadt th\u01b0 gi\u00e3n nh\u01b0 thi\u1ec1n \u0111\u1ecbnh, yoga, h\u00edt th\u1edf s\u00e2u c\u00f3 th\u1ec3 gi\u00fap t\u0103ng c\u01b0\u1eddng serotonin v\u00e0 gi\u1ea3m c\u0103ng th\u1eb3ng.</li> </ul> H\u1ed9i ch\u1ee9ng Anhedonia? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Anhedonia l\u00e0 thu\u1eadt ng\u1eef d\u00f9ng \u0111\u1ec3 m\u00f4 t\u1ea3 s\u1ef1 m\u1ea5t h\u1ee9ng th\u00fa v\u1edbi cu\u1ed9c s\u1ed1ng, c\u00e1c ho\u1ea1t \u0111\u1ed9ng c\u00e1 nh\u00e2n t\u1eebng y\u00eau th\u00edch, \u0111\u1ed3ng th\u1eddi gi\u1ea3m kh\u1ea3 n\u0103ng c\u1ea3m nh\u1eadn ni\u1ec1m vui t\u1eeb ho\u1ea1t \u0111\u1ed9ng h\u00e0ng ng\u00e0y. Anhedonia c\u0169ng l\u00e0 m\u1ed9t trong nh\u1eefng tri\u1ec7u ch\u1ee9ng kh\u00e1 ph\u1ed5 bi\u1ebfn, c\u1ed1t l\u00f5i c\u1ee7a b\u1ec7nh r\u1ed1i lo\u1ea1n tr\u1ea7m c\u1ea3m th\u1ec3 n\u1eb7ng.</p> <p>Anhedonia l\u00e0 m\u1ed9t tri\u1ec7u ch\u1ee9ng c\u1ed1t l\u00f5i c\u1ee7a b\u1ec7nh tr\u1ea7m c\u1ea3m v\u00e0 b\u1ec7nh t\u00e2m th\u1ea7n ph\u00e2n li\u1ec7t. Tuy nhi\u00ean, \u0111\u00f4i khi c\u0169ng c\u00f3 m\u1ed9t v\u00e0i tr\u01b0\u1eddng h\u1ee3p b\u1ec7nh nh\u00e2n ph\u1ea3i \u0111\u1ed1i m\u1eb7t v\u1edbi c\u01a1n \u0111au m\u00e3n t\u00ednh v\u00e0 b\u1ec7nh Parkinson c\u00f3 li\u00ean quan \u0111\u1ebfn Anhedonia. B\u00ean c\u1ea1nh \u0111\u00f3, Anhedonia c\u00f3 th\u1ec3 xu\u1ea5t hi\u1ec7n do l\u1ea1m d\u1ee5ng ch\u1ea5t k\u00edch th\u00edch qu\u00e1 nhi\u1ec1</p> H\u1ed9i ch\u1ee9ng Catatonia? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Catatonia l\u00e0 m\u1ed9t d\u1ea1ng r\u1ed1i lo\u1ea1n t\u00e2m th\u1ea7n \u1ea3nh h\u01b0\u1edfng tr\u1ef1c ti\u1ebfp \u0111\u1ebfn ch\u1ee9c n\u0103ng v\u1eadn \u0111\u1ed9ng c\u1ee7a ng\u01b0\u1eddi b\u1ec7nh. V\u1ea5n \u0111\u1ec1 s\u1ee9c kh\u1ecfe n\u00e0y c\u00f2n \u0111\u01b0\u1ee3c bi\u1ebft \u0111\u1ebfn v\u1edbi t\u00ean g\u1ecdi th\u1ee9 hai l\u00e0 h\u1ed9i ch\u1ee9ng c\u0103ng tr\u01b0\u01a1ng l\u1ef1c. </p> <p>B\u1ec7nh xu\u1ea5t hi\u1ec7n theo c\u01a1n ho\u1eb7c t\u1eebng \u0111\u1ee3t. Nghi\u00ean c\u1ee9u cho th\u1ea5y th\u1eddi gian k\u00e9o d\u00e0i c\u1ee7a m\u1ed7i \u0111\u1ee3t c\u00f3 th\u1ec3 t\u1eeb v\u00e0i gi\u1edd \u0111\u1ebfn c\u1ea3 ch\u1ee5c ng\u00e0y.</p> <p>Catatonia c\u0169ng c\u00f3 th\u1ec3 kh\u1edfi ph\u00e1t n\u1ebfu c\u00f3 s\u1ef1 b\u1ea5t th\u01b0\u1eddng trong c\u1ea5u tr\u00fac v\u00e0 ho\u1ea1t \u0111\u1ed9ng c\u1ee7a h\u1ec7 th\u1ed1ng d\u1eabn truy\u1ec1n th\u1ea7n kinh glutamate, axit gamma-aminobutyric (GABA) v\u00e0 dopamine. </p> Th\u01b0 vi\u1ec7n tr\u00ed tu\u1ec7 Chunks? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>V\u1ec1 c\u01a1 b\u1ea3n, ph\u01b0\u01a1ng ph\u00e1p \u0111\u1ec3 t\u0103ng c\u01b0\u1eddng ki\u1ebfn th\u1ee9c v\u00e0 k\u1ef9 n\u0103ng, l\u00e0 x\u00e2y d\u1ef1ng d\u1ea7n d\u1ea7n s\u1ed1 l\u01b0\u1ee3ng c\u00e1c Chunk \u00fd t\u01b0\u1edfng trong \u0111\u1ea7u, c\u00e1c m\u1ea3ng th\u00f4ng tin qu\u00fd gi\u00e1 m\u00e0 ng\u01b0\u1eddi ta c\u00f3 th\u1ec3 k\u1ebft n\u1ed1i v\u1edbi nhau theo c\u00e1c c\u00e1ch m\u1edbi v\u00e0 s\u00e1ng t\u1ea1o.</p> <p>Th\u01b0 vi\u1ec7n tr\u00ed tu\u1ec7 ph\u00e2n theo Chunk c\u1ee7a b\u1ea1n c\u00e0ng l\u1edbn v\u00e0 c\u00e0ng \u0111\u01b0\u1ee3c th\u1ef1c h\u00e0nh nhi\u1ec1u, b\u1ea5t k\u1ec3 b\u1ea1n \u0111ang h\u1ecdc m\u00f4n g\u00ec, th\u00ec b\u1ea1n s\u1ebd c\u00e0ng c\u00f3 kh\u1ea3 n\u0103ng gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 v\u00e0 t\u00ecm ra gi\u1ea3i ph\u00e1p. </p> <p>\u0110\u1ea1i k\u1ef3 th\u1ee7 c\u1edd t\u01b0\u1edbng c\u00f3 th\u1ec3 d\u1ec5 d\u00e0ng truy c\u1eadp h\u00e0ng ng\u00e0n c\u00e1ch \u0111\u00e1nh c\u1edd kh\u00e1c nhau</p> <p>Nh\u1ea1c s\u0129/nh\u00e0 ng\u00f4n ng\u1eef h\u1ecdc/nh\u00e0 khoa h\u1ecdc c\u00f3 th\u1ec3 d\u1ec5 d\u00e0ng truy c\u1eadp c\u00e1c Chunk ki\u1ebfn th\u1ee9c trong l\u0129nh v\u1ef1c c\u1ee7a h\u1ecd</p> S\u1ef1 chuy\u1ec3n giao Chunk l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>C\u00e1c Chunk c\u0169ng gi\u00fap b\u1ea1n hi\u1ec3u nh\u1eefng kh\u00e1i ni\u1ec7m m\u1edbi. \u0110\u00f3 l\u00e0 v\u00ec khi b\u1ea1n \u0111\u00e3 hi\u1ec3u r\u00f5 m\u1ed9t Chunk b\u1ea1n s\u1ebd th\u1ea5y l\u00e0 Chunk \u0111\u00f3 c\u00f3 th\u1ec3 c\u00f3 quan h\u1ec7 v\u1edbi c\u00e1c Chunk t\u01b0\u01a1ng t\u1ef1 m\u1ed9t c\u00e1ch b\u1ea5t ng\u1edd, kh\u00f4ng ch\u1ec9 trong c\u00f9ng l\u0129nh v\u1ef1c, nh\u01b0ng \u1edf c\u1ea3 c\u00e1c l\u0129nh v\u1ef1c r\u1ea5t kh\u00e1c nhau.</p> Overlearning l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Overlearning (h\u1ecdc qu\u00e1 m\u1ee9c) l\u00e0 ti\u1ebfp t\u1ee5c h\u1ecdc ho\u1eb7c th\u1ef1c h\u00e0nh sau khi b\u1ea1n \u0111\u00e3 th\u00e0nh th\u1ea1o nh\u1eefng g\u00ec b\u1ea1n c\u00f3 th\u1ec3 trong bu\u1ed5i h\u1ecdc.</p> <p>TED experts th\u01b0\u1eddng t\u1eadp 70 ti\u1ebfng cho 20 ph\u00fat n\u00f3i</p> <p>Tuy nhi\u00ean, overlearning qu\u00e1 nhi\u1ec1u s\u1ebd t\u1ed1n th\u1eddi gian b\u1edfi v\u00ec khi b\u1ea1n \u0111\u00e3 hi\u1ec3u r\u00f5 m\u1ed9t v\u1ea5n \u0111\u1ec1 th\u00ec \u0111i\u1ec1u \u0111\u00f3 tr\u1edf n\u00ean d\u1ec5 d\u00e0ng, n\u1ebfu b\u1ea1n c\u1ee9 quanh qu\u1ea9n l\u00e0m vi\u1ec7c d\u1ec5 d\u00e0ng th\u00ec b\u1ea1n d\u1ec5 b\u1ecb r\u01a1i v\u00e0o tr\u1ea1ng th\u00e1i \u1ea2o T\u01b0\u1edfng N\u0103ng L\u1ef1c v\u00ec nh\u1eefng vi\u1ec7c d\u1ec5 d\u00e0ng.</p> Deliberate Practice l\u00e0 g\u00ec? C\u1ed1 g\u1eafng nh\u1edb l\u1ea1i tr\u01b0\u1edbc khi xem \u0111\u00e1p \u00e1n <p>Deliberate Practice (th\u1ef1c h\u00e0nh c\u00f3 ch\u1ee7 \u0111\u00edch) l\u00e0 vi\u1ec7c b\u1ea1n t\u1eadp trung v\u00e0o nh\u1eefng vi\u1ec7c kh\u00f3 h\u01a1n.</p>"},{"location":"lhtl/#procrastination-and-memory","title":"Procrastination and Memory","text":""},{"location":"lhtl/#renaissance-learning-and-unlocking-your-potential","title":"Renaissance Learning and Unlocking Your Potential","text":""},{"location":"roadmap/","title":"Your DevSecOps Roadmap: From Beginner to Pro","text":"<p>Alright, let's map out your journey to becoming a top-notch DevSecOps Engineer. This roadmap is designed to be flexible, so we can adjust it based on your progress and interests.</p>"},{"location":"roadmap/#phase-1-foundational-skills-4-6-weeks","title":"Phase 1: Foundational Skills (4-6 Weeks)","text":"<ul> <li>Goal: Build a solid understanding of core concepts.</li> <li>Topics:<ul> <li>Linux Fundamentals: Command line, file system, basic scripting.</li> <li>Networking Basics: TCP/IP, DNS, HTTP.</li> <li>Version Control: Git, GitHub.</li> <li>Introduction to Cloud: AWS fundamentals (EC2, S3, IAM).</li> <li>Basic Scripting: Python or Bash.</li> </ul> </li> <li>Action Items:<ul> <li>Complete online courses (e.g., Linux Academy, A Cloud Guru).</li> <li>Set up a personal GitHub repository.</li> <li>Deploy a simple web application on AWS EC2.</li> </ul> </li> </ul>"},{"location":"roadmap/#phase-2-containerization-automation-6-8-weeks","title":"Phase 2: Containerization &amp; Automation (6-8 Weeks)","text":"<ul> <li>Goal: Master containerization and automation tools.</li> <li>Topics:<ul> <li>Docker: Containerization, Dockerfiles, Docker Compose.</li> <li>Kubernetes: Orchestration, deployments, services.</li> <li>Infrastructure as Code (IaC): Terraform or CloudFormation.</li> <li>CI/CD Basics: Jenkins or GitHub Actions.</li> <li>Automation: Ansible.</li> </ul> </li> <li>Action Items:<ul> <li>Build and deploy a containerized application on Kubernetes.</li> <li>Automate infrastructure deployment with Terraform.</li> <li>Create a basic CI/CD pipeline.</li> </ul> </li> </ul>"},{"location":"roadmap/#phase-3-devsecops-security-8-10-weeks","title":"Phase 3: DevSecOps &amp; Security (8-10 Weeks)","text":"<ul> <li>Goal: Integrate security into the development lifecycle.</li> <li>Topics:<ul> <li>Security Best Practices: SAST, DAST, vulnerability scanning.</li> <li>IAM &amp; Access Control: AWS IAM, security groups.</li> <li>Compliance: ISO 27001, SOC 2 basics.</li> <li>Monitoring &amp; Logging: Datadog, CloudWatch.</li> <li>Secrets management: Hashicorp Vault.</li> </ul> </li> <li>Action Items:<ul> <li>Implement SAST and DAST in your CI/CD pipeline.</li> <li>Configure monitoring and alerting for your applications.</li> <li>Audit your cloud infrastructure for security vulnerabilities.</li> </ul> </li> </ul>"},{"location":"roadmap/#phase-4-advanced-cloud-optimization-ongoing","title":"Phase 4: Advanced Cloud &amp; Optimization (Ongoing)","text":"<ul> <li>Goal: Deepen expertise and optimize performance.</li> <li>Topics:<ul> <li>Advanced AWS Services: ECS, Lambda, API Gateway.</li> <li>Cloud Networking: VPC, Transit Gateway, VPN.</li> <li>Performance Tuning: Application and infrastructure optimization.</li> <li>Data Lakehouse architectures: Databricks, Snowflake.</li> <li>Advanced CI/CD: ArgoCD, advanced GitHub Actions.</li> </ul> </li> <li>Action Items:<ul> <li>Build and deploy serverless applications.</li> <li>Implement advanced networking configurations.</li> <li>Contribute to open-source projects.</li> <li>Pursue AWS certifications (Solutions Architect, DevOps Engineer).</li> </ul> </li> </ul>"},{"location":"roadmap/#key-milestones","title":"Key Milestones","text":"<ul> <li>3 Months: Deploy a fully automated application on Kubernetes.</li> <li>6 Months: Implement a secure CI/CD pipeline with SAST and DAST.</li> <li>12 Months: Achieve AWS Certified Solutions Architect - Associate certification.</li> </ul>"},{"location":"roadmap/#continuous-learning","title":"Continuous Learning","text":"<ul> <li>Stay updated with industry trends through blogs, podcasts, and conferences.</li> <li>Join online communities and forums.</li> <li>Experiment with new tools and technologies.</li> <li>Build a home lab.</li> </ul> <p>Let's begin. What phase are you currently in, and what are your immediate goals?</p>"},{"location":"english/business-english/","title":"Business English","text":""},{"location":"english/business-english/#learn-how-to-introduce-yourself-in-a-business-setting","title":"Learn how to introduce yourself in a business setting","text":""},{"location":"english/business-english/#informal-greeting","title":"Informal greeting","text":"<p>Hello! You must be Sue. We've spoken through email before I think. I'm Raj Joshi.</p> <p>Yeah! That's right. Nice to meet you, Raj.</p> <p>Same here. So, which department are you in, Sue?</p> <p>I'm in the Legal department which is on this level. What about you?</p> <p>Uh yes, I remember that from your email now. I'm in the marketing department which is on level one.</p> <p>Oh, I see. That's good to know. Should we get ready for the meeting now?</p> <p>Yeah sure.</p> <p>Hello! You must be _________?</p> <p>If you already know who someone is but you have never actually met them.</p> <p>Hello! You must be Codey</p> <p>Yeah that's right. Nice to meet you.</p> <p>Good to meet you.</p> <p>Lovely to meet you.</p> <p>Nice to meet you, [Firstname].</p> <p>Nice to meet you, Andy.</p> <p>It's good to meet you too, [Firstname].</p> <p>It's good to meet you too, Bob.</p> <p>Lovely to meet you, [Firstname].</p> <p>Lovely to meet you, Sue.</p> <p>It's nice to meet you, [Firstname].</p> <p>It's nice to meet you, Josh.</p>"},{"location":"english/business-english/#formal-greeting-with-new-client","title":"Formal greeting (with new client)","text":"<p>\"Good morning, Mr. Wilson.\"</p> <p>\"Good morning, Mr. Joshi. Pleased to meet you.\"</p> <p>\"Me too. Let me introduce myself. I'm Raj Joshi. I'm from ABC Worldwide. I work in the Marketing department and this is my colleague Sue Long from the Legal department.\"</p> <p>\"Good morning, Mr. Wilson. Lovely to meet you.\"</p> <p>\"What about you, Mr. Wilson?\"</p> <p>\"I'm Andy Wilson. I'm from 123 Enterprises. I'm the managing director of the company\"</p> <p>Good [morning|afternoon|evening], [Mr|Mrs|Dr]. [Lastname]</p> <ul> <li>\"Good morning\" generally after 6am but before 12 noon.</li> <li>\"Good afternoon\" generally after 12 noon but before 5pm.</li> <li>\"Good evening\" generally after 5pm.</li> </ul> <p>Do not say Good night because this is another way to say goodbye.</p> <p><sup>'</sup>Pleased to meet you. Welcome to [Company Name].</p> <p>Let me introduce myself, I'm _________.</p> <p>This is my colleague [Fullname] from the [Department Name] department.</p> <p>These are my colleagues [Fullname 1] and [Fullname 2] from the [Department Name] department.</p>"},{"location":"english/business-english/#learn-about-the-importance-of-small-talk-in-a-business-setting","title":"Learn about the importance of small talk in a business setting","text":"<p>Good morning</p> <p>Good morning</p> <p>How are you doing?</p> <p>Yeah, good thanks.</p> <p>I haven't seen you around before.</p> <p>I'm Sue. I just started a new role. In fact, I just moved here.</p> <p>And so, where did you move from?</p> <p>I'm from Western Australia. Broome actually. Have you been there before? It's a beach town in the Kimberley region. That's in the north west of Australia. Where did you move from?</p> <p>Oh, I see, No, I haven't been there before</p> <p>What about you? Where do you live?</p> <p>What do you like to do when you're not working?</p> <p>Well, I love to play sports. </p> <p>Ah, right</p> <p>Mainly footy but I'm learning to play cricket.</p> <p>That's cool.</p> <p>I also love to cook and watch TV shows about traveling.</p> <p>Ah, I see.</p> <p>What about you?</p> <p>I just love watching TV shows.</p>"},{"location":"english/business-english/#asking-about-hobbies-and-interests","title":"Asking about hobbies and interests","text":"<p>What do you like to do when you're not working?</p> <p>What do you like to do in your free time?</p> <p>What do you do outside of work?</p> <p>What do you do for fun?</p>"},{"location":"english/business-english/#fillers","title":"Fillers","text":"<p>Ah right</p> <p>That's cool</p> <p>Wow!</p> <p>Yeah</p> <p>I see</p> Negative Neutral Yeah, nah Uh huh Really? Ah Right Oh Huh Yeah Right"},{"location":"english/business-english/#learn-to-explain-data-and-trends-in-english","title":"Learn to explain data and trends in English","text":"<pre><code>xychart-beta\n    title \"Avacado Sales 2000-2010\"\n    x-axis [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010]\n    y-axis \"Revenue (in $)\" 4000 --&gt; 17000\n    line [5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000]</code></pre> <p>The first graph shows that over a 10-year period, avacado sales increased. </p> <pre><code>xychart-beta\n    title \"Avacado Sales 2010-now\"\n    x-axis [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, now]\n    y-axis \"Revenue (in $)\" 4000 --&gt; 17000\n    line [5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000]\n    line [10000, 10000, 10000, 10000, 10000, 10000, 9000, 8000, 7000, 6000, 5000, 4000, 2000]</code></pre> <p>The next graph shows from 2010 until now. The total sales is a red line while the blue line shows a number of retailers.</p> <p>Sales have increased every year for the last three years but the number of retailers has fallen dramatically in the last year.</p> <p>Hi, Andy, thank you for sending us the data analysis. I was wondering if you could take us through some of the key points</p> <p>Yes, certainly. So I did some profit analysis. I predict the profit will continue to fall over the next three quarters. But we should not be alarmed by this decline.</p> <p>Okay, but why do you say that?</p> <p>Well, that's because we project sales are going to increase in the coming months.</p> <p>And what's driving that?</p> <p>Well as we are going into the holidays, spending will raise and therefore, there will be a jump in sales.</p> <p>That's good news then looking at these figures I was expecting sales to go down further.</p> <p>Not at all. The forecast suggests the company will grow strongly over the next few years.</p> Going up Going down Rise Fall Jump Drop Grow Decline Climb Decrease Increase Go down Rocket Plummet <p>to project</p> <p>To guess something based on data or trends.</p> <p>to predict</p> <p>To guess something will happen.</p> <p>to forcast</p> <p>To guess something, usually based on studyingj or analysing previous data.</p> <p>going to</p> <p>To talk about predictions based on evidence.</p> <p>will</p> <p>To talk about predictions based on opinion.</p>"},{"location":"english/business-english/#learn-how-to-negotiate-in-a-business-setting","title":"Learn how to negotiate in a business setting","text":""},{"location":"english/business-english/#question-tag","title":"Question tag","text":""},{"location":"english/business-english/#auxiliary-verb-or-modal-verb-of-the-main-sentence-subject-of-the-sentence","title":"Auxiliary verb or modal verb of the main sentence + subject of the sentence.","text":"<ul> <li>If the sentence is a positive, the question tag must be negative.</li> </ul> <p>The process takes around 6 months, doesn't it?</p> <ul> <li>If the sentence is a negative, the question tag must be positive.</li> </ul> <p>You don't have a problem with that, do you?</p> <p>Let's get down to business, shall we?</p> <p>Don't you?</p> <p>Aren't you?</p> <p>So I think that's the final deal, isn't it?</p> <p>Haven't you?</p> <p>Can't you?</p>"},{"location":"english/business-english/#answering-the-question-tag","title":"Answering the question tag","text":"<p>Agree or disagree on the original statement, not the question.</p> <p>We are studying English, aren't we?</p> <p>Yes, we are.</p> <p>This is a conversation English course, itn't it?</p> <p>No, it's a business English course.</p> <p>Tag questions are useful for negotiations, aren't they?</p> <p>Yes, they are.</p>"},{"location":"english/business-english/#common-phrases-and-words-in-negotiations","title":"Common phrases and words in negotiations","text":"<p>Bottom line (noun)</p> <p>The important fact in this situation.</p> <p>Compromise (verb)</p> <p>To change your mind slightly to reach an agreement.</p> <p>Push back (verb)</p> <p>Disagree.</p> <p>Counter proposal (noun)</p> <p>The second offer which is given in reply to the first offer.</p> <p>Point of view (noun)</p> <p>A person's thoughts or ideas.</p> <p>Comply (verb)</p> <p>To agree.</p> <p>Deadlock (noun)</p> <p>A point in the negotiation where no side will change their mind.</p> <p>Mutual (adjective)</p> <p>Agreed by everyone.</p> <p>Trade-off (noun)</p> <p>Something that we give away to get another thing.</p>"},{"location":"english/business-english/#learn-how-to-prepare-for-an-interview","title":"Learn how to prepare for an interview","text":"<p>Good afternoon. You're Raj right?</p> <p>Yes, good afternoon Mr. Wilson. How are you?</p> <p>Good thanks. What about you Raj?</p> <p>I'm good thank you. I'm realy excited to be speaking with you today. Thank you so much for the opportunity.</p> <p>My pleasure. Let's get started. Can you tell me a bit about yourself?</p> <p>Yes, sure. I'm from Malaysia. I've been living in Australia for four years now. I came here to study at university. Since I graduated I've been working for the local city council.</p>"},{"location":"english/business-english/#intonation","title":"Intonation","text":""},{"location":"english/business-english/#rising-intonation-for-yesno-questions","title":"Rising intonation for yes/no questions.","text":"<p>Did you get here ok?</p> <p>Do you have the necessary documents on you?</p> <p>Do you know much about the company?</p> <p>Rising intonation shows the listener you're feeling positive about what you're saying. Use our voice up at the end of a word</p> <p>Sure</p>"},{"location":"english/business-english/#falling-intonation-for-questions-where-were-asking-for-more-information","title":"Falling intonation for questions where we're asking for more information.","text":"<p>Can you tell me a bit about your experience?</p> <p>Why did you apply for this role?</p> <p>What do you bring to this role?</p>"},{"location":"english/business-english/#use-past-simple-and-present-perfect-continuous-tense-in-an-interview","title":"Use past simple and present perfect continuous tense in an interview","text":"<p>Present perfect continuous: Have been + verb-ing     Talk about something that started in the past and is still happening now</p> <p>I have been living</p> <p>I have been working</p> <p>Past simple: </p> <p>Since I graduated. I have been working</p>"},{"location":"english/devops-vocabulary/","title":"DevOps Vocabulary","text":""},{"location":"english/devops-vocabulary/#how-to-build-vocabulary","title":"How to build vocabulary?","text":"<ol> <li>Write the meaning in English.</li> <li>Use a word in a sentence.</li> <li>Learn other forms of the word.</li> <li>Learn the pronunciation.</li> <li>Learn colocations.</li> </ol>"},{"location":"english/fluency/","title":"Learn how to learn English fluency","text":"<p>Fluency is also about using the language in creative ways. You can:</p> <ul> <li>Write a short story.</li> <li>Sing a song.</li> <li>Make a video.</li> <li>Teaching others.</li> </ul> <p>Everyday!</p>"},{"location":"library/cm/","title":"CM","text":""},{"location":"library/iac/","title":"IaC","text":"Lifecycle Management terraform init <p>Initializes a working directory containing Terraform configuration files.</p> terraform plan <p>Creates an execution1 plan, showing what changes Terraform will make.</p> terraform apply <p>Executes the actions proposed in a Terraform plan.</p> terraform destroy <p>Destroys Terraform-managed infrastructure.</p> State Management terraform state list <p>Lists resources currently tracked in the Terraform state.</p> terraform state show  <p>Shows the attributes of a specific resource in the state.</p> terraform state mv  <p>Moves an item in the state to a new address.</p> terraform state rm  <p>Removes an item from the state.</p> terraform state pull <p>Downloads the state file from the remote backend.</p> terraform state push  <p>Uploads a local state file to the remote backend.</p> Formatting and Validation terraform fmt <p>Reformats Terraform configuration files to a canonical style.</p> terraform validate <p>Validates the syntax of Terraform configuration files.</p> Module Management terraform get <p>Downloads and updates modules defined in the configuration.</p> terraform providers <p>Displays information about the providers used in the current configuration.</p> Workspace Management terraform workspace list <p>Lists existing Terraform workspaces.</p> terraform workspace show <p>Shows the currently selected workspace.</p> terraform workspace select  <p>Selects an existing workspace.</p> terraform workspace new  <p>Creates a new workspace.</p> terraform workspace delete  <p>Deletes a workspace.</p> Output and Import terraform output <p>Shows the output values from the Terraform state.</p> terraform import  <p>Imports an existing resource into Terraform management.</p> Other Useful Commands terraform version <p>Shows the installed Terraform version.</p> terraform console <p>Opens an interactive console for evaluating Terraform expressions.</p> terraform taint  <p>Marks a resource as tainted, forcing its replacement on the next apply.</p> terraform untaint  <p>Removes the tainted status from a resource.</p> terraform debug <p>Enables debug logging.</p>"},{"location":"library/linux/","title":"Linux","text":"Navigation &amp; Basics Commands man cd pwd ls tree Moving Files/Dirs mv <pre><code>mv [option] source destination\n</code></pre> Creating Files/Dirs touch <pre><code>touch newfile.txt\n</code></pre> cat <pre><code>cat &gt; newfile.txt\n</code></pre> echo <pre><code>echo \"hello world!\" &gt; newfile.txt\n</code></pre> mkdir Deleting Files/Dirs rm <pre><code>rm unwantedfile.txt\nrm -i unwantedfile.txt # (1)!\n</code></pre> <ol> <li> <code>rm -i</code> (interactive) to ask for confirmation before deleting.</li> </ol> rmdir <p><code>rm [empty dir]</code></p> Filesystem Hierarchy Standard (FHS) / <p>Root dir, the top level of the file system</p> /home <p>User home dirs</p> /bin <p>Essential binary executables</p> /sbin <p>System administration binaries</p> /etc <p>Configuration files</p> /var <p>Variable data (logs, spool files)</p> /usr <p>User programs and data</p> /lib <p>Shared libraries</p> /tmp <p>Temporary files</p> Editing Files vim <p><pre><code>vim example.txt\n</code></pre> To insert new content, press <code>i</code> for 'insert mode'. After editing, press <code>ESC</code> to go back to 'command mode', and type <code>:wq</code> to save and quit.</p> nano <p><pre><code>nano exmaple.txt\n</code></pre> Installation for Ubuntu based distributions <pre><code>sudo apt update\nsudo apt installl nano\n</code></pre> Installation for Arch Linux <pre><code>sudo pacman -S nano\n</code></pre></p> Linux Shell Basics Command Path in Shell <p>In Linux, the command path is an important concept under shell basics. Simply put, command path is a variable that is used by the shell to determine where to look for the executable files to run. Linux commands are nothing but programs residing in particular directories. But, one does not have to navigate to these directories every time to run these programs. The command path comes to the rescue!</p> <p>Usually, when you type a command in the terminal, the shell needs to know the absolute path of the command's executable to run it. Instead of typing the full path each time, command paths allow the shell to automatically search the indicated directories in the correct order. These paths are stored in the $PATH environment variable. <pre><code>echo $PATH\n</code></pre></p> <p>[Mini-Project] What happen when you type a Linux command?</p> Environment Variables under Shell <p>List all the environment Variables <pre><code>env\n</code></pre></p> <p>Remember, every shell, such as Bourne shell, C shell, or Korn shell in Unix or Linux has different syntax and semantics to define and use environment variables.</p> Command Help <p>To view the manual entry for any command <pre><code>man [command]\n</code></pre> For built-in shell functions <pre><code>help [command]\n</code></pre> To view examples with TLDR <pre><code>tldr [command]\n</code></pre></p> Redirects in Shell <p>The shell in Linux provides a robust way of managing input and output streams of a command or program, this mechanism is known as Redirection. Linux being a multi-user and multi-tasking operating system, every process typically has 3 streams opened:</p> <ul> <li>Standard Input (stdin) - This is where the process reads its input from. The default is the keyboard.</li> <li>Standard Output (stdout) - The process writes its output to stdout. By default, this means the terminal.</li> <li>Standard Error (stderr) - The process writes error messages to stderr. This also goes to the terminal by default.</li> </ul> <p>Redirection in Linux allows us to manipulate these streams, advancing the flexibility with which commands or programs are run. Besides the default devices (keyboard for input and terminal for output), the I/O streams can be redirected to files or other devices.</p> <p>If you want to store the output of a command into a file instead of printing it to the console, we can use the <code>&gt;</code> operator.</p> <p><pre><code>ls -al &gt; file_list.txt\n</code></pre> This command will write the output of <code>ls -al</code> into <code>file_list.txt</code>, whether or not the file initially existed. It will be created if necessary, and if it already exists - it will be overwritten.</p> Super User <p>The Super User, also known as \u201croot user\u201d, represents a user account in Linux with extensive powers, privileges, and capabilities. This user has complete control over the system and can access any data stored on it. This includes the ability to modify system configurations, change other user\u2019s passwords, install software, and perform more administrative tasks in the shell environment.</p> <p>Switches the current user to the root <pre><code>su -\n</code></pre> Allows you to run a command as another user, default being root <pre><code>sudo [commmand]\n</code></pre></p> <p>Super User privileges should be handled with care due to their potential to disrupt the system\u2019s functionality. Mistaken changes to key system files or unauthorized access can lead to severe issues.</p> Working with Files <p>In Linux, everything is considered a file: texts, images, systems, devices, and directories.</p> Linux File Permissions -rwxr--r-- 1 root root 4096 Jan 1 12:00 filename <ul> <li>The first character: <code>-</code> for a file, <code>d</code> for a dir.</li> <li>The first group of three characters: represents the permissions for the owner. (<code>rwx</code>)</li> <li>The next group of three characters: represents the permissions for the group. (<code>r--</code>)</li> <li>The last group of three characters: represents the permission for the others. (<code>r--</code>)</li> </ul> <p>The <code>r</code> indicates that the file can be read, <code>w</code> indicates that the file can be written to, and <code>x</code> indicates that the file can be executed.</p> chmod chown chgrp Archiving &amp; Compression <p>In Linux, archiving and compression are separate processes, hence tar to archive and gzip/bzip2 to compress. Although they\u2019re commonly used together, they can very much be used separately as per the requirements.</p> <p>Create a tar archive <pre><code>tar cvf archive_name.tar dir_to_archive/\n</code></pre> Extract a tar archive <pre><code>tar xvf archive_name.tar\n</code></pre> Create a gzip compressed tar archive <pre><code>tar cvzf archive_name.tar.gz dir_to_archive/\n</code></pre> Create a bzip2 compressed tar archive <pre><code>tar cvjf archive_name.tar.bz2 dir_to_archive/\n</code></pre></p> Copying &amp; Renaming Files <p>To copy files <pre><code>cp /path/to/original/file /path/to/copied/file\n</code></pre> To rename files <pre><code>mv /path/to/original/file /path/to/new/file\n</code></pre></p> Soft &amp; Hard Links <p>A hard link is a mirror reflection of the original file, sharing the same file data and inode number, but displaying a different name. It\u2019s vital to note that if the original file is deleted, the hard link still retains the file data. <pre><code>ln source_file.txt hard_link.txt\n</code></pre> A soft link, also known as a symbolic link, is more like a shortcut to the original file. It has a different inode number and the file data resides only in the original file. If the original file is removed, the symbolic link breaks and will not work until the original file is restored. <pre><code>ln -s source_file.txt soft_link.txt\n</code></pre></p> Text Processing awk <p><code>awk</code> is adept at performing operations upon text files, such as sorting, filtering, and report generation.</p> <p>The language comprises a set of commands within a script that define pattern-action pairs. Essentially, awk reads an input file line by line, identifies patterns that match what is specified in the script, and consequently executes actions upon those matches. <pre><code>awk '{pattern-action pairs}' [filename]\n</code></pre></p> <p>awk {print $1,$2}' file.txt</p> <p>cat file.txt<pre><code>file.txt file2.txt file3.txt\ndir.txt dir2.txt dir3.txt\ndrive.txt drive2.txt drive3.txt\nport.txt port2.txt port3.txt\n</code></pre> awk '{print $1,$2}' file.txt<pre><code>file.txt file2.txt\ndir.txt dir2.txt\ndrive.txt drive2.txt\nport.txt port2.txt\n</code></pre> This would display the first and second field (typically separated by spaces) of every line in <code>file.txt</code>.</p> grep <p>GREP (Global Regular Expression Print) is considered a significant tool in text processing area on Unix-like operating systems including Linux. It is a powerful utility that searches and filters text matching a given pattern. When it identifies a line that matches the pattern, it prints the line to the screen, offering an effective and a codified way to find text within files. <pre><code>grep \"pattern\" [filename]\n</code></pre></p> <p>grep 'e.txt' file.txt</p> <p>cat file.txt<pre><code>file.txt\ndir.txt\ndrive.txt\nport.txt\n</code></pre> grep 'e.txt' file.txt<pre><code>file.txt\ndrive.txt\n</code></pre> This command will search for the specified pattern within the file and prints the line to the terminal.</p> ripgrep <p>There is also an alternative to <code>grep</code> - <code>ripgrep</code>.</p> <p><code>ripgrep</code> is an extremely fast text processor that supports all the features of <code>grep</code> and extends it.</p> uniq <p>In Linux, uniq is an extremely useful command-line program for text processing. It aids in the examination and manipulation of text files by comparing or filtering out repeated lines that are adjacent. Whether you\u2019re dealing with a list of data or a large text document, the uniq command allows you to find and filter out duplicate lines, or even provide a count of each unique line in a file. It\u2019s important to remember that uniq only removes duplicates that are next to each other, so to get the most out of this command, data is often sorted using the sort command first. <pre><code>sort [filename] | uniq\n</code></pre></p> <p>sort names.txt | uniq</p> <p><code>names.txt</code> is a file containing a list of names. The <code>sort</code> command sorts all the lines in the file, and then the <code>uniq</code> command removes all the duplicate lines. The resulting output would be a list of unique names from <code>names.txt</code>.</p> unexpand <p>This command works by replacing spaces with tabs, making a document or output more coherent and neat.</p> <p>It is primarily used to format the structure, particularly in programming scripts, where indenting with tabs is a common practice. <pre><code>unexpand [options] [filename]\n</code></pre></p> <p>unexpand -t 4 file.txt</p> <p>The <code>-t 4</code> switch tells <code>unexpand</code> to replace every four spaces in <code>file.txt</code> with a tab.</p> expand <p>It can be an essential tool while working with file outputs where the formatting can get disturbed due to tabs. This can be especially useful when working with Linux shell scripts, where the tab space might differ on different systems or text editors, resulting in inconsistent formatting. Consistent indentation using space can greatly enhance code readability. <pre><code>expand [options] [filename]\n</code></pre></p> <p>expand file.txt</p> <p>The <code>expand</code> command by default converts tabs into 8 spaces.</p> <p>expand -t 4 file.txt</p> <p>Each tab character in file.txt will be replaced with 4 spaces. The output would then be displayed on the console.</p> wc <p>The <code>wc</code> command is a commonly used tool in Unix or Linux that allows users to count the number of bytes, characters, words, and lines in a file or in data piped from standard input. The name <code>wc</code> stands for \u2018word count\u2019, but it can do much more than just count words. Common usage of <code>wc</code> includes tracking program output, counting code lines, and more. It\u2019s an invaluable tool for analyzing text at both granular and larger scales <pre><code>wc [options] [filename]\n</code></pre></p> <p>wc file.txt</p> <p>cat file.txt<pre><code>file.txt\ndir.txt\ndrive.txt\nport.txt\n</code></pre> wc file.txt<pre><code>3  4 35 file.txt\n</code></pre> This command would output the number of lines, words, and characters in <code>file.txt</code>. The output is displayed in the following order: line count, word count, character count, followed by the filename.</p> nl <p><code>nl</code> command in Linux is a utility for numbering lines in a text file. Also known as \u2018number lines\u2019, it can be handy when you need an overview where certain lines in a file are located. By default, nl number the non-empty lines only, but this behavior can be modified based on user\u2019s needs. <pre><code>nl [options] [filename]\n</code></pre></p> <p>nl file.txt</p> <p>cat file.txt<pre><code>file.txt\ndir.txt\ndrive.txt\nport.txt\n</code></pre> nl file.txt<pre><code>    1  file.txt\n    2  dir.txt\n    3  drive.txt\n    4  port.txt\n</code></pre> If no file is specified, <code>nl</code> will wait for input from user\u2019s terminal (stdin). Its clear and readable output makes it a valuable part of any Linux user\u2019s text processing toolkit.</p> tee <p><code>tee</code> command reads from the standard input and writes to standard output and files. This operation gets its name from the T-splitter in plumbing, which splits the flow into two directions, paralleling the function of the tee command. <pre><code>[command] | tee file\n</code></pre></p> <p>ls | tee file.txt</p> <p>ls | tee file.txt<pre><code>file.txt\n</code></pre> cat file.txt<pre><code>file.txt\n</code></pre> <code>ls</code> lists the files in the current directory from which <code>tee</code> reads the output, and <code>file.txt</code> signifies the file where <code>tee</code> writes the output.</p> | <p>The pipe (<code>|</code>) is a powerful feature in Linux used to connect two or more commands together. This mechanism allows output of one command to be \u201cpiped\u201d as input to another. <pre><code>[command 1] | [command 2] | ...\n</code></pre></p> <p>ls | grep '.txt$'</p> <p><code>ls</code> lists the files in the current directory and grep <code>\\.txt$</code> filters out any files that don\u2019t end with <code>.txt</code>. The pipe command, <code>|</code>, takes the output from <code>ls</code> and uses it as the input to grep <code>\\.txt$</code>. The output of the entire command is the list of text files in the current directory.</p> split <p>The <code>split</code> command in Linux divides a file into multiple equal parts, based on the lines or bytes specified by the user. <pre><code>split [options] [input [prefix]]\n</code></pre></p> <p>split bigfile.txt</p> <p>By default, the <code>split</code> command divides the file into smaller files of 1000 lines each. If no input file is provided, or if it is given as <code>-</code>, it reads from standard input.</p> <p>split -l 500 bigfile.txt</p> <p>Split a file named <code>bigfile.txt</code>into files of 500 lines each.</p> join <p><code>join</code> to combine lines of two files on a common field. <pre><code>join [filename_first] [filename_second]\n</code></pre></p> <p>join file1.txt file2.txt</p> <p>cat file1.txt<pre><code>item1 10\nitem2 20\n</code></pre> cat file2.txt<pre><code>item1 10$\nitem2 20$\n</code></pre> join file1.txt file2.txt<pre><code>item1 10 10$\nitem2 20 20$\n</code></pre> If you have two files that have a list of items, one with costs and the other with quantities, you can use join to combine these two files so each item has a cost and quantity on the same line.</p> tail <p>The <code>tail</code> command reads data from standard input or from a file and outputs the last <code>N</code> bytes, lines, blocks, characters or words to the standard output (or a different file). <pre><code>tail [options] [filename]\n</code></pre></p> <p>tail /var/log/syslog</p> <p>By default, the <code>tail</code> command will print the last 10 lines of the <code>/var/log/syslog</code> file.</p> head <p>The <code>tail</code> command reads data from standard input or from a file and outputs the first <code>N</code> bytes, lines, blocks, characters or words to the standard output (or a different file). <pre><code>head [options] [filename]\n</code></pre></p> <p>head /var/log/syslog</p> <p>By default, the <code>head</code> command will print the first 10 lines of the <code>/var/log/syslog</code> file.</p> <p>head -n 5 /var/log/syslog</p> <p>Print the first 5 lines of the <code>/var/log/syslog</code> file.</p> tr <p>The <code>tr</code> command in Linux is a command-line utility that translates or substitutes characters. It reads from the standard input and writes to the standard output. Although commonly used for translation applications, <code>tr</code> has versatile functionality in the text processing aspect of Linux. Ranging from replacing a list of characters, to deleting or squeezing character repetitions, <code>tr</code> presents a robust tool for stream-based text manipulations. <pre><code>[command] | tr [pattern] [new_pattern]\n</code></pre></p> <p>cat file.txt | tr 'a-z' 'A-Z'</p> <p>cat file.txt<pre><code>file.txt file2.txt file3.txt\ndir.txt dir2.txt dir3.txt\ndrive.txt drive2.txt drive3.txt\nport.txt port2.txt port3.txt\n</code></pre> cat file.txt | tr 'a-z' 'A-Z'<pre><code>FILE.TXT FILE2.TXT FILE3.TXT\nDIR.TXT DIR2.TXT DIR3.TXT\nDRIVE.TXT DRIVE2.TXT DRIVE3.TXT\nPORT.TXT PORT2.TXT PORT3.TXT\n</code></pre> <code>tr</code> is used to convert the lowercase in the <code>file.txt</code> to uppercase.</p> sort <p>The <code>sort</code> command in Linux is used to sort the contents of a text file, line by line. The command uses ASCII values to sort files. You can use this command to sort the data in a file in a number of different ways such as alphabetically, numerically, reverse order, or even monthly. The sort command takes a file as input and prints the sorted content on the standard output (screen). <pre><code>sort [options] [filename]\n</code></pre></p> <p>sort file.txt</p> <p>cat file.txt<pre><code>    file.txt file2.txt file3.txt\n    dir.txt dir2.txt dir3.txt\n    drive.txt drive2.txt drive3.txt\n    port.txt port2.txt port3.txt\n</code></pre> sort file.txt<pre><code>    dir.txt dir2.txt dir3.txt\n    drive.txt drive2.txt drive3.txt\n    file.txt file2.txt file3.txt\n    port.txt port2.txt port3.txt\n</code></pre> This command prints the sorted content of the filename.txt file. The original file content remains unchanged.</p> <p>sort file.txt &gt; sorted_file.txt</p> <p>cat file.txt<pre><code>    file.txt file2.txt file3.txt\n    dir.txt dir2.txt dir3.txt\n    drive.txt drive2.txt drive3.txt\n    port.txt port2.txt port3.txt\n</code></pre> sort file.txt &gt; sorted_file.txt<pre><code>\n</code></pre> cat file.txt<pre><code>    file.txt file2.txt file3.txt\n    dir.txt dir2.txt dir3.txt\n    drive.txt drive2.txt drive3.txt\n    port.txt port2.txt port3.txt\n</code></pre> cat sorted_file.txt<pre><code>    dir.txt dir2.txt dir3.txt\n    drive.txt drive2.txt drive3.txt\n    file.txt file2.txt file3.txt\n    port.txt port2.txt port3.txt\n</code></pre></p> paste <p><code>paste</code> is a powerful text processing utility that is primarily used for merging lines from multiple files. It allows users to combine data by columns rather than rows, adding immense flexibility to textual data manipulation. Users can choose a specific delimiter for separating columns, providing a range of ways to format the output. <pre><code>paste [filename_first] [filename_second]\n</code></pre></p> <p>paste file1.txt file2.txt</p> <p>cat file1.txt<pre><code>item1 10\nitem2 20\n</code></pre> cat file2.txt<pre><code>item1 10$\nitem2 20$\n</code></pre> paste file1.txt file2.txt<pre><code>item1 10        item1 10$\nitem2 20        item2 20$\n</code></pre></p> cut <p>The <code>cut</code> command is a text processing utility that allows you to cut out sections of each line from a file or output, and display it on the standard output (usually, the terminal). It\u2019s commonly used in scripts and pipelines, especially for file operations and text manipulation.</p> <p>This command is extremely helpful when you only need certain parts of the file, such as a column, a range of columns, or a specific field. For example, with Linux system logs or CSV files, you might only be interested in certain bits of information. <pre><code>cut OPTION... [FILE]...\n</code></pre></p> <p>echo \"one,two,three,four\" | cut -d \",\" -f 2</p> <p>This command will output the second field (<code>two</code>) by using the comma as a field delimiter (<code>-d \",\"</code>).</p> stdout / stdin / stderr <p>The concepts of stdout and stderr in Linux belong to the fundamentals of Linux text processing. In Linux, when a program is executed, three communication channels are typically opened, namely, STDIN (Standard Input), STDOUT (Standard Output), and STDERR (Standard Error).</p> <p>Each of these channels has a specific function. STDOUT is the channel through which the output from most shell commands is sent. STDERR, on the other hand, is used specifically for sending error messages. This distinction is very useful when scripting or programming, as it allows you to handle normal output and error messages in different manners. <pre><code>[command] &gt; stdout.txt 2&gt; stderr.txt\n</code></pre></p> <p>ls &gt; stdout.txt 2&gt; stderr.txt</p> <p>cat stdout.txt<pre><code>    file1.txt\n    file2.txt\n    file.txt\n    sorted_file.txt\n    stderr.txt\n    stdout.txt\n</code></pre> cat stderr.txt<pre><code>\n</code></pre></p> <p>ls bad-options-blablabla &gt; stdout.txt 2&gt; stderr.txt</p> <p>cat stdout.txt<pre><code>\n</code></pre> cat stderr.txt<pre><code>ls: cannot access 'bad-options-blablabla': No such file or directory\n</code></pre></p> Server Review Uptime Load <p>When managing a Linux server, one critical metric deserving close scrutiny is the \u201cuptime\u201d. The <code>uptime</code> command in Linux gives information about how long the system has been running without shutting down or restarting, and the system load average.</p> <p>The system load average is an important indicator that illustrates the amount of computational work that a computer system performs. It\u2019s a reflection of how many processes are waiting in line to get CPU time. The system load average is typically shown for 1, 5, and 15 minutes durations.</p> <p>By consistently analyzing the uptime and load on a Linux server, administrators can identify system usage patterns, diagnose possible performance issues, and determine an efficient capacity planning strategy. If a server has a high load average, it may suggest that the system resources are not sufficient or are misconfigured, leading to possible slow performance or system unresponsiveness.</p> <p>Uptime and Load</p> <p>uptime<pre><code> 10:58:35 up 2 days, 20 min,  1 user,  load average: 0.00, 0.01, 0.05\n</code></pre> \u201c2 days, 20 min\u201d tells us how long the system has been up, while \u201c0.00, 0.01, 0.05\u201d shows the system\u2019s load average over the last one, five, and fifteen minutes, respectively.</p> Authentication Logs <p>When dealing with a Linux server and its maintenance, one of the most critical components to regularly review is the auth logs. These logs, usually located in <code>/var/log/auth.log</code> (for Debian-based distributions) or <code>/var/log/secure</code> (for Red Hat and CentOS), record all authentication-related events and activities which have occurred on the server. This includes, among others, system logins, password changes, and issued sudo commands.</p> <p>Auth logs are an invaluable tool for monitoring and analyzing the security of your Linux server. They can indicate brute force login attacks, unauthorized access attempts, and any suspicious behavior. Regular analysis of these logs is a fundamental task in ensuring server security and data integrity.</p> <p>View authentication log</p> tail /var/log/auth.log<pre><code>Feb 21 09:28:18 server-prod su: (to root) debian on pts/0\nFeb 21 09:28:18 server-prod su: pam_unix(su:session): session opened for user root by debian(uid=0)\nFeb 21 09:28:18 server-prod sshd[6346]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=18.9.14.18  user=root\nFeb 21 09:28:20 server-prod sshd[6346]: Failed password for root from 18.9.14.18 port 37752 ssh2\nFeb 21 09:28:21 server-prod sshd[6346]: Connection closed by authenticating user root 18.9.14.18 port 37752 [preauth]\nFeb 21 09:28:26 server-prod sshd[6368]: Invalid user bigdata from 18.9.14.18 port 54708\nFeb 21 09:28:27 server-prod sshd[6368]: pam_unix(sshd:auth): check pass; user unknown\nFeb 21 09:28:27 server-prod sshd[6368]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=18.9.14.18 \nFeb 21 09:28:28 server-prod sshd[6368]: Failed password for invalid user bigdata from 18.9.14.18 port 54708 ssh2\nFeb 21 09:28:30 server-prod sshd[6368]: Connection closed by invalid user bigdata 18.9.14.18 port 54708 [preauth]\n</code></pre> Services Running <p>Linux servers are popular for their stability and flexibility, factors that make them a preferred choice for businesses and organizations when it comes to managing various services. Services that run under a Linux server can range from web services to database services, DNS servers, mail servers, and many others.</p> <p>As a Linux system administrator, it\u2019s important to periodically review these running services to manage resources, check their statuses, and troubleshoot issues, ensuring the health and performance of the server.</p> <p>Linux has a variety of tools to achieve this, such as: <code>systemctl</code>, <code>service</code>, <code>netstat</code>, <code>ss</code> and <code>lsof</code>.</p> <p>systemctl --type=service</p> systemctl --type=service<pre><code>    UNIT               LOAD   ACTIVE SUB     DESCRIPTION                                     \n    apparmor.service   loaded active exited  Load AppArmor profiles\n    cron.service       loaded active running Regular background program processing daemon\n    ...                ...    ...    ...     ... \n    unscd.service      loaded active running Name Service Cache  Daemon \n    user@1000.service  loaded active running User Manager for UID 1000\n\n    LOAD   = Reflects whether the unit definition was properly loaded.\n    ACTIVE = The high-level unit activation state, i.e. generalization of SUB.\n    SUB    = The low-level unit activation state, values depend on unit type.\n\n    47 loaded units listed. Pass --all to see loaded but inactive units, too.\n    To show all installed unit files use 'systemctl list-unit-files'.\n</code></pre> Available Memory/Disk free <p>Gives a summary of the overall memory usage including total used and free memory, swap memory and buffer/cache memory.</p> <p>free -h</p> <p>free -h<pre><code>                total       used        free      shared  buff/cache   available\n    Mem:         14Gi      519Mi        11Gi       274Mi       2.4Gi        13Gi\n    Swap:          0B         0B          0B\n</code></pre> the <code>-h</code> option is used to present the results in a human-readable format</p> vmstat top Process Management Background / Foreground Processes <p>In Linux environment, a process can be run in either the foreground (fg) or the background (bg). The foreground process takes input directly from the user, displaying output and errors to the user\u2019s terminal. On the other hand, a background process runs independently of the user\u2019s actions, freeing up the terminal for other tasks.</p> <p>Typically, a process starts in the foreground. However, you can send it to the background by appending an ampersand (<code>&amp;</code>) to the command or by using the <code>bg</code> command. Conversely, the <code>fg</code> command brings a background process to the foreground. send a running process to background<pre><code>[command] &amp;\n</code></pre> if a process is already running<pre><code>CTRL + Z # (1)!\nbg # (2)!\n</code></pre></p> <ol> <li>This will pause the process</li> <li>This resumes the paused process in the background</li> </ol> <p>bring it back to the foreground<pre><code>fg\n</code></pre> These commands, <code>bg</code> and <code>fg</code> are part of job control in Unix-like operating systems, which lets you manage multiple tasks simultaneously from a single terminal</p> Listing / Finding Processes <p>The proc filesystem is an extremely powerful tool in this respect. Available in all Unix-like operating systems, proc is a virtual file system that provides detailed information about running processes, including its PID, status, and resource consumption.</p> <p>With commands like ps, top, and htop, we can quickly list out the running processes on the Linux system. Specifically, the ps command offers an in-depth snapshot of currently running processes, whereas top and htop give real-time views of system performance.</p> <p>ps -ef</p> <p>List all runningj processes.</p> <p>top</p> <p>Display ongoing list of running processes.</p> <p>htop</p> <p><code>top</code> alternatively, for a more user-friendly interface.</p> <p>Exploring the proc directory (/proc), we dive even deeper, enabling us to view the system\u2019s kernel parameters and each process\u2019s specific system details.</p> <p>cat /proc/{PID}/status</p> <p>View specifics of a particular PID</p> Process Signals <p>Process signals are a form of communication mechanism in Unix and Linux systems. They provide a means to notify a process of synchronous or asynchronous events. There are a variety of signals like SIGINT, SIGSTOP, SIGKILL, etc. available which can be sent to a running process to interrupt, pause or terminate it.</p> <p>kill -SIGSTOP {PID}</p> <p>Send a SIGSTOP signal to a process with a PID. This will suspend the execution of the process until a SIGCONT signal is received.</p> Process Priorities <p>In the Linux environment, every running task or essentially a \u201cprocess\u201d is assigned a certain priority level that impacts its execution timing. These priorities are instrumental in efficient system resource utilization, enabling Linux to fine-tune execution and allocate system resources smartly.</p> <p>The Linux kernel sorts processes in the proc structure, typically found under the <code>/proc</code> file system directory. This structure contains information about all active processes, including their priorities. The concept of proc priorities under process management refers to the priority accorded to each process by the system. This priority value (also known as \u201cnice\u201d value) ranges from -20 (highest priority) to +19 (lowest priority).</p> <p>By understanding and managing proc priorities, you can optimize system performance and control which processes receive more or less of the CPU\u2019s attention.</p> <p>View all PIDs with Priorities and Users</p> <p>Display the process ID, priority, and user for all processes. ps -eo pid,pri,user<pre><code>PID   PRI USER\n1     19  root\n2     19  root\n...   ... ...\n4488  19  chanvi\n</code></pre></p> <p>Change priority of a PID</p> <pre><code>renice [nice_value] [option] [PID]\n</code></pre> <p>Increase priority by 5 units for process ID 4488</p> <p>ps -eo pid,pri,user<pre><code>PID   PRI USER\n1     19  root\n2     19  root\n...   ... ...\n4488  19  chanvi\n</code></pre> renice -5 -p 4488<pre><code>4488 (process ID) old priority 0, new priority -5\n</code></pre> ps -eo pid,pri,user<pre><code>PID   PRI USER\n1     19  root\n2     19  root\n...   ... ...\n4488  24  chanvi\n</code></pre></p> Killing Processes <p>On any Linux system, whether you\u2019re on a server or a desktop system, processes are consistently running. Sometimes, these processes may not behave as expected due to certain reasons like system bugs, unexpected system behavior, or accidental initiation and may require termination. This is where the concept of killing processes in Linux comes to picture under the area of process management.</p> <p><code>kill</code> in Linux is a built-in command that is used to terminate processes manually. You can use the <code>kill</code> command to send a specific signal to a process. When we use the <code>kill</code> command, we basically request a process to stop, pause, or terminate <pre><code>kill [signal or option] PID(s)\n</code></pre></p> <p>In practice, you would identify the Process ID (PID) of the process you want to terminate and replace PID(s) in the above command. The signal or option part is optional, but very powerful allowing for specific termination actions.</p> Process Forking <p>Process forking is a fundamental concept under process management in Linux systems. The term refers to the mechanism where a running process (parent process) can generate a copy of itself (child process), enabling concurrent execution of both processes. This is facilitated by the \u2018fork\u2019 system call. It is a prominent aspect in understanding the creation and control of processes in a Linux environment.</p> <p>The child process created by fork is a nearly perfect copy of the parent process with exception to just a few values including the process ID and parent process ID. Any changes made in the child process does not affect the parent process, and vice versa.</p> Basic code snippet of proc forking in C<pre><code>#include&lt;sys/types.h&gt;\n#include&lt;unistd.h&gt;\n#include&lt;stdio.h&gt;\n\nint main()\n{\n    pid_t child_pid;\n\n    // Try creating a child process\n    child_pid = fork();\n\n    // If a child is successfully created\n    if(child_pid &gt;= 0)\n    printf(\"Child created with PID: %d\\n\", child_pid);\n    else\n    printf(\"Fork failed\\n\");\n    return 0;\n}\n</code></pre> <p>In this snippet, <code>fork()</code> is used to created a new child process. If the process creation is successful, <code>fork()</code> returns the process ID of the child process. If unsuccessful, it returns a negative value.</p> User Management Create/Delete/Update Users Create new users<pre><code>useradd [username] # (1)!\n</code></pre> <ol> <li>Alternative, <code>adduser [username]</code></li> </ol> <p>Update user's details (home dir or login shell)<pre><code>usermod\n</code></pre> Delete users<pre><code>userdel [username]\n</code></pre></p> Users and Groups <p>User management in Linux uses user groups to manage system users and permissions efficiently. A user group is a collection of users that simplifies system administration by determining access rights to resources like files and directories. Each user belongs to one or more groups, allowing administrators to grant specific privileges without full superuser access.  groupadd<pre><code>groupadd\n</code></pre> groupmod<pre><code>groupmod\n</code></pre> groupdel<pre><code>groupdel\n</code></pre> usermod<pre><code>usermod\n</code></pre> gpasswd<pre><code>gpasswd\n</code></pre></p> Managing Permissions <p>User management in Linux involves managing permissions to control who can access, modify, and execute files and directories. Permissions are categorized into read, write, and execute types and can be set for the file owner (user), the owning group, and others. chmod<pre><code>chmod\n</code></pre> chown<pre><code>chown\n</code></pre> chgrp<pre><code>chgrp\n</code></pre></p> Service Management(systemd) Checking Service Status <pre><code>systemctl status [service_name]\n</code></pre> <p>Check PostgreSQL status</p> systemctl status postgresql<pre><code>\u25cf postgresql.service - PostgreSQL RDBMS\n    Loaded: loaded (/usr/lib/systemd/system/postgresql.service; enabled; preset: enabled)\n    Active: active (exited) since Tue 2025-02-25 08:49:01 +07; 2h 57min ago\nMain PID: 2535 (code=exited, status=0/SUCCESS)\n        CPU: 726us\n\nFeb 25 08:49:01 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 08:49:01 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\n</code></pre> Start/Stop Services <pre><code>systemctl [stop|start|restart] [service_name]\n</code></pre> <p>Stop a service</p> <p>systemctl stop postgresql<pre><code>\n</code></pre> systemctl status postgresql<pre><code>\u25cb postgresql.service - PostgreSQL RDBMS\n    Loaded: loaded (/usr/lib/systemd/system/postgresql.service; enabled; preset: enabled)\n    Active: inactive (dead) since Tue 2025-02-25 14:23:09 +07; 5s ago\nDuration: 16.311s\n    Process: 59550 ExecStart=/bin/true (code=exited, status=0/SUCCESS)\nMain PID: 59550 (code=exited, status=0/SUCCESS)\n        CPU: 2ms\n\nFeb 25 14:22:53 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:22:53 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:23:09 chanvi-Dell-G15-5520 systemd[1]: postgresql.service: Deactivated successfully.\nFeb 25 14:23:09 chanvi-Dell-G15-5520 systemd[1]: Stopped postgresql.service - PostgreSQL RDBMS.\n</code></pre></p> <p>Start a service</p> <p>systemctl start postgresql<pre><code>\n</code></pre> systemctl status postgresql<pre><code>\u25cf postgresql.service - PostgreSQL RDBMS\n    Loaded: loaded (/usr/lib/systemd/system/postgresql.service; enabled; preset: enabled)\n    Active: active (exited) since Tue 2025-02-25 14:25:53 +07; 2s ago\n    Process: 60645 ExecStart=/bin/true (code=exited, status=0/SUCCESS)\nMain PID: 60645 (code=exited, status=0/SUCCESS)\n        CPU: 1ms\n\nFeb 25 14:25:53 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:25:53 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\n</code></pre></p> <p>Restart a service</p> <p>systemctl restart postgresql<pre><code>\n</code></pre> systemctl status postgresql<pre><code>\u25cf postgresql.service - PostgreSQL RDBMS\n    Loaded: loaded (/usr/lib/systemd/system/postgresql.service; enabled; preset: enabled)\n    Active: active (exited) since Tue 2025-02-25 14:29:02 +07; 3s ago\n    Process: 63540 ExecStart=/bin/true (code=exited, status=0/SUCCESS)\nMain PID: 63540 (code=exited, status=0/SUCCESS)\n        CPU: 2ms\n\nFeb 25 14:29:02 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:29:02 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\n</code></pre></p> Checking Service Logs <p>Several essential logs generated by system processes, users and administrator actions can be found in <code>/var/log</code> directory. Logs can be accessed and viewed using several commands. For example, the <code>dmesg</code> command can be used to display the kernel ring buffer. Most system logs are managed by <code>systemd</code> and can be checked using the command <code>journalctl</code>. <pre><code>journalctl\n</code></pre></p> <p>This command will show the entire system log from the boot to the moment you\u2019re calling the journal. <pre><code>journalct -u [service_name]\n</code></pre> To display logs for a specific service, the <code>-u</code> option can be used followed by the service\u2019s name.</p> <p>Display logs for PosgreSQL</p> journalctl -u postgresql<pre><code>Feb 03 18:03:25 chanvi-Dell-G15-5520 systemd[1]: postgresql.service: Deactivated successfully.\nFeb 03 18:03:25 chanvi-Dell-G15-5520 systemd[1]: Stopped postgresql.service - PostgreSQL RDBMS.\n-- Boot 7e4d6dedb3a84472a4c09dc86fffce33 --\nFeb 03 19:43:29 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 03 19:43:29 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\nFeb 03 20:06:34 chanvi-Dell-G15-5520 systemd[1]: postgresql.service: Deactivated successfully.\nFeb 03 20:06:34 chanvi-Dell-G15-5520 systemd[1]: Stopped postgresql.service - PostgreSQL RDBMS.\n-- Boot 17f7b7cf745a497e8995273fa628f802 --\nFeb 04 08:39:12 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 04 08:39:12 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\nFeb 04 17:57:34 chanvi-Dell-G15-5520 systemd[1]: postgresql.service: Deactivated successfully.\nFeb 04 17:57:34 chanvi-Dell-G15-5520 systemd[1]: Stopped postgresql.service - PostgreSQL RDBMS.\n...\n-- Boot 84636cdedf26420e8bb1b2170ee71809 --\nFeb 25 08:49:01 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 08:49:01 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:21:06 chanvi-Dell-G15-5520 systemd[1]: postgresql.service: Deactivated successfully.\nFeb 25 14:21:06 chanvi-Dell-G15-5520 systemd[1]: Stopped postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:22:12 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:22:12 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:22:50 chanvi-Dell-G15-5520 systemd[1]: postgresql.service: Deactivated successfully.\nFeb 25 14:22:50 chanvi-Dell-G15-5520 systemd[1]: Stopped postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:22:50 chanvi-Dell-G15-5520 systemd[1]: Stopping postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:22:53 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:22:53 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:23:09 chanvi-Dell-G15-5520 systemd[1]: postgresql.service: Deactivated successfully.\nFeb 25 14:23:09 chanvi-Dell-G15-5520 systemd[1]: Stopped postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:25:53 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:25:53 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:28:59 chanvi-Dell-G15-5520 systemd[1]: postgresql.service: Deactivated successfully.\nFeb 25 14:28:59 chanvi-Dell-G15-5520 systemd[1]: Stopped postgresql.service - PostgreSQL RDBMS.\nFeb 25 14:28:59 chanvi-Dell-G15-5520 systemd[1]: Stopping postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:29:02 chanvi-Dell-G15-5520 systemd[1]: Starting postgresql.service - PostgreSQL RDBMS...\nFeb 25 14:29:02 chanvi-Dell-G15-5520 systemd[1]: Finished postgresql.service - PostgreSQL RDBMS.\nlines 159-176/176 (END)\n</code></pre> Creating New Services <p>`my_service.service` file<pre><code>[Unit]\nDescription=My Custom Service\nAfter=network.target\n\n[Service]\nExecStart=/path/to/your/executable\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> This service file can be placed under <code>/etc/systemd/system/</code>to make systemd recognize it. You would then control the service using <code>systemctl</code>, systemd\u2019s command too</p> <p>Note that best practices in Linux dictate that we should not run services as root whenever possible, for security reasons. Instead, we should create a new user to run the service.</p> Package Management <p>Linux distributions use various package managers. Some of the commonly used are <code>apt</code> (Advanced Packaging Tool) for Debian-based distributions, <code>yum</code> (Yellowdog Updater, Modified) and <code>dnf</code> (Dandified YUM) for Red-Hat-based distributions, and <code>pacman</code> for Arch Linux.</p> Package Repositories <p>A repository in Linux is a storage location from where the system retrieves and installs the necessary OS updates and applications. These repositories contain thousands of Software Packages or RPM Packages compiled for specific Linux distributions.</p> <p>The specific repository used depends on the Linux distribution (like Ubuntu, Fedora, etc.) and the package format the distribution uses (like .deb in Debian and Ubuntu or .rpm in Fedora and CentOS).</p> <p>Repositories provide a method of updating the tools and applications on your Linux system, and they also ensure all updates and dependencies work together and are tested for integration before they are released.</p> <p>There is no standard way to use the repositories across various distributions, each comes with its pre-configured set of repositories. Update the repository in Ubuntu<pre><code>sudo apt update\n</code></pre> Update the repository in CentOS/RHEL/Fedora<pre><code>sudo yum update\n</code></pre> Update the repository in Racket<pre><code>raco pkg update\n</code></pre></p> Snap <p>Snap is a modern approach to package management in Linux systems promoted by Canonical (the company behind Ubuntu). Unlike traditional package management systems such as dpkg or RPM, Snap focuses on providing software as self-contained packages (known as \u2018Snaps\u2019) that include all of their dependencies. This ensures that a Snap application runs consistently across a variety of different Linux distributions.</p> <p>Snaps are installed from a Snapcraft store and are automatically updated in the background. The Snap update process is transactional, meaning if something goes wrong during an update, Snap can automatically revert to the previous working version. Example of a snap command<pre><code>sudo snap install [package_name]\n</code></pre></p> Finding and Installing Packages <p>Install a new package on a Debian-based system like Ubuntu<pre><code>sudo [apt | apt-get] update\nsudo [apt | apt-get] install [package_name]\n</code></pre> Install a new package on a Fedora/RHEL/CentOS<pre><code>sudo [dnf | yum] update\nsudo [dnf | yum] install [package_name]\n</code></pre></p> Listing Installed Packages <p>Listing installed packages in an `apt` package manager<pre><code>sudo apt list --installed\n</code></pre> Listing installed packages for `dnf` package manager<pre><code>dnf list installed\n</code></pre></p> Install/Remove/Upgrade Packages <p>Remove a package<pre><code>\n</code></pre> Update a package<pre><code>\n</code></pre></p> Linux Disks Filesystems <p>Linux uses a variety of filesystems to allow us to store and retrieve data from the hardware of a computer system such as disks. The filesystem defines how data is organized, stored, and retrieved on these storage devices. Examples of popular Linux filesystems include EXT4, FAT32, NTFS, and Btrfs.</p> <p>Each filesystem has its own advantages, disadvantages, and use cases. For example, EXT4 is typically used for Linux system volumes due to its robustness and compatibility with Linux, while FAT32 may be used for removable media like USB drives for its compatibility with almost all operating systems.</p> <p>View the Filesystem type</p> df -T<pre><code>Filesystem      Type     1K-blocks    Used Available Use% Mounted on\nudev            devtmpfs    986480       0    986480   0% /dev\ntmpfs           tmpfs       199404     412    198992   1% /run\n/dev/nvme0n1p1  ext4      51359360 8744592  40424004  18% /\ntmpfs           tmpfs       997000       0    997000   0% /dev/shm\ntmpfs           tmpfs         5120       0      5120   0% /run/lock\n/dev/nvme0n1p15 vfat        126678   10922    115756   9% /boot/efi\ntmpfs           tmpfs       199400       0    199400   0% /run/user/0\n</code></pre> Inodes <p>In a Linux filesystem, an inode (index node) is a core concept that represents a filesystem object such as a file or a directory. More specifically, an inode is a data structure that stores critical information about a file except its name and actual data. This information includes the file\u2019s size, owner, access permissions, access times, and more.</p> <p>Every file or directory in a Linux filesystem has a unique inode, and each inode is identified by an inode number within its own filesystem. This inode number provides a way of tracking each file, acting as a unique identifier for the Linux operating system.</p> <p>Whenever a file is created in Linux, it is automatically assigned an inode that stores its metadata. The structure and storage of inodes are handled by the filesystem, which means the kind and amount of metadata in an inode can differ between filesystems.</p> <p>Retrieve the inode of files/dirs</p> <p>ls -i<pre><code>17859963 directory  17855518 file1.txt  17856147 file2.txt  17845502 file.txt  17831913 sorted_file.txt  17830444 stderr.txt  17827405 stdout.txt\n</code></pre> ls -i file.txt<pre><code>17845502 file.txt\n</code></pre></p> Filesystems <p>Linux supports various types of filesystems, such as EXT4, XFS, BTRFS, etc. Each one of them has their own advantages regarding performance, data integrity and recovery options.</p> <p>View the Filesystem type</p> df -T<pre><code>Filesystem      Type     1K-blocks    Used Available Use% Mounted on\nudev            devtmpfs    986480       0    986480   0% /dev\ntmpfs           tmpfs       199404     412    198992   1% /run\n/dev/nvme0n1p1  ext4      51359360 8744592  40424004  18% /\ntmpfs           tmpfs       997000       0    997000   0% /dev/shm\ntmpfs           tmpfs         5120       0      5120   0% /run/lock\n/dev/nvme0n1p15 vfat        126678   10922    115756   9% /boot/efi\ntmpfs           tmpfs       199400       0    199400   0% /run/user/0\n</code></pre> Mounts <p>In Linux environments, a very crucial concept related to disk management is the \u201cmounting\u201d of filesystems. Fundamentally, mounting in Linux refers to the process that allows the operating system to access data stored on underlying storage devices, such as hard drives or SSDs. This process attaches a filesystem (available on some storage medium) to a specific directory (also known as a mount point) in the Linux directory tree.</p> <p>The beauty of this approach lies in the unified and seamless manner in which Linux treats all files, irrespective of whether they reside on a local disk, network location, or any other kind of storage device.</p> <p>The <code>mount</code> command in Linux is used for mounting filesystems. When a specific filesystem is \u2018mounted\u2019 at a particular directory, the system can begin reading data from the device and interpreting it according to the filesystem\u2019s rules.</p> <p>It\u2019s worth noting that Linux has a special directory, <code>/mnt</code>, that is conventionally used as a temporary mount point for manual mounting and unmounting operations. Mount the second partition of a second hard drive at the `/mnt` directory<pre><code>mount /dev/sdb1 /mnt\n</code></pre></p> Adding Disks <p>List all block devices (disk and partitions).</p> lsblk<pre><code>NAME                        MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINTS  \nsda                           8:0    1 119.2G  0 disk  \nnvme0n1                     259:0    0 476.9G  0 disk  \n\u251c\u2500nvme0n1p1                 259:1    0     1G  0 part  /boot/efi\n\u251c\u2500nvme0n1p2                 259:2    0     2G  0 part  /boot\n\u2514\u2500nvme0n1p3                 259:3    0 473.9G  0 part  \n\u2514\u2500dm_crypt-0              252:0    0 473.9G  0 crypt \n    \u2514\u2500ubuntu--vg-ubuntu--lv 252:1    0 473.9G  0 lvm   /\n</code></pre> <p>Create a new partition on a disk.</p> <p>sudo fdisk /dev/sda<pre><code>Welcome to fdisk (util-linux 2.39.3).\nChanges will remain in memory only, until you decide to write them.\nBe careful before using the write command.\n\nCommand (m for help): n\nPartition type\np   primary (0 primary, 0 extended, 4 free)\ne   extended (container for logical partitions)\nSelect (default p): p\nPartition number (1-4, default 1): 1\nFirst sector (2048-250068991, default 2048): \nLast sector, +/-sectors or +/-size{K,M,G,T,P} (2048-250068991, default 250068991): \n\nCreated a new partition 1 of type 'Linux' and of size 119.2 GiB.\n\nCommand (m for help): p\nDisk /dev/sda: 119.24 GiB, 128035323904 bytes, 250068992 sectors\nDisk model: USB Flash Drive \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: dos\nDisk identifier: 0xbf31f41c\n\nDevice     Boot Start       End   Sectors   Size Id Type\n/dev/sda1        2048 250068991 250066944 119.2G 83 Linux\n\nCommand (m for help): w\nThe partition table has been altered.\nCalling ioctl() to re-read partition table.\nSyncing disks.\n</code></pre> lsblk<pre><code>NAME                        MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINTS  \nsda                           8:0    1 119.2G  0 disk  \n\u2514\u2500sda1                        8:1    1 119.2G  0 part  \nnvme0n1                     259:0    0 476.9G  0 disk  \n\u251c\u2500nvme0n1p1                 259:1    0     1G  0 part  /boot/efi\n\u251c\u2500nvme0n1p2                 259:2    0     2G  0 part  /boot\n\u2514\u2500nvme0n1p3                 259:3    0 473.9G  0 part  \n\u2514\u2500dm_crypt-0              252:0    0 473.9G  0 crypt \n    \u2514\u2500ubuntu--vg-ubuntu--lv 252:1    0 473.9G  0 lvm   /\n</code></pre></p> <p>Create a new filesystem on a partition.</p> sudo mkfs.ext4 /dev/sda1<pre><code>mke2fs 1.47.0 (5-Feb-2023)\nCreating filesystem with 31258368 4k blocks and 7815168 inodes\nFilesystem UUID: 7dba2cd1-a61f-4139-adb2-a3c21df3abd0\nSuperblock backups stored on blocks: \n        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, \n        4096000, 7962624, 11239424, 20480000, 23887872\n\nAllocating group tables: done                            \nWriting inode tables: done                            \nCreating journal (131072 blocks): done\nWriting superblocks and filesystem accounting information: done\n</code></pre> <p>Mount a filesystem to a directory.</p> <p>sudo mount /dev/sda1 /mnt<pre><code>\n</code></pre> lsblk<pre><code>NAME                        MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINTS  \nsda                           8:0    1 119.2G  0 disk  \n\u2514\u2500sda1                        8:1    1 119.2G  0 part  /mnt\nnvme0n1                     259:0    0 476.9G  0 disk  \n\u251c\u2500nvme0n1p1                 259:1    0     1G  0 part  /boot/efi\n\u251c\u2500nvme0n1p2                 259:2    0     2G  0 part  /boot\n\u2514\u2500nvme0n1p3                 259:3    0 473.9G  0 part  \n\u2514\u2500dm_crypt-0              252:0    0 473.9G  0 crypt \n    \u2514\u2500ubuntu--vg-ubuntu--lv 252:1    0 473.9G  0 lvm   /\n</code></pre> df -T<pre><code>Filesystem      Type     1K-blocks    Used Available Use% Mounted on\nudev            devtmpfs    986480       0    986480   0% /dev\ntmpfs           tmpfs       199404     412    198992   1% /run\n/dev/nvme0n1p1  ext4      51359360 8744592  40424004  18% /\ntmpfs           tmpfs       997000       0    997000   0% /dev/shm\ntmpfs           tmpfs         5120       0      5120   0% /run/lock\n/dev/nvme0n1p15 vfat        126678   10922    115756   9% /boot/efi\ntmpfs           tmpfs       199400       0    199400   0% /run/user/0\n/dev/sda1       ext4     122485360      24 116217280   1% /mnt\n</code></pre></p> Swap <p>Swap space in Linux is used when the amount of physical memory (RAM) is full. If the system needs more memory resources and the physical memory is full, inactive pages in memory are moved to the swap space. Swap space is a portion of a hard disk drive (HDD) that is used for virtual memory.</p> <p>Having swap space ensures that whenever your system runs low on physical memory, it can move some of the data to the swap, freeing up RAM space, but this comes with performance implications as disk-based storage is slower than RAM.</p> <p>In the context of disks and filesystems, the swap space can live in two places:</p> <ol> <li>In its own dedicated partition.</li> <li>In a regular file within an existing filesystem.</li> </ol> <pre><code>fallocate -l 1G /swapfile # creates a swap file\nchmod 600 /swapfile # secures the swap file by preventing regular users from reading it\nmkswap /swapfile # sets up the Linux swap area\nswapon /swapfile # enables the file for swapping\n</code></pre> LVM <p>The Linux Logical Volume Manager (LVM) is a device mapper framework that provides logical volume management for the Linux kernel. It was created to ease disk management, allowing for the use of abstracted storage devices, known as logical volumes, instead of using physical storage devices directly.</p> <p>LVM is extremely flexible, and features include resizing volumes, mirroring volumes across multiple physical disks, and moving volumes between disks without needing to power down.</p> <p>LVM works on 3 levels: Physical Volumes (PVs), Volume Groups (VGs), and Logical Volumes (LVs).</p> <ol> <li>PVs are the actual disks or partitions.</li> <li>VGs combine PVs into a single storage pool.</li> <li>LVs carve out portions from the VG to be used by the system.</li> </ol> create an LVM<pre><code>pvcreate /dev/sdb1\nvgcreate my-vg /dev/sdb1\nlvcreate -L 10G my-vg -n my-lv\n</code></pre> Booting Linux <p>The whole process involves several stages including POST (Power-On Self Test), MBR (Master Boot Record), GRUB (GRand Unified Bootloader), Kernel, Init process, and finally the GUI or command line interface where users interact.</p> <p>During this process, vital system checks are executed, hardware is detected, appropriate drivers are loaded, filesystems are mounted, necessary system processes are started, and finally, the user is presented with a login prompt. example of the GRUB configuration file `/etc/default/grub`<pre><code>GRUB_DEFAULT=0\nGRUB_TIMEOUT=5\nGRUB_DISTRIBUTOR=`lsb_release -i -s 2&gt; /dev/null || echo Debian`\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\nGRUB_CMDLINE_LINUX=\"\"\n</code></pre></p> Boot Loaders <p>Boot Loaders play an integral role in booting up any Linux-based system. When the system is switched on, it\u2019s the Boot Loader that takes charge and loads the kernel of the OS into the system\u2019s memory. The kernel then initializes the hardware components and loads necessary drivers, after which it starts the scheduler and executes the init process.</p> <p>Typically, the two most commonly used boot loaders in Linux are LILO (Linux Loader) and GRUB (GRand Unified Bootloader). GRUB sets the standard for modern day Linux booting, providing rich features like a graphical interface, scripting, and debugging capabilities. LILO, on the other hand, is older and does not have as many features, but runs on a broader range of hardware platforms. sudo update-grub<pre><code>Sourcing file `/etc/default/grub'\nGenerating grub configuration file ...\nFound linux image: /boot/vmlinuz-6.11.0-17-generic\nFound initrd image: /boot/initrd.img-6.11.0-17-generic\nFound linux image: /boot/vmlinuz-6.8.0-52-generic\nFound initrd image: /boot/initrd.img-6.8.0-52-generic\nFound memtest86+ 64bit EFI image: /memtest86+x64.efi\nWarning: os-prober will not be executed to detect other bootable partitions.\nSystems on them will not be added to the GRUB boot configuration.\nCheck GRUB_DISABLE_OS_PROBER documentation entry.\nAdding boot menu entry for UEFI Firmware Settings ...\ndone\n</code></pre> Irrespective of the type of Boot Loader used, understanding and configuring them properly is essential for maintaining an efficient, stable and secure operating system. Boot loaders also allow users to switch between different operating systems on the same machine, if required.</p> Logs <p>Linux utilizes various log message levels from <code>emerg</code> (the system is unusable) to <code>debug</code> (debug-level messages). During the boot process, messages from various components of the system like kernel, init, services, etc., are stored. Many Linux distributions use systemd logging system, <code>journalctl</code>, which holds the logs of the boot process. Viewing boot messages in real-time<pre><code>sudo dmesg\n</code></pre></p> Networking TCP/IP Stack <p>The TCP/IP (Transmission Control Protocol/Internet Protocol) forms the backbone of internet protocols. Essentially, it is a set of networking protocols that allows two or more computers to communicate. In the context of Linux, TCP/IP networking is a fundamental part of the operating system\u2019s functionality. It provides a platform for establishing connections and facilitating data transfer between two endpoints.</p> <p>TCP/IP serves a vital role in enabling a host, given a correct IP configuration, to connect and interact with other hosts on the same or different networks. It is comprised of a four layers model, including the Network Interface, Internet, Transport, and Application layers. Understanding TCP/IP, its structure and how it works are crucial for effectively managing and troubleshooting Linux networks.</p> <p>View all active TCP/IP network connections with <code>netstat</code></p> sudo apt update; sudo apt install net-tools -y<pre><code>sudo apt update\nsudo apt install net-tools -y\n```bash title=\"netstat -at\"\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address         State      \ntcp        0      0 localhost:ipp           0.0.0.0:*               LISTEN     \ntcp        0      0 chanvi-Dell-G15-:domain 0.0.0.0:*               LISTEN     \ntcp        0      0 _localdnsproxy:domain   0.0.0.0:*               LISTEN     \ntcp        0      0 localhost:5433          0.0.0.0:*               LISTEN     \ntcp        0      0 _localdnsstub:domain    0.0.0.0:*               LISTEN     \ntcp       25      0 chanvi-Dell-G15-5:49924 ec2-15-188-95-58.:https CLOSE_WAIT \ntcp        0      0 chanvi-Dell-G15-5:54636 a23-36-252-26.dep:https ESTABLISHED\ntcp        0      0 chanvi-Dell-G15-5:50966 146.75.45.229:https     ESTABLISHED\ntcp        0      0 chanvi-Dell-G15-5:38352 172.67.72.113:https     ESTABLISHED\n...      ...    ... ...                     ...                     ...\ntcp        0      0 chanvi-Dell-G15-5:55284 103.229.10.247:https    ESTABLISHED\ntcp6       0      0 ip6-localhost:ipp       [::]:*                  LISTEN\n</code></pre> Subnetting <p>Display current routing table</p> route -n<pre><code>Kernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.0.1.1        0.0.0.0         UG    0      0        0 ens5\n10.0.1.0        0.0.0.0         255.255.255.0   U     0      0        0 ens5\n</code></pre> <p>Add a new subnet</p> <p>route add -net 10.0.2.0/24 gw 0.0.0.0<pre><code>\n</code></pre> route -n<pre><code>Kernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         10.0.1.1        0.0.0.0         UG    0      0        0 ens5\n10.0.1.0        0.0.0.0         255.255.255.0   U     0      0        0 ens5\n10.0.2.0        0.0.0.0         255.255.255.0   UG    0      0        0 ens5\n</code></pre></p> Ethernet &amp; ARP/RARP <ul> <li>Ethernet: It\u2019s the most widely installed LAN (Local Area Network) technology, allowing devices to communicate within a local area network.</li> <li>ARP: As per its name, it provides address resolution, translating IP addresses into MAC (Media Access Control) addresses, facilitating more direct network communication.</li> <li>RARP: It is the Reverse Address Resolution Protocol, working in the opposite way to ARP. It converts MAC addresses into IP addresses, which is useful in scenarios when a computer knows its MAC address but needs to find out its IP address.</li> </ul> DHCP <p>In Linux, DHCP can be configured and managed using terminal commands. This involves the installation of the DHCP server software, editing the configuration files, and managing the server\u2019s services.</p> <p>A traditional DHCP server should have a static IP address to manage the IP distribution effectively. The DHCP in Linux also handles DNS and other related data that your network might require.</p> <p>Install a DHCP server in a Debian-based Linux</p> sudo apt-get install isc-dhcp-server -y<pre><code>Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following packages were automatically installed and are no longer required:\nlibllvm17t64 python3-netifaces\nUse 'sudo apt autoremove' to remove them.\nThe following additional packages will be installed:\nisc-dhcp-common\nSuggested packages:\nisc-dhcp-server-ldap policycoreutils\nThe following NEW packages will be installed:\nisc-dhcp-common isc-dhcp-server\n0 upgraded, 2 newly installed, 0 to remove and 71 not upgraded.\nNeed to get 1,281 kB of archives.\nAfter this operation, 4,281 kB of additional disk space will be used.\nDo you want to continue? [Y/n] y\nGet:1 http://vn.archive.ubuntu.com/ubuntu noble/universe amd64 isc-dhcp-server amd64 4.4.3-P1-4ubuntu2 [1,236 kB]\nGet:2 http://vn.archive.ubuntu.com/ubuntu noble/universe amd64 isc-dhcp-common amd64 4.4.3-P1-4ubuntu2 [45.8 kB]\nFetched 1,281 kB in 3s (382 kB/s)     \nPreconfiguring packages ...\nSelecting previously unselected package isc-dhcp-server.\n(Reading database ... 269829 files and directories currently installed.)\nPreparing to unpack .../isc-dhcp-server_4.4.3-P1-4ubuntu2_amd64.deb ...\nUnpacking isc-dhcp-server (4.4.3-P1-4ubuntu2) ...\nSelecting previously unselected package isc-dhcp-common.\nPreparing to unpack .../isc-dhcp-common_4.4.3-P1-4ubuntu2_amd64.deb ...\nUnpacking isc-dhcp-common (4.4.3-P1-4ubuntu2) ...\nSetting up isc-dhcp-server (4.4.3-P1-4ubuntu2) ...\nGenerating /etc/default/isc-dhcp-server...\nCreated symlink /etc/systemd/system/multi-user.target.wants/isc-dhcp-server.service \u2192 /usr/lib/systemd/system/isc-dhcp-server.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/isc-dhcp-server6.service \u2192 /usr/lib/systemd/system/isc-dhcp-server6.service.\nSetting up isc-dhcp-common (4.4.3-P1-4ubuntu2) ...\nProcessing triggers for man-db (2.12.0-4build2) ...\n</code></pre> <p>After the installation process, all configurations of the DHCP server are done in the configuration file located at <code>/etc/dhcp/dhcpd.conf</code> which can be edited using any text editor. cat /etc/dhcp/dhcpd.conf<pre><code># dhcpd.conf\n#\n# Sample configuration file for ISC dhcpd\n#\n# Attention: If /etc/ltsp/dhcpd.conf exists, that will be used as\n# configuration file instead of this file.\n#\n\n# option definitions common to all supported networks...\noption domain-name \"example.org\";\noption domain-name-servers ns1.example.org, ns2.example.org;\n\ndefault-lease-time 600;\nmax-lease-time 7200;\n\n# The ddns-updates-style parameter controls whether or not the server will\n# attempt to do a DNS update when a lease is confirmed. We default to the\n# behavior of the version 2 packages ('none', since DHCP v2 didn't\n# have support for DDNS.)\nddns-update-style none;\n\n...\n\n#shared-network 224-29 {\n#  subnet 10.17.224.0 netmask 255.255.255.0 {\n#    option routers rtr-224.example.org;\n#  }\n#  subnet 10.0.29.0 netmask 255.255.255.0 {\n#    option routers rtr-29.example.org;\n#  }\n#  pool {\n#    allow members of \"foo\";\n#    range 10.17.224.10 10.17.224.250;\n#  }\n#  pool {\n#    deny members of \"foo\";\n#    range 10.0.29.10 10.0.29.230;\n#  }\n#}\n</code></pre></p> IP Routing ip route show<pre><code>default via 10.0.1.1 dev ens5 \n10.0.1.0/24 dev ens5 proto kernel scope link src 10.0.1.117\n</code></pre> DNS Resolution <p>On Linux systems, when an application needs to connect to a certain URL, it consults the DNS resolver. This resolver, using the file <code>/etc/resolv.conf</code>, communicates with the DNS server, which then converts the URL into an IP address to establish a network connection. cat /etc/resolv.conf<pre><code>nameserver 10.0.0.2\n</code></pre> nslookup hocachoc.dev<pre><code>Server:         127.0.0.53\nAddress:        127.0.0.53#53\n\nNon-authoritative answer:\nName:   hocachoc.dev\nAddress: 185.199.111.153\nName:   hocachoc.dev\nAddress: 185.199.110.153\nName:   hocachoc.dev\nAddress: 185.199.108.153\nName:   hocachoc.dev\nAddress: 185.199.109.153\nName:   hocachoc.dev\nAddress: 2606:50c0:8003::153\nName:   hocachoc.dev\nAddress: 2606:50c0:8001::153\nName:   hocachoc.dev\nAddress: 2606:50c0:8000::153\nName:   hocachoc.dev\nAddress: 2606:50c0:8002::153\n</code></pre> dig hocachoc.dev<pre><code>; &lt;&lt;&gt;&gt; DiG 9.18.30-0ubuntu0.24.04.2-Ubuntu &lt;&lt;&gt;&gt; hocachoc.dev\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43906\n;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 65494\n;; QUESTION SECTION:\n;hocachoc.dev.                  IN      A\n\n;; ANSWER SECTION:\nhocachoc.dev.           1787    IN      A       185.199.108.153\nhocachoc.dev.           1787    IN      A       185.199.109.153\nhocachoc.dev.           1787    IN      A       185.199.110.153\nhocachoc.dev.           1787    IN      A       185.199.111.153\n\n;; Query time: 0 msec\n;; SERVER: 127.0.0.53#53(127.0.0.53) (UDP)\n;; WHEN: Fri Feb 28 11:50:58 +07 2025\n;; MSG SIZE  rcvd: 105\n</code></pre></p> Netfilter <p>Netfilter is a powerful tool included in Linux that provides the functionality for maneuvering and altering network packets. It is essentially a framework that acts as an interface between the kernel and the packet, allowing for the manipulation and transformation of packets in transit.</p> <p>Netfilter\u2019s primary application is in developing firewall systems and managing network address translations (NATs). In Linux, netfilter is extremely valuable due to the wide range of applications it offers, from traffic control, packet modification, logging, and network intrusion detection.</p> <p>The structure of netfilter allows for custom functions, often referred to as hooks, to be inserted into the kernel\u2019s networking stack. These hooks can manipulate or inspect packets at various stages like prerouting, local in, forward, local out, and postrouting.</p> <p>A common tool used in conjunction with netfilter is iptables, which provides a mechanism to configure the tables in the kernel provided by the Netfilter Framework.</p> <p>Using <code>iptables</code> with netfilter module to create a simple firewall rule</p> iptables -A INPUT -i eth0 -s 192.168.0.0/24 -m netfilter --netfilter-name example --action drop<pre><code>\n</code></pre> <p>In this command, \u2018-A INPUT\u2019 is adding a new rule to the \u2018INPUT\u2019 chain. \u2018-i eth0\u2019 is specifying the network interface, and \u2018-s 192.168.0.0/24\u2019 is designating the IP address range for the rule. \u2018-m netfilter\u2019 is calling the netfilter module, \u2018\u2014netfilter-name example\u2019 is naming the rule, and \u2018\u2014action drop\u2019 is specifying how to handle the matching packets (In this case, dropping them).</p> SSH SSH to remote server with private key<pre><code>ssh -i [private_key] [username]@[remote_server_ipaddress]\n</code></pre> File Transfer Copy file from local to remote destination<pre><code>scp -i [private_key] /path/to/local/file [username]@[remote_server_ipaddress]:/path/to/destination\n</code></pre> Backup Tools rsync Create a backup by synchronizing the source directory with the destination directory<pre><code>rsync -avz /source_dir/ /destination_dir/ # (1)!\n</code></pre> <ol> <li><code>-a</code> (archive mode), <code>-v</code> (verbose), and <code>-z</code> (compress data).</li> </ol> tar dump restore Shell Programming Example of a bash shell script<pre><code>#!/bin/bash\n\necho \"Hello, World!\"\n</code></pre> <p>The <code>echo</code> command prints its argument, in this case \u201cHello, World!\u201d, to the terminal.</p> Literals <p>The term \u2018literal\u2019, in computer science and shell programming, refers to a notation for representing a fixed value in source code. In shell scripts, these fixed values can include string literals, numeric literals or a boolean. Example of literals in shell script<pre><code>#!/bin/bash\n\nStringLiteral=\"This is a string literal\"\nNumericLiteral=125\necho $StringLiteral\necho $NumericLiteral\n</code></pre></p> <p><code>StringLiteral</code> and <code>NumericLiteral</code> are literals and <code>echo</code> is used to print them.</p> Variables <p>In the context of Shell Programming on Linux, a variable is a character string that can store system data or user-defined data. It is a symbolic name that is assigned to an amount of storage space that can change its value during the execution of the program. Variables play a vital role in any programming paradigm, and shell scripting is no different.</p> <p>Variables fall into two broad categories: System Variables and User-Defined Variables. System variables are created and maintained by the Linux system itself. Examples include PATH, HOME, and PWD. User-defined variables, on the other hand, are created and controlled by the user.</p> <p>A variable in shell scripting is defined by the \u2019=\u2019 (equals) operator, and the value can be retrieved by prefixing the variable name with a \u2019$\u2019 (dollar) sign. <pre><code># Create a User-Defined Variable\nMY_VARIABLE=\"Hello World\"\n\n# Print the value of the Variable\necho $MY_VARIABLE  # Output: Hello World\n</code></pre></p> Loops <p>for</p> <p><code>for</code> loop iterates over a list of items and performs actions on each of them. <pre><code>for i in 1 2 3\ndo\n    echo \"$i\"\ndone\n</code></pre> This will ocutput <pre><code>1\n2\n3\n</code></pre></p> <p>while</p> <p><code>while</code> loop executes commands as long as the control condition remains true.</p> <p>!!! note \"until     <code>until</code> loop runs commands until the control condition becomes true.</p> Conditionals <pre><code>#!/bin/bash\n\na=10\nb=20\n\nif [ $a -lt 20 ]\nthen\n    echo \"a is less than b\"\nelif [ $a -gt 20 ]\nthen\n    echo \"a is greater than b\"\nelse\n    echo \"a is equal to b\"\nfi\n</code></pre> Debugging <p>When encountering an issue in a shell script, you have several debugging tools at your disposal in a Linux environment. These aid in detecting, tracing, and fixing errors or bugs in your shell scripts. Some of these debugging tools include the bash shell\u2019s <code>-x</code> (or <code>-v</code>) options, which allow for execution traces. Other tools like <code>trap</code>, <code>set</code> command, or even leveraging external debugging tools such as <code>shellcheck</code> can also be highly effective. cat script.sh<pre><code>#!/bin/bash\n\necho \"hocachoc.dev\"\nbad-command-abc\n</code></pre> bash -x script.sh<pre><code>+ echo hocachoc.dev\nhocachoc.dev\n+ bad-command-abc\nscript.sh: line 5: bad-command-abc: command not found\n</code></pre> or cat script_with_debug_option.sh<pre><code>#!/bin/bash -x\n\necho \"hocachoc.dev\"\nbad-command-abc\n</code></pre> ./script_with_debug_option.sh<pre><code>+ echo hocachoc.dev\nhocachoc.dev\n+ bad-command-abc\n./script_with_debug_option.sh: line 5: bad-command-abc: command not found\n</code></pre></p> Troubleshooting ping ping google.com<pre><code>PING google.com (142.250.178.142) 56(84) bytes of data.\n64 bytes from par21s22-in-f14.1e100.net (142.250.178.142): icmp_seq=1 ttl=118 time=1.11 ms\n64 bytes from par21s22-in-f14.1e100.net (142.250.178.142): icmp_seq=2 ttl=118 time=1.05 ms\n64 bytes from par21s22-in-f14.1e100.net (142.250.178.142): icmp_seq=3 ttl=118 time=1.05 ms\n64 bytes from par21s22-in-f14.1e100.net (142.250.178.142): icmp_seq=4 ttl=118 time=1.05 ms\n^C\n--- google.com ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3003ms\nrtt min/avg/max/mdev = 1.048/1.064/1.105/0.023 ms\n</code></pre> ICMP traceroute <p>Traceroute is a network diagnostic tool used widely in Linux systems for troubleshooting. It is designed to display the path that packets take from the system where traceroute is run to a specified destination system or website. It\u2019s used to identify routing problems, offer latency measurement, and figure out the network structure as packets journey across the internet.</p> <p>Each jump along the route is tested multiple times (the default is 3 but this can be changed), and the round-trip time for each packet is displayed. If certain packets are failing to reach their destination, traceroute can help diagnose where the failure is occurring. traceroute google.com<pre><code> 1  240.1.0.15 (240.1.0.15)  1.340 ms 240.1.0.12 (240.1.0.12)  1.421 ms  1.640 ms\n 2  * * *\n 3  151.148.8.45 (151.148.8.45)  1.152 ms  1.168 ms  1.156 ms\n 4  * * *\n 5  216.239.48.138 (216.239.48.138)  2.014 ms 72.14.237.92 (72.14.237.92)  1.154 ms 142.251.253.32 (142.251.253.32)  1.115 ms\n 6  142.251.64.131 (142.251.64.131)  1.275 ms 142.250.59.230 (142.250.59.230)  1.746 ms 142.251.64.129 (142.251.64.129)  1.288 ms\n 7  par21s22-in-f14.1e100.net (142.250.178.142)  1.036 ms  1.025 ms 72.14.238.53 (72.14.238.53)  2.925 ms\n</code></pre></p> netstat <p>Netstat, short for network statistics, is a built-in command-line tool used in Linux systems for network troubleshooting and performance measurement. It provides statistics for protocols, a list of open ports, routing table information, and other important network details. Administrators and developers work with netstat to examine network issues and understand how a system communicates with others.</p> <p>Its functionality is extended owing to various command-line options it supports, which could be used singularly or combinedly to fine-tune the output. These might include displaying numerical addresses instead of names (<code>-n)</code>, continuous monitoring (<code>-c</code>), or spotting connections on a specific protocol (<code>-t</code>, <code>-u</code>). netstat -n<pre><code>Active Internet connections (w/o servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State      \ntcp        0      0 10.0.1.117:443          194.120.230.215:22      SYN_RECV   \n...       ...    ...                        ...                     ...\nudp        0      0 10.0.1.117:56106        8.8.4.4:53              ESTABLISHED\nActive UNIX domain sockets (w/o servers)\nProto RefCnt Flags       Type       State         I-Node   Path\nunix  2      [ ]         DGRAM                    820113   /run/user/0/systemd/notify\nunix  2      [ ]         DGRAM                    11526    /run/chrony/chronyd.sock\n...  ...     ...           ...                    ...      ...\nunix  2      [ ]         DGRAM                    820018\n</code></pre></p> Packet Analysis Containerization ulimits cgroups Container Runtime Docker"},{"location":"projects/","title":"Projects","text":""},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/","title":"Flow state: The heart of Developer Experience (DevEx)","text":"<p>\u201cHave you ever been so immersed in something that you forgot about time, hunger or even sleep?\u201d If your answer is yes, that you have entered the flow state.</p> <p></p> <ul> <li>Thanks to  for supporting this content.</li> </ul>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#introduction","title":"Introduction","text":"<p>In this article, you will learn about:</p> <ul> <li>What is the flow state actually?</li> <li>Why is flow state so important to developers at work?</li> <li>How to maintain the flow state at work?</li> <li>Why choose flow state as the core goal in the great DevEx?</li> <li>Some misconceptions around DevEx?</li> </ul>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#what-is-the-flow-state","title":"What is the flow state?","text":"<p>Named by the psychologist Mih\u00e1ly Cs\u00edkszentmih\u00e1lyi in 1970, the flow state in positive psychology, also known as \u201cbeing in the zone\u201d, or \u201cdeep work\u201d is the mental state in which a person performing some activities is fully immersed in a feeling of energized focus, full involvement, and enjoyment in the process of the activity. In essence, flow is characterized by the complete absorption in what one does and a resulting transformation in one\u2019s sense of time.</p> <p>The flow state can be entered while performing an activity or task which is wholeheartedly engaged for intrinsic purposes. Three conditions must be met to achieve flow:</p> <ul> <li>The activity must have clear goals and progress.</li> <li>The activity must provide clear and immediate feedback.</li> <li>Perceived balance is required between the challenge level of the activity and one\u2019s skills level. Confidence in the ability to complete the activity is required.</li> </ul> <p>To achieve the flow state, the activity must be challenging enough to engage us but not so easy that it becomes boring or so complicated that it causes anxiety.</p> <p>Consider the graph below, based on Csikszentmihalyi\u2019s flow model, for a visualization of where the flow state resides:</p> Csikszentmihalyi Flow Model <p>Achieving a flow state is a core element in the creative process. Historical sources suggest that Michelangelo (the Italian artist) may have painted the painting on the ceiling of the Sistine Chapel in the Vatican in a state of Flow, that he painted continuously for many days and was so absorbed in his work that he did not stop, to sleep or eat until the last stroke. Bruce Lee also talked about a psychological state like Flow in his book \u201cThe Tao of Jeet Kune Do\u201d. As creative individuals, developers should be able to tap into these same experiences.</p> <p>However, several problems of the model have been discussed in the literature. One is that it does not ensure the perceived balance between challenges and skills which is said to be the central precondition of the flow state. In 2013, Dr. Schaffer proposed seven flow conditions:</p> <ul> <li>Knowing what to do. Start with knowing your skill set and our limitations.</li> <li>Knowing how to do it. You need to know how to do something before you can get into the flow state of mind and do it.</li> <li>Knowing how well one is doing. Knowing how you are doing can help motivate you and increase higher vibration in your life.</li> <li>Knowing where to go (if navigation is involved). You need to know where you are going. Have the end in mind, and always be doing something that helps you get there.</li> <li>High perceived challenges. Challenge yourself. Always be pushing yourself to do better and to be better. Empower yourself to do more and achieve more.</li> <li>High perceived skills. Perceive the skills you want to learn. We all think we want to accomplish in our lives and the skills we need to do it. Take baby steps and step away from frustration.</li> <li>Freedom from distractions. Too many pointless meetings throughout the day, chat distractions, noisy offices, too many context switching etc.</li> </ul>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#why-do-developers-need-to-focus-on-flow-state-rather-than-productivity","title":"Why do developers need to focus on flow state rather than productivity?","text":""},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#flow-state-increases-productivity-and-creativity","title":"Flow state increases productivity and creativity","text":"<p>When developers fully immerse themselves in the activity/task/problem, they significantly increase their productivity, creativity, and performance speed. This is better than establishing productivity metrics and may create the wrong incentives. For example, rewarding developers for the number of completed tasks they do will not provide better quality software.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#flow-state-makes-developers-happy-at-work","title":"Flow state makes developers happy at work","text":"<p>Developers tend to be smart, and maintaining a flow state makes their life easier. Matt Kiernander, technical advocate at Stack Overflow, said \u201cWhen I code, I don\u2019t like disruptions in my flow state. Constantly stopping and starting makes me feel unproductive. We all want to feel like we\u2019re making a difference, and hitting roadblocks at work just because you\u2019re not sure where to find answers is incredibly frustrating.\u201d</p> <p>At Tekos Interactive, we have windows, quiet surroundings, bright natural light, plants, trees, flowers, and a comfortable chair in the office. All in all, Tekos Interactive values flexibility so we could choose between working in the office or from home. We have clearly defined tasks, timelines, and on-time support from the team. All these things make our developers\u2019 lives happier.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#how-to-maintain-the-flow-state","title":"How to maintain the flow state?","text":"<p>Some of the challenges to staying in a flow state include states of apathy, boredom, and anxiety.</p> <ul> <li>The state of apathy = low challenges level + low skill level requirements \u2192 lack of interest in the activity</li> <li>The state of boredom = low challenges level + one\u2019s skill level exceeds those challenges \u2192 one to seek higher challenges</li> <li>The state of anxiety = challenges are high enough to exceed perceived skill level \u2192 distress and uneasiness</li> </ul> <p>These states in general prevent achieving the balance necessary for flow. Cs\u00edkszentmih\u00e1lyi has said, \u201cIf challenges are too low, one gets back to flow by increasing them. If challenges are too great, one can return to the flow state by learning new skills.\u201d</p> <p>At Tekos Interactive, we have all kinds of challenge levels (from internal projects to external clients) with a great team behind us so that it is easy to seek advice or support from seniors or managers. All we have to do is deliver the best values to Tekos Interactive\u2019s clients.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#what-makes-a-great-devex","title":"What makes a great DevEx?","text":"<p>\u201cGreat DevEx is what you get when developers can easily achieve and maintain flow state at work.\u201c Choose flow state as the core goal of a great DevEx can also lead to a number of benefits that contribute to making the team more effective, including:</p> <ul> <li>Improved communication</li> <li>Clearer vision and purpose as a result of better leadership</li> <li>Less time wasted on menial tasks</li> <li>Better hiring and onboarding practices</li> <li>Becoming more attractive to potential hires</li> <li>Fewer redundant processes</li> <li>Better tooling</li> <li>Better-quality outcomes (which in turn can translate to happier customers and more money)</li> <li>Psychological safety</li> <li>Better working environments</li> <li>More streamlined engineering practices</li> </ul> <p>Measuring what hurts developers from achieving and maintaining a flow state is the art of measuring what\u2019s NOT productive.</p> <p>However, too often, companies and their leadership seem to go out of their way to prevent their developers from entering a flow state. Let\u2019s consider again Dr Schaffer\u2019s 7 Flow Conditions:</p> <ol> <li>Knowing what to do \u2192 Leadership lacks vision and doesn\u2019t provide adequate context, or adequate planning.</li> <li>Knowing how to do it \u2192 Engineers have difficulty finding the right tooling, team, or documentation to do their job. Developers are often given tasks out of the scope of their role, such as infrastructure tasks, without meaningful abstractions or good tools, leading to needless cognitive load.</li> <li>Knowing how well one is doing \u2192 Insufficient feedback loops and observability to gauge impact and get feedback tend to leave developers in the dark about their performance.</li> <li>Knowing where to go \u2192 lack of a developer portal, platform, or hub to help orientate developers within the company. Plus, any existing documentation is often disorganized and it is difficult to find relevant information.</li> <li>High perceived challenges \u2192 Developers have to sort through tedious, menial work that\u2019s not challenging or creative. The goals are either too lofty or not engaging enough \u2013 or non-existent.</li> <li>High perceived skills \u2192 Engineers lacking the ability to foster learning or tackle meaningful challenges that build skills relevant to their career goals. Using tooling that\u2019s not relevant to their job or career or drowned in tedious processes that are pointless.</li> <li>Freedom from distractions \u2192 Developer time is taken up by too many pointless meetings peppered throughout the day, Slack distractions, noisy offices, too much context switching etc.</li> </ol> <p>Leadership will do more harm than good by arbitrarily defining what productivity is and forcing it on teams. Leadership instead must aim to implement a culture of measuring everything that hurts the flow state and make it a joint responsibility to improve that \u2013 that\u2019s how you improve the quality of outcomes and yes, indirectly, become productive.</p> <p>At Tekos Interactive, leadership may not be able to make a developer happy in all areas of their life, but it can at least create the best possible condition for flow to occur in their most productive hours, significantly increasing engagement and well-being.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#what-devex-is-not","title":"What DevEx is not?","text":"<p>Now let\u2019s start with some common misconceptions around DevEx.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#devex-as-a-subset-of-ux","title":"DevEx as a Subset of UX","text":"<p>DevEx is not equal to User eXperience (UX), DevEx is a part of UX. UX not only refers to how users interact with a tool, website, or app but also encompasses the entire user journey. Remember, developers are users too \u2013 they are internal users of other teams and tools. The UX of the tooling you pick or create will play a crucial part in your DevEx.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#elevating-devex-a-focus-on-talent","title":"Elevating DevEx: A Focus on Talent","text":"<p>DevEx is not about catering to lazy developers; It\u2019s about hiring the best talent and creating the best conditions for them to work efficiently. DevEx strategy should be based on hiring the best possible people to do the job. Individuals who are eager to learn, self-driven, an adequate cultural fit, and allowing them to get into the flow of work as soon as possible.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#devex-and-ai-a-balanced-approach","title":"DevEx and AI: A Balanced Approach","text":"<p>DevEx is not implementing AI super tools to save money on staff. As mentioned, tooling is also very important when it comes to your DevEx strategy, but that doesn\u2019t mean it can replace high quality contributors. AI tools are just there to make things easier, they are great assistants, but they are decades away from replacing a human being. They will get things wrong a lot of the time and it requires a human to understand and optimize the outputs and use them into a bigger context.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#devex-a-collaborative-approach","title":"DevEx: A Collaborative Approach","text":"<p>DevEx is not just leadership\u2019s responsibility \u2013 it\u2019s a joint engineering effort. It doesn\u2019t matter how much the CEO/CTO preaches about the great DevEx if all the work produced by the engineering team is difficult to use and understand. The important thing is that your entire company learns to see other colleagues and teams as their customers/users and deliver work that makes their job easy.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#reference","title":"Reference:","text":"<ul> <li>https://en.wikipedia.org/wiki/Flow_(psychology)</li> <li>https://stackoverflow.blog/2022/03/17/new-data-what-makes-developers-happy-at-work/</li> <li>https://www.opslevel.com/resources/devex-series-part-1-what-is-devex</li> </ul>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/","title":"Automated Security Scanning Tools for Containerized Environments: Unleashing Your Robot Guardians","text":"<p>So, you're building this awesome containerized kingdom, right? It's like a bustling city of microservices, each living in its own container. But here's the thing: just like any city, you need a strong defense system to keep those pesky intruders out. Don't worry, securing your containers isn't about building an impenetrable fortress, but it's definitely more than just a picket fence. Let's explore some automated security scanning tools that act like vigilant robots, constantly patrolling your kingdom and keeping it safe from harm.</p> <p></p>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/#1-why-automated-security-scanning-for-containers","title":"1. Why Automated Security Scanning for Containers?","text":"<p>Imagine trying to guard your city manually, checking every nook and cranny for potential threats. It's like playing a never-ending game of whack-a-mole, exhausting and inefficient, right? That's where automated security scanning tools come in. They're like your tireless robot guardians, constantly scanning your containers, images, and infrastructure for vulnerabilities, misconfigurations, and security risks.</p>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/#2-types-of-security-scanning-robots","title":"2. Types of Security Scanning Robots","text":"<p>Just like there are different types of robots for different tasks, there are different types of security scanning tools for containers:</p>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/#1-image-scanning","title":"1. Image Scanning:","text":"<p>These robots specialize in inspecting your container images, like those blueprints for your containers. They scan for known vulnerabilities, outdated packages, and insecure configurations, ensuring your images are clean and safe before you even deploy them.</p>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/#2-runtime-scanning","title":"2. Runtime Scanning:","text":"<p>These robots patrol your running containers, monitoring their behavior and detecting any suspicious activity. They can identify malicious processes, network connections, or file system changes, alerting you to potential threats in real-time.</p>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/#3-infrastructure-scanning","title":"3. Infrastructure Scanning:","text":"<p>These robots scan your underlying infrastructure, like the foundations of your city. They check for vulnerabilities in your host operating system, network configurations, and orchestration tools, ensuring your entire environment is secure.</p>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/#3-popular-security-scanning-tools","title":"3. Popular Security Scanning Tools","text":"<p>There are numerous security scanning tools available, each with its own strengths and specialties. Some popular choices include:</p> <ul> <li>Snyk: This versatile tool scans your images, code, and open-source dependencies for vulnerabilities, providing actionable insights and remediation advice.</li> <li>Anchore: This comprehensive tool offers deep image analysis, policy enforcement, and continuous monitoring, ensuring your containers comply with security standards.</li> <li>Trivy: This lightweight and open-source tool scans your images and filesystems for vulnerabilities, providing fast and accurate results.</li> <li>Clair: This powerful tool from CoreOS scans your images for vulnerabilities and provides detailed reports, helping you understand and mitigate risks.</li> </ul>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/#4-integrating-scanning-into-your-cicd-pipeline","title":"4. Integrating Scanning into Your CI/CD Pipeline","text":"<p>Just like you automate those routine tasks in your city, integrate security scanning into your CI/CD pipeline. This way, your robot guardians can automatically scan your images and code with every change, ensuring continuous security without slowing down your development process.</p>"},{"location":"projects/2025/02/02/automated-security-scanning-tools-for-containerized-environments-unleashing-your-robot-guardians/#5-building-a-secure-and-automated-containerized-kingdom","title":"5. Building a Secure and Automated Containerized Kingdom","text":"<p>Automated security scanning tools are essential for securing your containerized environments. By integrating these tools into your CI/CD pipeline and regularly scanning your images, containers, and infrastructure, you can build a secure and resilient kingdom that can withstand the test of time and protect your valuable assets. Remember, security is not an afterthought, it's an ongoing process. So, unleash your robot guardians and let them keep your containerized kingdom safe and sound!</p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/","title":"Automating Deployments with Argo CD on Kubernetes: Conducting Your Deployment Orchestra with Ease","text":"<p>So, you're diving into the world of Kubernetes deployments, and you've heard about this cool tool called Argo CD, right? That's fantastic! Think of Kubernetes as a grand orchestra, with numerous instruments (your applications) playing together. Argo CD is your talented conductor, ensuring every instrument is in tune and playing in perfect harmony.</p> <p></p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#1-why-argo-cd-for-kubernetes-deployments","title":"1. Why Argo CD for Kubernetes Deployments?","text":"<p>Imagine trying to manage a large orchestra without a conductor. Chaos, right? That's where Argo CD comes in. It's like your maestro, automating and orchestrating your Kubernetes deployments, ensuring everything runs smoothly and efficiently.</p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#2-gitops-the-musical-score","title":"2. GitOps: The Musical Score","text":"<p>Argo CD is built on the concept of GitOps, where your Git repository becomes the single source of truth for your deployments. Think of it as your musical score, containing all the instructions for your orchestra. Argo CD continuously monitors your Git repo and automatically applies any changes to your Kubernetes cluster, ensuring your deployments are always in sync with your desired state.</p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#3-declarative-deployments-defining-your-desired-state","title":"3. Declarative Deployments: Defining Your Desired State","text":"<p>With Argo CD, you define your desired state declaratively, using YAML files to describe your applications and their configurations. It's like writing down the sheet music for each instrument, specifying the notes, rhythm, and dynamics. Argo CD takes care of translating your desired state into reality, ensuring your applications are deployed and configured correctly.</p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#4-automated-synchronization-keeping-your-orchestra-in-tune","title":"4. Automated Synchronization: Keeping Your Orchestra in Tune","text":"<p>Argo CD continuously monitors your Kubernetes cluster and compares it to your desired state in Git. If it detects any drift, it automatically takes action to bring your cluster back in sync. It's like your conductor constantly listening to the orchestra, making sure every instrument is playing the right notes at the right time.</p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#5-visualizing-your-deployments-the-orchestral-scoreboard","title":"5. Visualizing Your Deployments: The Orchestral Scoreboard","text":"<p>Argo CD provides a beautiful web UI that visualizes your deployments, showing you the status of your applications, their configurations, and any synchronization issues. It's like having a real-time scoreboard for your orchestra, allowing you to monitor the performance and identify any areas that need attention.</p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#6-health-checks-ensuring-your-instruments-are-in-top-shape","title":"6. Health Checks: Ensuring Your Instruments are in Top Shape","text":"<p>Argo CD allows you to define health checks for your applications, ensuring they are running smoothly and serving their purpose. It's like your conductor checking each instrument before the performance, making sure they are in top shape and ready to play.</p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#7-rollouts-and-rollbacks-graceful-transitions","title":"7. Rollouts and Rollbacks: Graceful Transitions","text":"<p>Argo CD supports various deployment strategies, such as blue/green deployments and canary releases, allowing you to roll out new versions of your applications gradually and safely. It's like your conductor introducing new instruments or musicians to the orchestra, ensuring a smooth transition without disrupting the performance.</p>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#8-beyond-the-basics-advanced-orchestration-techniques","title":"8. Beyond the Basics: Advanced Orchestration Techniques","text":"<p>Once you've mastered the basics, Argo CD offers a range of advanced features, such as:</p> <ul> <li>Automated sync waves: Orchestrate complex deployments with multiple applications and dependencies.</li> <li>PreSync and PostSync hooks: Execute custom scripts before and after deployments.</li> <li>SSO integration: Securely manage access to your Argo CD instance.</li> <li>Observability: Integrate with monitoring tools for deeper insights into your deployments.</li> </ul>"},{"location":"projects/2025/01/19/automating-deployments-with-argo-cd-on-kubernetes-conducting-your-deployment-orchestra-with-ease/#9-ready-to-conduct","title":"9. Ready to Conduct?","text":"<p>Automating deployments with Argo CD on Kubernetes might seem daunting at first, but with a little practice and guidance, it's like conducting a well-rehearsed orchestra. Define your desired state, let Argo CD handle the synchronization, and enjoy the harmony of automated deployments.</p> <p>So, what are you waiting for? Grab your conductor's baton and start orchestrating your deployments with Argo CD!</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/","title":"Best Practices for Securing Containerized Workloads: Shielding Your Precious Cargo on the Open Seas","text":"<p>So, you're shipping your valuable applications in these awesome containers, right? It's like sending your precious cargo on a grand voyage across the open seas. But here's the thing: just like any ship, you need to protect your cargo from pirates, storms, and other dangers. Don't worry, securing your containerized workloads isn't about building an impenetrable fortress, but it's definitely more than just a flimsy raft. Let's explore some best practices to keep your cargo safe and sound on its journey.</p> <p></p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#1-choose-the-right-vessel-secure-base-images","title":"1. Choose the Right Vessel: Secure Base Images","text":"<p>Imagine your container is like a ship. You wouldn't want to set sail on a rickety old vessel, right? Same goes for your base images. Choose those sturdy and well-maintained ones, like those from trusted sources like official repositories or reputable vendors. They're like those reliable ships, built with security in mind and regularly inspected for vulnerabilities.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#2-minimize-your-load-reduce-your-attack-surface","title":"2. Minimize Your Load: Reduce Your Attack Surface","text":"<p>Imagine your ship is carrying a mountain of unnecessary cargo. It makes it harder to maneuver, right? Same goes for your containers. Minimize your load by only including the essential components your application needs. It's like packing light for your voyage, reducing the chances of something going wrong or getting lost.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#3-secure-your-crew-principle-of-least-privilege","title":"3. Secure Your Crew: Principle of Least Privilege","text":"<p>Imagine your ship's crew has access to everything on board, even the captain's quarters. Not a good idea, huh? Same goes for your containers. Follow the principle of least privilege, granting only the necessary permissions to your applications and users. It's like assigning roles and responsibilities to your crew, ensuring everyone has access to only what they need to do their job.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#4-seal-the-hatches-secure-your-secrets","title":"4. Seal the Hatches: Secure Your Secrets","text":"<p>Imagine your ship's treasure chest is left unlocked and unguarded. That's a recipe for disaster, right? Same goes for your secrets, like those passwords, API keys, and certificates. Don't leave them exposed in your containers or environment variables. Use secrets management tools like HashiCorp Vault or AWS Secrets Manager to store and manage your secrets securely. It's like locking up your treasure chest and giving the key to only those you trust.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#5-keep-watch-monitoring-and-logging","title":"5. Keep Watch: Monitoring and Logging","text":"<p>Imagine your ship has no lookout or radar. You'd be sailing blind, right? Same goes for your containerized workloads. Monitor your containers and their activity for suspicious behavior, performance issues, or potential breaches. Use monitoring and logging tools like Datadog, Prometheus, or AWS CloudWatch to get a clear view of what's happening on your ship.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#6-chart-your-course-network-security","title":"6. Chart Your Course: Network Security","text":"<p>Imagine your ship has no navigation system or maps. You'd be lost at sea, right? Same goes for your containerized workloads. Secure your network by using firewalls, network policies, and secure configurations. It's like charting your course and setting up safe routes for your containers to communicate with each other and the outside world.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#7-weather-the-storms-vulnerability-scanning","title":"7. Weather the Storms: Vulnerability Scanning","text":"<p>Imagine your ship is sailing through a storm without any weather forecast. That's risky, right? Same goes for your containerized workloads. Regularly scan your images and containers for vulnerabilities, using tools like Snyk, Anchore, or Trivy. It's like checking the weather forecast and making sure your ship is prepared for any storms that might come your way.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#8-stay-alert-intrusion-detection","title":"8. Stay Alert: Intrusion Detection","text":"<p>Imagine your ship has no alarm system or security personnel. You'd be vulnerable to pirates, right? Same goes for your containerized workloads. Implement intrusion detection systems and security tools to detect and respond to potential attacks. It's like having a security team on board, ready to defend your ship from any intruders.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#9-continuous-improvement-learn-from-your-voyages","title":"9. Continuous Improvement: Learn from Your Voyages","text":"<p>Imagine your ship returns from a voyage with valuable lessons learned. You'd use those lessons to improve your next journey, right? Same goes for securing your containerized workloads. Continuously learn from your experiences, security incidents, and industry best practices. It's like keeping a logbook of your voyages, documenting your successes and challenges to improve your future security posture.</p>"},{"location":"projects/2025/02/09/best-practices-for-securing-containerized-workloads-shielding-your-precious-cargo-on-the-open-seas/#sailing-towards-secure-horizons","title":"Sailing Towards Secure Horizons","text":"<p>Securing your containerized workloads is an ongoing journey, not a destination. By following these best practices, you can ensure your precious cargo reaches its destination safely and securely. Remember, it's not about building an impenetrable fortress, but about creating a resilient and adaptable security strategy that evolves with your needs. So, set sail with confidence, knowing that your containerized workloads are protected on their voyage across the open seas.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/","title":"Building a Data Lakehouse with Databricks and Snowflake: Constructing Your Data Mansion","text":"<p>So, you're ready to build a data lakehouse, huh? That's fantastic! Think of a data lakehouse as a magnificent mansion for your data, combining the best features of a data lake and a data warehouse. It's like having a spacious and flexible living space where your data can relax, mingle, and be easily accessed by everyone who needs it. Databricks and Snowflake are your trusted architects and builders, providing the tools and expertise to construct your data mansion.</p> <p></p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#1-why-a-data-lakehouse","title":"1. Why a Data Lakehouse?","text":"<p>Imagine storing your data in a cluttered and disorganized warehouse, where it's hard to find what you need. That's the traditional data warehouse approach. Now, imagine having a sprawling data lake, where your data can roam freely, but it's hard to organize and access efficiently. That's the data lake approach.</p> <p>A data lakehouse combines the best of both worlds. It's like having a well-organized mansion with different rooms for different types of data, but with the flexibility to add new rooms and rearrange furniture as your needs evolve.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#2-databricks-your-data-architect","title":"2. Databricks: Your Data Architect","text":"<p>Databricks is like your expert data architect, providing a platform for data engineering, machine learning, and data science. It's like having a team of skilled designers and engineers who can help you structure your data, build pipelines, and create analytical models.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#3-snowflake-your-data-builder","title":"3. Snowflake: Your Data Builder","text":"<p>Snowflake is like your master data builder, providing a cloud-based data platform that's scalable, secure, and easy to use. It's like having a team of construction workers who can quickly and efficiently build your data mansion, ensuring it's strong, reliable, and ready for your data to move in.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#4-building-the-foundation-data-ingestion","title":"4. Building the Foundation: Data Ingestion","text":"<p>Before you start building your data mansion, you need to gather all your data from various sources. Databricks and Snowflake offer tools for data ingestion, allowing you to connect to different data sources, such as databases, cloud storage, and streaming platforms. It's like gathering all the building materials and furniture for your mansion.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#5-structuring-the-rooms-data-organization","title":"5. Structuring the Rooms: Data Organization","text":"<p>Once you have your data, you need to organize it into different rooms or zones within your data lakehouse. Databricks and Snowflake provide features for data organization, such as tables, views, and schemas. It's like designing the layout of your mansion, creating different rooms for different purposes, such as a living room for structured data, a library for unstructured data, and a game room for semi-structured data.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#6-accessing-the-data-data-sharing-and-collaboration","title":"6. Accessing the Data: Data Sharing and Collaboration","text":"<p>A data lakehouse is not just about storing data; it's also about sharing and collaborating with others. Databricks and Snowflake offer features for data sharing and collaboration, allowing you to easily share your data with other teams, partners, or customers. It's like inviting guests to your mansion, providing them with comfortable spaces to work and interact with your data.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#7-maintaining-the-mansion-data-governance-and-security","title":"7. Maintaining the Mansion: Data Governance and Security","text":"<p>Just like any mansion, your data lakehouse needs regular maintenance and upkeep to ensure it remains secure and organized. Databricks and Snowflake provide features for data governance and security, such as access control, data masking, and auditing. It's like having a team of housekeepers and security guards who keep your mansion clean, safe, and well-maintained.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#8-moving-in-data-analytics-and-machine-learning","title":"8. Moving In: Data Analytics and Machine Learning","text":"<p>Once your data mansion is built, it's time to move in and start using your data! Databricks and Snowflake offer tools for data analytics and machine learning, allowing you to explore your data, build dashboards, and create predictive models. It's like hosting parties and events in your mansion, inviting guests to enjoy your data and discover new insights.</p>"},{"location":"projects/2025/01/12/building-a-data-lakehouse-with-databricks-and-snowflake-constructing-your-data-mansion/#9-building-your-data-dream-home","title":"9. Building Your Data Dream Home","text":"<p>Building a data lakehouse with Databricks and Snowflake might seem like a daunting task, but with the right mindset and tools, it's an achievable goal. Start with a clear vision, gather your data, structure your rooms, and invite your guests. And remember, Databricks and Snowflake are your trusted partners, providing the expertise and support to build your data dream home.</p> <p>So, what are you waiting for? Let's start building your data mansion today!</p>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/","title":"Docker Security: Keepin' Your Containers Safe (and Cozy)","text":"<p>So, you've got these awesome Docker containers running your apps, right? But here's the thing: just like your house needs locks and alarms, your containers need some security love too. Don't worry, it's not rocket science. Let's break it down, nice and easy.</p> <p></p>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#1-updates-updates-updates","title":"1. Updates, Updates, Updates!","text":"<p>Think of Docker updates like those software updates on your phone. They often have those pesky security patches that keep the bad guys out. So, keep your Docker engine and all its buddies up-to-date, okay?</p> Update that Docker engine!<pre><code>sudo apt-get update &amp;&amp; sudo apt-get install docker-ce docker-ce-cli containerd.io\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#2-slim-down-those-images","title":"2. Slim Down Those Images","text":"<p>Imagine your container is like a backpack. You don't want to carry a bunch of junk you don't need, right? Same goes for Docker images. Use those \"minimal\" ones like alpine or distroless. They're like those lightweight backpacks \u2013 just the essentials, no extra baggage.</p> Dockerfile<pre><code>FROM alpine:latest\n# Your app's instructions go here\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#3-dont-give-em-the-keys-to-the-kingdom","title":"3. Don't Give 'Em the Keys to the Kingdom","text":"<p>Running containers as \"root\" is like giving everyone the keys to your house. Not a good idea, huh? Create a special user for your app, kinda like giving your friend a key to just their room.</p> Dockerfile<pre><code># Create a user, just for your app\nRUN adduser -D myuser\nUSER myuser\n# Your app's instructions go here\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#4-set-some-limits","title":"4. Set Some Limits","text":"<p>Imagine your app is like a kid in a candy store. You gotta set some limits, right? Same with Docker. Set those CPU and memory limits so your app doesn't gobble up all the resources.</p> <pre><code>docker run --cpus=\"1\" --memory=\"512m\" my-image\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#5-secret-stash-for-sensitive-stuff","title":"5. Secret Stash for Sensitive Stuff","text":"<p>Don't leave your passwords and secret codes lying around, right? Same goes for your Docker images. Use those \"Docker Secrets\" \u2013 it's like a super safe vault for your sensitive stuff.</p> Create a secret, shhh...<pre><code>echo \"mysecret\" | docker secret create my_secret -\n</code></pre> Use the secret in your Docker Compose file<pre><code>services:\n  my-service:\n    secrets:\n      - my_secret\nsecrets:\n  my_secret:\n    external: true\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#6-scan-for-those-sneaky-vulnerabilities","title":"6. Scan for Those Sneaky Vulnerabilities","text":"<p>Think of vulnerability scanners like those security guards at the mall. They're always on the lookout for trouble. Use tools like Trivy, Clair, or Snyk to scan your images for those sneaky vulnerabilities.</p> Trivy to the rescue!<pre><code>trivy image my-image\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#7-network-lockdown","title":"7. Network Lockdown","text":"<p>Your Docker network is like the neighborhood your container lives in. You want some fences and security cameras, right? Use Docker's network features to keep things separated and secure.</p> <ul> <li>Custom Networks: Like having your own little gated community.</li> <li>Firewall Rules: Think of these as your security guards, controlling who comes and goes.</li> <li>Don't Open Too Many Doors: Only expose the ports your app really needs, like locking up those extra doors in your house.</li> </ul> Dockerfile<pre><code>EXPOSE 8080\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#8-read-only-please","title":"8. Read-Only, Please!","text":"<p>Imagine your app's files are like those precious family photos. You don't want anyone messing with them, right? Mount your app's filesystem as \"read-only\" to keep those files safe and sound.</p> <pre><code>docker run --read-only my-image\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#9-content-trust-verify-then-trust","title":"9. Content Trust: Verify, Then Trust","text":"<p>Think of \"Content Trust\" as verifying someone's ID before letting them in. Enable Docker Content Trust to make sure those images you're pulling are the real deal.</p> <pre><code>export DOCKER_CONTENT_TRUST=1\ndocker pull my-trusted-image\n</code></pre>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#10-keep-an-eye-on-things","title":"10. Keep an Eye on Things","text":"<p>Just like you check your house for anything suspicious, you gotta keep an eye on your Docker containers. Use those logging and monitoring tools to spot any weird activity.</p>"},{"location":"projects/2024/12/01/docker-security-keepin-your-containers-safe-and-cozy/#wrapping-it-up","title":"Wrapping It Up","text":"<p>Securing your Docker containers is like building a fortress around your apps. It's all about layers of protection, you know? Keep things updated, use those minimal images, and don't forget to scan for those sneaky vulnerabilities. And hey, if you ever need a hand, you know where to find me \ud83d\ude09.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/","title":"Flow state: The heart of Developer Experience (DevEx)","text":"<p>\u201cHave you ever been so immersed in something that you forgot about time, hunger or even sleep?\u201d If your answer is yes, that you have entered the flow state.</p> <p></p> <ul> <li>Thanks to  for supporting this content.</li> </ul>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#introduction","title":"Introduction","text":"<p>In this article, you will learn about:</p> <ul> <li>What is the flow state actually?</li> <li>Why is flow state so important to developers at work?</li> <li>How to maintain the flow state at work?</li> <li>Why choose flow state as the core goal in the great DevEx?</li> <li>Some misconceptions around DevEx?</li> </ul>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#what-is-the-flow-state","title":"What is the flow state?","text":"<p>Named by the psychologist Mih\u00e1ly Cs\u00edkszentmih\u00e1lyi in 1970, the flow state in positive psychology, also known as \u201cbeing in the zone\u201d, or \u201cdeep work\u201d is the mental state in which a person performing some activities is fully immersed in a feeling of energized focus, full involvement, and enjoyment in the process of the activity. In essence, flow is characterized by the complete absorption in what one does and a resulting transformation in one\u2019s sense of time.</p> <p>The flow state can be entered while performing an activity or task which is wholeheartedly engaged for intrinsic purposes. Three conditions must be met to achieve flow:</p> <ul> <li>The activity must have clear goals and progress.</li> <li>The activity must provide clear and immediate feedback.</li> <li>Perceived balance is required between the challenge level of the activity and one\u2019s skills level. Confidence in the ability to complete the activity is required.</li> </ul> <p>To achieve the flow state, the activity must be challenging enough to engage us but not so easy that it becomes boring or so complicated that it causes anxiety.</p> <p>Consider the graph below, based on Csikszentmihalyi\u2019s flow model, for a visualization of where the flow state resides:</p> Csikszentmihalyi Flow Model <p>Achieving a flow state is a core element in the creative process. Historical sources suggest that Michelangelo (the Italian artist) may have painted the painting on the ceiling of the Sistine Chapel in the Vatican in a state of Flow, that he painted continuously for many days and was so absorbed in his work that he did not stop, to sleep or eat until the last stroke. Bruce Lee also talked about a psychological state like Flow in his book \u201cThe Tao of Jeet Kune Do\u201d. As creative individuals, developers should be able to tap into these same experiences.</p> <p>However, several problems of the model have been discussed in the literature. One is that it does not ensure the perceived balance between challenges and skills which is said to be the central precondition of the flow state. In 2013, Dr. Schaffer proposed seven flow conditions:</p> <ul> <li>Knowing what to do. Start with knowing your skill set and our limitations.</li> <li>Knowing how to do it. You need to know how to do something before you can get into the flow state of mind and do it.</li> <li>Knowing how well one is doing. Knowing how you are doing can help motivate you and increase higher vibration in your life.</li> <li>Knowing where to go (if navigation is involved). You need to know where you are going. Have the end in mind, and always be doing something that helps you get there.</li> <li>High perceived challenges. Challenge yourself. Always be pushing yourself to do better and to be better. Empower yourself to do more and achieve more.</li> <li>High perceived skills. Perceive the skills you want to learn. We all think we want to accomplish in our lives and the skills we need to do it. Take baby steps and step away from frustration.</li> <li>Freedom from distractions. Too many pointless meetings throughout the day, chat distractions, noisy offices, too many context switching etc.</li> </ul>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#why-do-developers-need-to-focus-on-flow-state-rather-than-productivity","title":"Why do developers need to focus on flow state rather than productivity?","text":""},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#flow-state-increases-productivity-and-creativity","title":"Flow state increases productivity and creativity","text":"<p>When developers fully immerse themselves in the activity/task/problem, they significantly increase their productivity, creativity, and performance speed. This is better than establishing productivity metrics and may create the wrong incentives. For example, rewarding developers for the number of completed tasks they do will not provide better quality software.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#flow-state-makes-developers-happy-at-work","title":"Flow state makes developers happy at work","text":"<p>Developers tend to be smart, and maintaining a flow state makes their life easier. Matt Kiernander, technical advocate at Stack Overflow, said \u201cWhen I code, I don\u2019t like disruptions in my flow state. Constantly stopping and starting makes me feel unproductive. We all want to feel like we\u2019re making a difference, and hitting roadblocks at work just because you\u2019re not sure where to find answers is incredibly frustrating.\u201d</p> <p>At Tekos Interactive, we have windows, quiet surroundings, bright natural light, plants, trees, flowers, and a comfortable chair in the office. All in all, Tekos Interactive values flexibility so we could choose between working in the office or from home. We have clearly defined tasks, timelines, and on-time support from the team. All these things make our developers\u2019 lives happier.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#how-to-maintain-the-flow-state","title":"How to maintain the flow state?","text":"<p>Some of the challenges to staying in a flow state include states of apathy, boredom, and anxiety.</p> <ul> <li>The state of apathy = low challenges level + low skill level requirements \u2192 lack of interest in the activity</li> <li>The state of boredom = low challenges level + one\u2019s skill level exceeds those challenges \u2192 one to seek higher challenges</li> <li>The state of anxiety = challenges are high enough to exceed perceived skill level \u2192 distress and uneasiness</li> </ul> <p>These states in general prevent achieving the balance necessary for flow. Cs\u00edkszentmih\u00e1lyi has said, \u201cIf challenges are too low, one gets back to flow by increasing them. If challenges are too great, one can return to the flow state by learning new skills.\u201d</p> <p>At Tekos Interactive, we have all kinds of challenge levels (from internal projects to external clients) with a great team behind us so that it is easy to seek advice or support from seniors or managers. All we have to do is deliver the best values to Tekos Interactive\u2019s clients.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#what-makes-a-great-devex","title":"What makes a great DevEx?","text":"<p>\u201cGreat DevEx is what you get when developers can easily achieve and maintain flow state at work.\u201c Choose flow state as the core goal of a great DevEx can also lead to a number of benefits that contribute to making the team more effective, including:</p> <ul> <li>Improved communication</li> <li>Clearer vision and purpose as a result of better leadership</li> <li>Less time wasted on menial tasks</li> <li>Better hiring and onboarding practices</li> <li>Becoming more attractive to potential hires</li> <li>Fewer redundant processes</li> <li>Better tooling</li> <li>Better-quality outcomes (which in turn can translate to happier customers and more money)</li> <li>Psychological safety</li> <li>Better working environments</li> <li>More streamlined engineering practices</li> </ul> <p>Measuring what hurts developers from achieving and maintaining a flow state is the art of measuring what\u2019s NOT productive.</p> <p>However, too often, companies and their leadership seem to go out of their way to prevent their developers from entering a flow state. Let\u2019s consider again Dr Schaffer\u2019s 7 Flow Conditions:</p> <ol> <li>Knowing what to do \u2192 Leadership lacks vision and doesn\u2019t provide adequate context, or adequate planning.</li> <li>Knowing how to do it \u2192 Engineers have difficulty finding the right tooling, team, or documentation to do their job. Developers are often given tasks out of the scope of their role, such as infrastructure tasks, without meaningful abstractions or good tools, leading to needless cognitive load.</li> <li>Knowing how well one is doing \u2192 Insufficient feedback loops and observability to gauge impact and get feedback tend to leave developers in the dark about their performance.</li> <li>Knowing where to go \u2192 lack of a developer portal, platform, or hub to help orientate developers within the company. Plus, any existing documentation is often disorganized and it is difficult to find relevant information.</li> <li>High perceived challenges \u2192 Developers have to sort through tedious, menial work that\u2019s not challenging or creative. The goals are either too lofty or not engaging enough \u2013 or non-existent.</li> <li>High perceived skills \u2192 Engineers lacking the ability to foster learning or tackle meaningful challenges that build skills relevant to their career goals. Using tooling that\u2019s not relevant to their job or career or drowned in tedious processes that are pointless.</li> <li>Freedom from distractions \u2192 Developer time is taken up by too many pointless meetings peppered throughout the day, Slack distractions, noisy offices, too much context switching etc.</li> </ol> <p>Leadership will do more harm than good by arbitrarily defining what productivity is and forcing it on teams. Leadership instead must aim to implement a culture of measuring everything that hurts the flow state and make it a joint responsibility to improve that \u2013 that\u2019s how you improve the quality of outcomes and yes, indirectly, become productive.</p> <p>At Tekos Interactive, leadership may not be able to make a developer happy in all areas of their life, but it can at least create the best possible condition for flow to occur in their most productive hours, significantly increasing engagement and well-being.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#what-devex-is-not","title":"What DevEx is not?","text":"<p>Now let\u2019s start with some common misconceptions around DevEx.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#devex-as-a-subset-of-ux","title":"DevEx as a Subset of UX","text":"<p>DevEx is not equal to User eXperience (UX), DevEx is a part of UX. UX not only refers to how users interact with a tool, website, or app but also encompasses the entire user journey. Remember, developers are users too \u2013 they are internal users of other teams and tools. The UX of the tooling you pick or create will play a crucial part in your DevEx.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#elevating-devex-a-focus-on-talent","title":"Elevating DevEx: A Focus on Talent","text":"<p>DevEx is not about catering to lazy developers; It\u2019s about hiring the best talent and creating the best conditions for them to work efficiently. DevEx strategy should be based on hiring the best possible people to do the job. Individuals who are eager to learn, self-driven, an adequate cultural fit, and allowing them to get into the flow of work as soon as possible.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#devex-and-ai-a-balanced-approach","title":"DevEx and AI: A Balanced Approach","text":"<p>DevEx is not implementing AI super tools to save money on staff. As mentioned, tooling is also very important when it comes to your DevEx strategy, but that doesn\u2019t mean it can replace high quality contributors. AI tools are just there to make things easier, they are great assistants, but they are decades away from replacing a human being. They will get things wrong a lot of the time and it requires a human to understand and optimize the outputs and use them into a bigger context.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#devex-a-collaborative-approach","title":"DevEx: A Collaborative Approach","text":"<p>DevEx is not just leadership\u2019s responsibility \u2013 it\u2019s a joint engineering effort. It doesn\u2019t matter how much the CEO/CTO preaches about the great DevEx if all the work produced by the engineering team is difficult to use and understand. The important thing is that your entire company learns to see other colleagues and teams as their customers/users and deliver work that makes their job easy.</p>"},{"location":"projects/2025/01/01/flow-state-the-heart-of-developer-experience-devex/#reference","title":"Reference:","text":"<ul> <li>https://en.wikipedia.org/wiki/Flow_(psychology)</li> <li>https://stackoverflow.blog/2022/03/17/new-data-what-makes-developers-happy-at-work/</li> <li>https://www.opslevel.com/resources/devex-series-part-1-what-is-devex</li> </ul>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/","title":"GitHub Actions for DevSecOps: Assembling Your Superhero Squad to Secure and Automate Your Code","text":"<p>So, you're diving into the exciting world of DevSecOps, and you've heard about GitHub Actions, right? That's fantastic! Think of GitHub Actions as your superhero team, ready to automate your workflows, secure your code, and fight off those pesky villains (bugs and vulnerabilities).</p> <p></p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#1-why-github-actions-for-devsecops","title":"1. Why GitHub Actions for DevSecOps?","text":"<p>Imagine trying to protect your code and automate your workflows manually. It's like fighting off villains one by one, exhausting and inefficient, right? That's where GitHub Actions comes in. It's like having a team of superheroes with unique powers, working together to automate your tasks, secure your code, and keep your projects safe.</p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#2-workflows-your-superhero-missions","title":"2. Workflows: Your Superhero Missions","text":"<p>GitHub Actions uses workflows, which are like missions for your superhero team. Each workflow is defined in a YAML file, where you specify the triggers, jobs, and steps to be executed. It's like writing down the battle plan for your superheroes, outlining their roles and responsibilities.</p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#3-actions-your-superhero-powers","title":"3. Actions: Your Superhero Powers","text":"<p>Actions are the individual superpowers of your superheroes. They are reusable units of code that perform specific tasks, such as building your code, running tests, scanning for vulnerabilities, or deploying your application. It's like each superhero having a unique ability, such as super strength, invisibility, or teleportation.</p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#4-runners-your-superhero-headquarters","title":"4. Runners: Your Superhero Headquarters","text":"<p>Runners are the environments where your superheroes operate. They can be virtual machines, containers, or even your own servers. It's like having a secret headquarters where your superheroes gather, strategize, and execute their missions.</p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#5-devsecops-with-github-actions-supercharging-your-security","title":"5. DevSecOps with GitHub Actions: Supercharging Your Security","text":"<p>GitHub Actions is a powerful tool for DevSecOps, allowing you to integrate security into every stage of your development lifecycle. It's like having a dedicated security team within your superhero squad, constantly monitoring your code, scanning for vulnerabilities, and protecting your projects from threats.</p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#6-automating-security-checks-super-scanning-your-code","title":"6. Automating Security Checks: Super-Scanning Your Code","text":"<p>With GitHub Actions, you can automate security checks by integrating tools like Snyk, CodeQL, or SonarQube into your workflows. It's like having your superheroes scan your code for weaknesses, identifying potential vulnerabilities before they can cause harm.</p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#7-continuous-security-always-on-guard","title":"7. Continuous Security: Always on Guard","text":"<p>GitHub Actions allows you to implement continuous security by running security checks on every code change or pull request. It's like having your superheroes constantly patrolling your codebase, ensuring that every line of code is secure and compliant.</p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#8-automated-deployments-super-fast-delivery","title":"8. Automated Deployments: Super-Fast Delivery","text":"<p>GitHub Actions can also automate your deployments, making it easy to deploy your applications to various environments, such as staging or production. It's like having your superheroes deliver your code to its destination with lightning speed and precision.</p>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#9-beyond-the-basics-advanced-superhero-training","title":"9. Beyond the Basics: Advanced Superhero Training","text":"<p>Once you've mastered the basics, GitHub Actions offers a range of advanced features, such as:</p> <ul> <li>Custom Actions: Create your own superpowers to automate specific tasks.</li> <li>Secrets Management: Securely store and manage your sensitive information.</li> <li>Workflow Visualization: Monitor your workflows and track their progress.</li> <li>Community Actions: Leverage the power of the GitHub community and use pre-built actions for common tasks.</li> </ul>"},{"location":"projects/2025/01/26/github-actions-for-devsecops-assembling-your-superhero-squad-to-secure-and-automate-your-code/#10-ready-to-assemble-your-team","title":"10. Ready to Assemble Your Team?","text":"<p>GitHub Actions for DevSecOps might seem like a complex operation, but with a little practice and guidance, it's like assembling a team of superheroes to protect your code and automate your workflows. Define your workflows, leverage the power of actions, and watch your DevSecOps practices soar to new heights.</p> <p>So, what are you waiting for? Assemble your superhero squad and let GitHub Actions supercharge your DevSecOps journey!</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/","title":"Implementing IaC for Multi-Environment Deployments with Terraspace: Your Blueprint for Building a Multi-Stage Infrastructure Masterpiece","text":"<p>So, you're ready to take your infrastructure game to the next level with IaC and Terraspace, right? That's fantastic! Think of it like constructing a magnificent building, where you carefully plan each stage and ensure everything fits together seamlessly. Terraspace is your trusted blueprint, guiding you through the process.</p> <p></p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#1-why-iac-and-multi-environment-deployments","title":"1. Why IaC and Multi-Environment Deployments?","text":"<p>Imagine building a complex structure without blueprints or a clear plan. Chaos, right? That's where IaC comes in. It's like having a detailed blueprint that defines your infrastructure as code, making it repeatable, scalable, and version-controlled.</p> <p>Now, imagine building different versions of your structure for different purposes. You might want a smaller model for testing, a larger one for staging, and the final grand masterpiece for production. That's where multi-environment deployments come in. It's like having separate blueprints for each stage, ensuring smooth transitions and minimizing surprises.</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#2-terraspace-your-master-builder-toolkit","title":"2. Terraspace: Your Master Builder Toolkit","text":"<p>Terraspace is like your master builder toolkit, packed with features to streamline your IaC journey. It helps you organize your code, manage different environments, and automate deployments. Think of it as your trusty toolbox, filled with all the essential tools to bring your infrastructure vision to life.</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#3-building-your-foundation-project-structure","title":"3. Building Your Foundation: Project Structure","text":"<p>Before you start laying bricks, you need a solid foundation. Terraspace helps you organize your IaC code into modules, stacks, and environments. It's like dividing your blueprint into sections for different parts of your structure, making it easy to manage and maintain.</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#4-laying-the-bricks-defining-your-infrastructure","title":"4. Laying the Bricks: Defining Your Infrastructure","text":"<p>Now comes the exciting part: defining your infrastructure as code. With Terraspace, you can use familiar tools like Terraform to describe your resources, from virtual machines and networks to databases and load balancers. It's like writing down the specifications for each brick and how they connect.</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#5-staging-your-masterpiece-multi-environment-deployments","title":"5. Staging Your Masterpiece: Multi-Environment Deployments","text":"<p>Terraspace makes it easy to deploy your infrastructure to different environments, like development, staging, and production. It's like having separate blueprints for each stage, allowing you to test and refine your infrastructure before going live.</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#6-automating-the-construction-cicd-integration","title":"6. Automating the Construction: CI/CD Integration","text":"<p>Imagine having a team of automated builders that tirelessly work to construct your infrastructure based on your blueprints. That's where CI/CD integration comes in. Terraspace seamlessly integrates with popular CI/CD tools, allowing you to automate deployments and ensure consistency across environments.</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#7-scaling-your-masterpiece-modularity-and-reusability","title":"7. Scaling Your Masterpiece: Modularity and Reusability","text":"<p>As your infrastructure grows, you want to avoid repetition and ensure consistency. Terraspace promotes modularity and reusability, allowing you to create reusable components and easily scale your infrastructure. It's like having pre-fabricated building blocks that you can assemble and customize for different parts of your structure.</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#8-embracing-the-journey-continuous-improvement","title":"8. Embracing the Journey: Continuous Improvement","text":"<p>Building a masterpiece is an ongoing process. Terraspace encourages continuous improvement by providing tools for testing, version control, and collaboration. It's like having a team of architects and engineers constantly refining your blueprints and construction techniques.</p>"},{"location":"projects/2024/12/22/implementing-iac-for-multi-environment-deployments-with-terraspace-your-blueprint-for-building-a-multi-stage-infrastructure-masterpiece/#9-ready-to-build","title":"9. Ready to Build?","text":"<p>Implementing IaC for multi-environment deployments with Terraspace might seem like a daunting task, but with the right mindset and tools, it's an achievable goal. Start with a solid foundation, define your infrastructure clearly, and embrace automation. And remember, I'm here to guide you through the process, ensuring your infrastructure masterpiece stands tall and proud.</p> <p>So, what are you waiting for? Let's start building!</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/","title":"Integrating SAST and DAST into Your CI/CD Pipeline: Spicing Up Your Pipeline with Security Goodness","text":"<p>So, you're building this awesome CI/CD pipeline, right? It's like a well-oiled machine, churning out those delicious software releases. But here's the thing: just like any good chef, you want to make sure your ingredients are fresh and safe, and your kitchen is spotless. That's where SAST and DAST come in. They're like those secret spices that add an extra layer of security flavor to your pipeline, ensuring your software is not only tasty but also safe to consume.</p> <p></p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#1-sast-your-code-inspector","title":"1. SAST: Your Code Inspector","text":"<p>Imagine having a meticulous inspector in your kitchen, carefully examining every ingredient before you even start cooking. That's SAST, or Static Application Security Testing. It's like a code detective, scanning your source code for potential vulnerabilities, like those hidden bugs or security loopholes that could spoil your dish.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#2-dast-your-taste-tester","title":"2. DAST: Your Taste Tester","text":"<p>Now, imagine having a professional taste tester who samples your dish at different stages of cooking, making sure it's not only delicious but also safe to eat. That's DAST, or Dynamic Application Security Testing. It's like a security guard, testing your running application for vulnerabilities that might not be visible in the code itself, like those sneaky SQL injections or cross-site scripting attacks.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#3-why-bother-with-sast-and-dast","title":"3. Why Bother with SAST and DAST?","text":"<p>You might be thinking, \"Why all this fuss about security? Can't I just focus on making my software work?\" Well, imagine serving a dish that looks and tastes great but gives everyone food poisoning. Not a good look, right? Same goes for software. Security vulnerabilities can lead to data breaches, system crashes, and a whole lot of headaches.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#4-integrating-sast-and-dast-into-your-pipeline","title":"4. Integrating SAST and DAST into Your Pipeline","text":"<p>Now, let's talk about how to add those security spices to your CI/CD pipeline. It's like adding those secret ingredients at different stages of your cooking process.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#1-sast-early-and-often","title":"1. SAST: Early and Often","text":"<p>Just like you inspect your ingredients before you start cooking, integrate SAST early in your pipeline, ideally during the development phase. This way, you can catch those vulnerabilities early on, before they become a bigger problem.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#2-dast-test-in-a-safe-environment","title":"2. DAST: Test in a Safe Environment","text":"<p>You wouldn't want your taste tester to sample your dish in a dirty kitchen, right? Same goes for DAST. Run your DAST tests in a dedicated staging environment that mimics your production environment, so you can catch those vulnerabilities without affecting your live application.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#3-automate-automate-automate","title":"3. Automate, Automate, Automate","text":"<p>Just like you automate those repetitive tasks in your kitchen, automate your SAST and DAST scans. Integrate them into your CI/CD pipeline so they run automatically with every code change or deployment. This way, you can ensure continuous security testing without slowing down your development process.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#4-dont-just-scan-fix","title":"4. Don't Just Scan, Fix!","text":"<p>Finding vulnerabilities is only half the battle. You need to fix them too! Integrate your SAST and DAST tools with your issue tracking system so you can track and remediate those vulnerabilities efficiently.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#5-continuous-learning-and-improvement","title":"5. Continuous Learning and Improvement","text":"<p>Just like any good chef, you're always learning and improving your recipes, right? Same goes for security. Stay updated with the latest security threats and vulnerabilities, and continuously refine your SAST and DAST strategies.</p>"},{"location":"projects/2025/01/05/integrating-sast-and-dast-into-your-cicd-pipeline-spicing-up-your-pipeline-with-security-goodness/#5-serving-up-secure-software","title":"5. Serving Up Secure Software","text":"<p>By integrating SAST and DAST into your CI/CD pipeline, you're not only adding those secret security spices but also ensuring your software is safe and delicious for your users. Remember, security is not an afterthought, it's an essential ingredient in the software development process. So, spice up your pipeline with SAST and DAST, and serve up secure software that your users will love!</p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/","title":"Kubernetes Networking: A Practical Guide (No Jargon, Just the Good Stuff)","text":"<p>So, you're venturing into the land of Kubernetes, huh? That's awesome! But let's be real, Kubernetes networking can feel like navigating a city with a thousand streets and no map. Fear not, my friend, I'm here to be your trusty tour guide.</p> <p></p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#1-why-networking-matters-in-kubernetes-land","title":"1. Why Networking Matters in Kubernetes Land","text":"<p>Think of your Kubernetes cluster as a bustling city. You've got those cool containerized apps (like shops and businesses) running in pods (like buildings). Now, how do those pods talk to each other? How do customers (outside traffic) find those shops? That's where networking comes in. It's like the roads, bridges, and traffic lights that keep everything flowing smoothly.</p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#2-pods-your-basic-building-blocks","title":"2. Pods: Your Basic Building Blocks","text":"<p>Remember those pods? They're like apartment buildings where your apps live. Each pod gets its own unique IP address, like a building's street address. Pods can chat with each other within the same cluster, no problem. It's like neighbors visiting each other in the same apartment complex.</p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#3-services-your-friendly-guides","title":"3. Services: Your Friendly Guides","text":"<p>Now, imagine trying to find a specific shop in a massive city. You might need a directory or a guide, right? That's where \"Services\" come in. They act like those friendly guides, giving your apps a stable, easy-to-remember name, even if the pods move around (like shops changing locations).</p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#4-ingress-the-welcome-committee","title":"4. Ingress: The Welcome Committee","text":"<p>Okay, so you've got your shops and your guides. But how do customers from outside the city find your businesses? That's where \"Ingress\" comes in. It's like the welcome committee, directing traffic from the outside world to the right pods. Think of it as the city's main entrance, with clear signs pointing to different shops.</p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#5-network-policies-the-security-guards","title":"5. Network Policies: The Security Guards","text":"<p>Of course, you want to keep your city safe, right? That's where \"Network Policies\" come in. They're like your security guards, controlling who can access which pods. It's like having those VIP areas or restricted zones in your city.</p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#6-cni-the-road-builders","title":"6. CNI: The Road Builders","text":"<p>Ever wondered how those roads and bridges get built in your city? That's where the \"Container Network Interface\" (CNI) comes in. It's like the team of road builders, creating the underlying network infrastructure that connects everything.</p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#7-dns-the-city-directory","title":"7. DNS: The City Directory","text":"<p>Trying to remember all those IP addresses is like trying to memorize a phone book. Not fun, right? That's where \"DNS\" comes in. It's like the city directory, translating those easy-to-remember names (like \"my-awesome-app\") into those IP addresses that computers understand.</p>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#8-exploring-the-neighborhoods-network-plugins","title":"8. Exploring the Neighborhoods (Network Plugins)","text":"<p>Just like cities have different neighborhoods, Kubernetes has different network plugins. These plugins offer different ways to connect your pods and manage traffic. Some popular ones include:</p> <ul> <li>Calico: Known for its flexibility and scalability.</li> <li>Weave Net: Easy to use and great for simple setups.</li> <li>Flannel: A simple and stable option, often used with basic deployments.</li> </ul>"},{"location":"projects/2024/12/08/kubernetes-networking-a-practical-guide-no-jargon-just-the-good-stuff/#9-ready-to-explore","title":"9. Ready to Explore?","text":"<p>Kubernetes networking might seem daunting at first, but with a little guidance, it's totally manageable. Start with the basics, experiment with different plugins, and don't be afraid to ask for help. Remember, I'm here to guide you on your Kubernetes journey. So, what are you waiting for? Let's explore this exciting world together!</p>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/","title":"Level Up Your Infrastructure Game: Mastering Terraform Modules for Reusable Magic","text":"<p>Tired of cooking up your infrastructure from scratch every single time? Imagine if you had an Instant Pot for your cloud \u2013 something that could whip up a perfect server, database, or network setup with just a few ingredients. That's exactly what Terraform modules are: prepackaged recipes for your digital kitchen.</p> <p></p> <ul> <li>Thanks to  for supporting this content.</li> </ul>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#why-modules-because-nobody-likes-starting-from-zero","title":"Why Modules? Because Nobody Likes Starting From Zero","text":"<p>Think of modules as your pre-built LEGO sets. Instead of painstakingly assembling every tiny brick for a spaceship, you grab a set that's already got the main body and wings ready to go. In Terraform, these sets are modules, and they help you create reusable infrastructure pieces.</p>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#benefits-youll-actually-care-about","title":"Benefits You'll Actually Care About","text":"<ul> <li>Speedy Delivery: Instead of waiting hours for your infrastructure to bake, modules give you \"instant\" results.</li> <li>Consistent Dishes: No more \"oops, I forgot the salt\" moments. Modules ensure your infrastructure tastes the same every time.</li> <li>Easy Cleanup: Modules keep your code organized, like having all your spices in labeled jars instead of scattered across the counter.</li> </ul>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#lets-cook-up-a-simple-module-an-ec2-server-recipe","title":"Let's Cook Up a Simple Module: An EC2 Server \"Recipe\"","text":"<p>We'll make a module that launches a basic server on AWS, like an \"Instant Server\" recipe.</p>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#1-recipe-repository","title":"1. Recipe Repository","text":"<p>The recipe repository name must follow this naming convention</p> <pre><code>terraform-&lt;aws|gcp&gt;-&lt;module_name&gt;\n</code></pre> <p>Terraform module to deploy an AWS EC2 instance, the module name would be</p> <p>terraform-aws-ec2-instance</p>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#2-create-a-recipe-file-tree","title":"2. Create a Recipe File Tree","text":"Copy and paste these commands to create the file tree<pre><code>mkdir terraform-aws-ec2-instance\ncd terraform-aws-ec2-instance\ntouch main.tf variables.tf outputs.tf\nmkdir -p examples/development\ncd examples/development\ntouch 00-providers.tf 01-data.tf 01-locals.tf 09-module.tf 10-outputs.tf\n</code></pre> Recipe File Tree<pre><code>terraform-aws-ec2-instance\n\u251c\u2500\u2500 examples\n\u2502   \u2514\u2500\u2500 development\n\u2502       \u251c\u2500\u2500 00-providers.tf\n\u2502       \u251c\u2500\u2500 01-data.tf\n\u2502       \u251c\u2500\u2500 01-locals.tf\n\u2502       \u251c\u2500\u2500 09-module.tf\n\u2502       \u2514\u2500\u2500 10-outputs.tf\n\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 outputs.tf\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 variables.tf\n</code></pre> <ul> <li><code>main.tf</code>: main file of the module.</li> <li><code>variables.tf</code>: module's input variables.</li> <li><code>outputs.tf</code>: module's outputs.</li> <li><code>examples/development</code>: an example of how to use this module.</li> <li><code>README.md</code> : This file must be generated by terraform-docs</li> </ul>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#3-write-the-recipe","title":"3. Write the \"Recipe.\"","text":"terraform-aws-ec2-instance/main.tf<pre><code>resource \"aws_instance\" \"this\" {\n  ami                    = var.ami\n  instance_type          = var.instance_type\n  subnet_id              = var.subnet_id\n  vpc_security_group_ids = var.vpc_security_group_ids\n  tags                   = merge(var.tags, { module : \"nhamchanvi/terraform-aws-ec2-instance\" })\n}\n</code></pre> terraform-aws-ec2-instance/variables.tf<pre><code>variable \"name\" {\n  description = \"Name to be used on EC2 instance created\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"ami\" {\n  description = \"ID of AMI to use for the instance\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"instance_type\" {\n  description = \"The type of instance to start\"\n  type        = string\n  default     = \"t3.micro\"\n}\n\nvariable \"subnet_id\" {\n  description = \"The VPC Subnet ID to launch in\"\n  type        = string\n  default     = null\n}\n\nvariable \"vpc_security_group_ids\" {\n  description = \"A list of security group IDs to associate with\"\n  type        = list(string)\n  default     = null\n}\n\nvariable \"tags\" {\n  description = \"A mapping of tags to assign to the resource\"\n  type        = map(string)\n  default     = {}\n}\n</code></pre> terraform-aws-ec2-instance/outputs.tf<pre><code>output \"public_ip\" {\n  description = \"The public IP address assigned to the instance, if applicable.\"\n  value       = aws_instance.this.public_ip\n}\n</code></pre>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#4-create-the-example-for-the-recipe","title":"4. Create the Example for the \"Recipe.\"","text":"examples/development/00-providers.tf<pre><code>terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt;4.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n}\n</code></pre> examples/development/01-data.tf<pre><code>data \"aws_ami\" \"debian\" {\n  most_recent = true\n\n  filter {\n    name   = \"name\"\n    values = [\"debian-11-amd64-*\"]\n  }\n\n  filter {\n    name   = \"root-device-type\"\n    values = [\"ebs\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n\n  owners = [\"136693071363\"]\n}\n\ndata \"aws_vpc\" \"default\" {\n  default = true\n}\n\ndata \"aws_subnets\" \"defaults\" {\n  filter {\n    name   = \"vpc-id\"\n    values = [data.aws_vpc.default.id]\n  }\n}\n</code></pre> examples/development/01-locals.tf<pre><code>locals {\n  scenario = \"development\"\n  tags = {\n    secnario   = \"module-development\"\n    terraform  = true\n    repository = \"https://github.com/nhamchanvi/terraform-aws-ec2-instance\"\n  }\n}\n</code></pre> examples/development/09-module.tf<pre><code>module \"ec2-instance\" {\n  source        = \"../../\"\n  name          = \"training-terrafrom-module\"\n  ami           = data.aws_ami.debian.id\n  instance_type = \"t3.micro\"\n  subnet_id     = data.aws_subnets.defaults.ids[0]\n  tags          = local.tags\n}\n</code></pre> examples/development/10-outputs.tf<pre><code>\n</code></pre>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#5-test-your-recipe","title":"5. Test Your \"Recipe.\"","text":"cd examples/development terraform init<pre><code>Initializing the backend...\nInitializing modules...\n- ec2-instance in ../..\n\nInitializing provider plugins...\n- Finding hashicorp/aws versions matching \"~&gt; 4.0\"...\n- Installing hashicorp/aws v4.67.0...\n- Installed hashicorp/aws v4.67.0 (signed by HashiCorp)\n\nTerraform has created a lock file .terraform.lock.hcl to record the provider\nselections it made above. Include this file in your version control repository\nso that Terraform can guarantee to make the same selections by default when\nyou run \"terraform init\" in the future.\n\nTerraform has been successfully initialized!\n\nYou may now begin working with Terraform. Try running \"terraform plan\" to see\nany changes that are required for your infrastructure. All Terraform commands\nshould now work.\n\nIf you ever set or change modules or backend configuration for Terraform,\nrerun this command to reinitialize your working directory. If you forget, other\ncommands will detect it and remind you to do so if necessary.\n</code></pre> terraform validate<pre><code>Success! The configuration is valid.\n</code></pre> terraform fmt<pre><code>\n</code></pre> terraform plan<pre><code>data.aws_vpc.default: Reading...\ndata.aws_ami.debian: Reading...\ndata.aws_ami.debian: Read complete after 1s [id=ami-00a5b694d38896fa5]\ndata.aws_vpc.default: Read complete after 2s [id=vpc-054a2a678b91e3149]\ndata.aws_subnets.defaults: Reading...\ndata.aws_subnets.defaults: Read complete after 1s [id=eu-west-1]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # module.ec2-instance.aws_instance.this will be created\n  + resource \"aws_instance\" \"this\" {\n      + ami                                  = \"ami-00a5b694d38896fa5\"\n      + arn                                  = (known after apply)\n      + associate_public_ip_address          = (known after apply)\n      + availability_zone                    = (known after apply)\n      + cpu_core_count                       = (known after apply)\n      + cpu_threads_per_core                 = (known after apply)\n      + disable_api_stop                     = (known after apply)\n      + disable_api_termination              = (known after apply)\n      + ebs_optimized                        = (known after apply)\n      + get_password_data                    = false\n      + host_id                              = (known after apply)\n      + host_resource_group_arn              = (known after apply)\n      + iam_instance_profile                 = (known after apply)\n      + id                                   = (known after apply)\n      + instance_initiated_shutdown_behavior = (known after apply)\n      + instance_state                       = (known after apply)\n      + instance_type                        = \"t3.micro\"\n      + ipv6_address_count                   = (known after apply)\n      + ipv6_addresses                       = (known after apply)\n      + key_name                             = (known after apply)\n      + monitoring                           = (known after apply)\n      + outpost_arn                          = (known after apply)\n      + password_data                        = (known after apply)\n      + placement_group                      = (known after apply)\n      + placement_partition_number           = (known after apply)\n      + primary_network_interface_id         = (known after apply)\n      + private_dns                          = (known after apply)\n      + private_ip                           = (known after apply)\n      + public_dns                           = (known after apply)\n      + public_ip                            = (known after apply)\n      + secondary_private_ips                = (known after apply)\n      + security_groups                      = (known after apply)\n      + source_dest_check                    = true\n      + subnet_id                            = \"subnet-0ed8441022b56cedc\"\n      + tags                                 = {\n          + \"module\"     = \"nhamchanvi/terraform-aws-ec2-instance\"\n          + \"repository\" = \"https://github.com/nhamchanvi/terraform-aws-ec2-instance\"\n          + \"secnario\"   = \"module-development\"\n          + \"terraform\"  = \"true\"\n        }\n      + tags_all                             = {\n          + \"module\"     = \"nhamchanvi/terraform-aws-ec2-instance\"\n          + \"repository\" = \"https://github.com/nhamchanvi/terraform-aws-ec2-instance\"\n          + \"secnario\"   = \"module-development\"\n          + \"terraform\"  = \"true\"\n        }\n      + tenancy                              = (known after apply)\n      + user_data                            = (known after apply)\n      + user_data_base64                     = (known after apply)\n      + user_data_replace_on_change          = false\n      + vpc_security_group_ids               = (known after apply)\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nNote: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run \"terraform apply\" now.\n</code></pre> terraform apply<pre><code>data.aws_vpc.default: Reading...\ndata.aws_ami.debian: Reading...\ndata.aws_ami.debian: Read complete after 2s [id=ami-00a5b694d38896fa5]\ndata.aws_vpc.default: Read complete after 3s [id=vpc-054a2a678b91e3149]\ndata.aws_subnets.defaults: Reading...\ndata.aws_subnets.defaults: Read complete after 1s [id=eu-west-1]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # module.ec2-instance.aws_instance.this will be created\n  + resource \"aws_instance\" \"this\" {\n      + ami                                  = \"ami-00a5b694d38896fa5\"\n      + arn                                  = (known after apply)\n      + associate_public_ip_address          = (known after apply)\n      + availability_zone                    = (known after apply)\n      + cpu_core_count                       = (known after apply)\n      + cpu_threads_per_core                 = (known after apply)\n      + disable_api_stop                     = (known after apply)\n      + disable_api_termination              = (known after apply)\n      + ebs_optimized                        = (known after apply)\n      + get_password_data                    = false\n      + host_id                              = (known after apply)\n      + host_resource_group_arn              = (known after apply)\n      + iam_instance_profile                 = (known after apply)\n      + id                                   = (known after apply)\n      + instance_initiated_shutdown_behavior = (known after apply)\n      + instance_state                       = (known after apply)\n      + instance_type                        = \"t3.micro\"\n      + ipv6_address_count                   = (known after apply)\n      + ipv6_addresses                       = (known after apply)\n      + key_name                             = (known after apply)\n      + monitoring                           = (known after apply)\n      + outpost_arn                          = (known after apply)\n      + password_data                        = (known after apply)\n      + placement_group                      = (known after apply)\n      + placement_partition_number           = (known after apply)\n      + primary_network_interface_id         = (known after apply)\n      + private_dns                          = (known after apply)\n      + private_ip                           = (known after apply)\n      + public_dns                           = (known after apply)\n      + public_ip                            = (known after apply)\n      + secondary_private_ips                = (known after apply)\n      + security_groups                      = (known after apply)\n      + source_dest_check                    = true\n      + subnet_id                            = \"subnet-0ed8441022b56cedc\"\n      + tags                                 = {\n          + \"module\"     = \"nhamchanvi/terraform-aws-ec2-instance\"\n          + \"repository\" = \"https://github.com/nhamchanvi/terraform-aws-ec2-instance\"\n          + \"secnario\"   = \"module-development\"\n          + \"terraform\"  = \"true\"\n        }\n      + tags_all                             = {\n          + \"module\"     = \"nhamchanvi/terraform-aws-ec2-instance\"\n          + \"repository\" = \"https://github.com/nhamchanvi/terraform-aws-ec2-instance\"\n          + \"secnario\"   = \"module-development\"\n          + \"terraform\"  = \"true\"\n        }\n      + tenancy                              = (known after apply)\n      + user_data                            = (known after apply)\n      + user_data_base64                     = (known after apply)\n      + user_data_replace_on_change          = false\n      + vpc_security_group_ids               = (known after apply)\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value: yes\n\nmodule.ec2-instance.aws_instance.this: Creating...\nmodule.ec2-instance.aws_instance.this: Still creating... [10s elapsed]\nmodule.ec2-instance.aws_instance.this: Creation complete after 19s [id=i-04d957d4f303de62d]\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n</code></pre> terraform destroy<pre><code>data.aws_vpc.default: Reading...\ndata.aws_ami.debian: Reading...\ndata.aws_ami.debian: Read complete after 1s [id=ami-00a5b694d38896fa5]\ndata.aws_vpc.default: Read complete after 2s [id=vpc-054a2a678b91e3149]\ndata.aws_subnets.defaults: Reading...\ndata.aws_subnets.defaults: Read complete after 0s [id=eu-west-1]\nmodule.ec2-instance.aws_instance.this: Refreshing state... [id=i-04d957d4f303de62d]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  - destroy\n\nTerraform will perform the following actions:\n\n  # module.ec2-instance.aws_instance.this will be destroyed\n  - resource \"aws_instance\" \"this\" {\n      - ami                                  = \"ami-00a5b694d38896fa5\" -&gt; null\n      - arn                                  = \"arn:aws:ec2:eu-west-1:842445166689:instance/i-04d957d4f303de62d\" -&gt; null\n      - associate_public_ip_address          = true -&gt; null\n      - availability_zone                    = \"eu-west-1b\" -&gt; null\n      - cpu_core_count                       = 1 -&gt; null\n      - cpu_threads_per_core                 = 2 -&gt; null\n      - disable_api_stop                     = false -&gt; null\n      - disable_api_termination              = false -&gt; null\n      - ebs_optimized                        = false -&gt; null\n      - get_password_data                    = false -&gt; null\n      - hibernation                          = false -&gt; null\n      - id                                   = \"i-04d957d4f303de62d\" -&gt; null\n      - instance_initiated_shutdown_behavior = \"stop\" -&gt; null\n      - instance_state                       = \"running\" -&gt; null\n      - instance_type                        = \"t3.micro\" -&gt; null\n      - ipv6_address_count                   = 0 -&gt; null\n      - ipv6_addresses                       = [] -&gt; null\n      - monitoring                           = false -&gt; null\n      - placement_partition_number           = 0 -&gt; null\n      - primary_network_interface_id         = \"eni-0479a48d34b61566d\" -&gt; null\n      - private_dns                          = \"ip-172-31-3-184.eu-west-1.compute.internal\" -&gt; null\n      - private_ip                           = \"172.31.3.184\" -&gt; null\n      - public_dns                           = \"ec2-54-74-231-76.eu-west-1.compute.amazonaws.com\" -&gt; null\n      - public_ip                            = \"54.74.231.76\" -&gt; null\n      - secondary_private_ips                = [] -&gt; null\n      - security_groups                      = [\n          - \"default\",\n        ] -&gt; null\n      - source_dest_check                    = true -&gt; null\n      - subnet_id                            = \"subnet-0ed8441022b56cedc\" -&gt; null\n      - tags                                 = {\n          - \"module\"     = \"nhamchanvi/terraform-aws-ec2-instance\"\n          - \"repository\" = \"https://github.com/nhamchanvi/terraform-aws-ec2-instance\"\n          - \"secnario\"   = \"module-development\"\n          - \"terraform\"  = \"true\"\n        } -&gt; null\n      - tags_all                             = {\n          - \"module\"     = \"nhamchanvi/terraform-aws-ec2-instance\"\n          - \"repository\" = \"https://github.com/nhamchanvi/terraform-aws-ec2-instance\"\n          - \"secnario\"   = \"module-development\"\n          - \"terraform\"  = \"true\"\n        } -&gt; null\n      - tenancy                              = \"default\" -&gt; null\n      - user_data_replace_on_change          = false -&gt; null\n      - vpc_security_group_ids               = [\n          - \"sg-0078b23a0d63568f7\",\n        ] -&gt; null\n\n      - capacity_reservation_specification {\n          - capacity_reservation_preference = \"open\" -&gt; null\n        }\n\n      - cpu_options {\n          - core_count       = 1 -&gt; null\n          - threads_per_core = 2 -&gt; null\n        }\n\n      - credit_specification {\n          - cpu_credits = \"unlimited\" -&gt; null\n        }\n\n      - enclave_options {\n          - enabled = false -&gt; null\n        }\n\n      - maintenance_options {\n          - auto_recovery = \"default\" -&gt; null\n        }\n\n      - metadata_options {\n          - http_endpoint               = \"enabled\" -&gt; null\n          - http_put_response_hop_limit = 1 -&gt; null\n          - http_tokens                 = \"optional\" -&gt; null\n          - instance_metadata_tags      = \"disabled\" -&gt; null\n        }\n\n      - private_dns_name_options {\n          - enable_resource_name_dns_a_record    = false -&gt; null\n          - enable_resource_name_dns_aaaa_record = false -&gt; null\n          - hostname_type                        = \"ip-name\" -&gt; null\n        }\n\n      - root_block_device {\n          - delete_on_termination = true -&gt; null\n          - device_name           = \"/dev/xvda\" -&gt; null\n          - encrypted             = false -&gt; null\n          - iops                  = 100 -&gt; null\n          - tags                  = {} -&gt; null\n          - throughput            = 0 -&gt; null\n          - volume_id             = \"vol-0a24924083e4afd34\" -&gt; null\n          - volume_size           = 8 -&gt; null\n          - volume_type           = \"gp2\" -&gt; null\n        }\n    }\n\nPlan: 0 to add, 0 to change, 1 to destroy.\n\nDo you really want to destroy all resources?\n  Terraform will destroy all your managed infrastructure, as shown above.\n  There is no undo. Only 'yes' will be accepted to confirm.\n\n  Enter a value: yes\n\nmodule.ec2-instance.aws_instance.this: Destroying... [id=i-04d957d4f303de62d]\nmodule.ec2-instance.aws_instance.this: Still destroying... [id=i-04d957d4f303de62d, 10s elapsed]\nmodule.ec2-instance.aws_instance.this: Still destroying... [id=i-04d957d4f303de62d, 20s elapsed]\nmodule.ec2-instance.aws_instance.this: Still destroying... [id=i-04d957d4f303de62d, 30s elapsed]\nmodule.ec2-instance.aws_instance.this: Still destroying... [id=i-04d957d4f303de62d, 40s elapsed]\nmodule.ec2-instance.aws_instance.this: Still destroying... [id=i-04d957d4f303de62d, 50s elapsed]\nmodule.ec2-instance.aws_instance.this: Destruction complete after 54s\n\nDestroy complete! Resources: 1 destroyed.\n</code></pre>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#6-create-readmemd-with-terraform-docs","title":"6. Create README.md with terraform-docs","text":"brew install terraform-docs<pre><code>==&gt; Downloading https://formulae.brew.sh/api/formula.jws.json\n==&gt; Downloading https://ghcr.io/v2/homebrew/core/terraform-docs/manifests/0.19.0\n################################################################################################################################# 100.0%\n==&gt; Fetching terraform-docs\n==&gt; Downloading https://ghcr.io/v2/homebrew/core/terraform-docs/blobs/sha256:73916d978b414105ca9a9d3d264e064b91e90cd43180a6f391372275fa19d563\n################################################################################################################################# 100.0%\n==&gt; Pouring terraform-docs--0.19.0.x86_64_linux.bottle.tar.gz\n==&gt; Downloading https://formulae.brew.sh/api/cask.jws.json\n==&gt; Caveats\nzsh completions have been installed to:\n  /home/linuxbrew/.linuxbrew/share/zsh/site-functions\n==&gt; Summary\n\ud83c\udf7a  /home/linuxbrew/.linuxbrew/Cellar/terraform-docs/0.19.0: 8 files, 23.2MB\n==&gt; Running `brew cleanup terraform-docs`...\nDisable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\nHide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n</code></pre> terraform-docs markdown table . &gt; README.md<pre><code>\n</code></pre> cat README.md<pre><code>## Requirements\n\nNo requirements.\n\n## Providers\n\n| Name | Version |\n|------|---------|\n| &lt;a name=\"provider_aws\"&gt;&lt;/a&gt; [aws](#provider\\_aws) | n/a |\n\n## Modules\n\nNo modules.\n\n## Resources\n\n| Name | Type |\n|------|------|\n| [aws_instance.this](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance) | resource |\n\n## Inputs\n\n| Name | Description | Type | Default | Required |\n|------|-------------|------|---------|:--------:|\n| &lt;a name=\"input_ami\"&gt;&lt;/a&gt; [ami](#input\\_ami) | ID of AMI to use for the instance | `string` | `\"\"` | no |\n| &lt;a name=\"input_instance_type\"&gt;&lt;/a&gt; [instance\\_type](#input\\_instance\\_type) | The type of instance to start | `string` | `\"t3.micro\"` | no |\n| &lt;a name=\"input_name\"&gt;&lt;/a&gt; [name](#input\\_name) | Name to be used on EC2 instance created | `string` | `\"\"` | no |\n| &lt;a name=\"input_subnet_id\"&gt;&lt;/a&gt; [subnet\\_id](#input\\_subnet\\_id) | The VPC Subnet ID to launch in | `string` | `null` | no |\n| &lt;a name=\"input_tags\"&gt;&lt;/a&gt; [tags](#input\\_tags) | A mapping of tags to assign to the resource | `map(string)` | `{}` | no |\n| &lt;a name=\"input_vpc_security_group_ids\"&gt;&lt;/a&gt; [vpc\\_security\\_group\\_ids](#input\\_vpc\\_security\\_group\\_ids) | A list of security group IDs to associate with | `list(string)` | `null` | no |\n\n## Outputs\n\n| Name | Description |\n|------|-------------|\n| &lt;a name=\"output_public_ip\"&gt;&lt;/a&gt; [public\\_ip](#output\\_public\\_ip) | The public IP address assigned to the instance, if applicable. |\n</code></pre>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#why-this-is-like-an-instant-pot","title":"Why This Is Like an Instant Pot","text":"<ul> <li><code>module \"ec2_instance\"</code>: Says, \"Hey Terraform, use my instant server recipe.\"</li> <li><code>source = \"../../\"</code>: Tells it where to find the recipe.</li> <li>We give it the ingredients (ami, instance_type, name).</li> <li>The module cooks up the server, and we get the address.</li> </ul>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#simple-cooking-tips","title":"Simple Cooking Tips","text":"<ul> <li>Make recipes that do one thing well (like \"Instant Pot Chicken\").</li> <li>Write notes on your recipes (comments) so you remember what's what.</li> <li>Share your recipes with your team!</li> </ul>"},{"location":"projects/2025/03/23/level-up-your-infrastructure-game-mastering-terraform-modules-for-reusable-magic/#conclusion","title":"Conclusion","text":"<p>In essence, Terraform modules are your infrastructure's secret weapon, transforming complex deployments into streamlined, repeatable processes. By embracing this \"Instant Pot\" approach to infrastructure as code, you'll not only save valuable time and resources but also ensure consistency and collaboration across your team. So, ditch the tedious manual labor and start building with the reusable magic of Terraform modules, unlocking a new level of efficiency and simplicity in your cloud deployments.</p>"},{"location":"projects/2025/03/02/linux-treasure-hunt/","title":"Linux Treasure Hunt","text":"<p>This project is more than just a game; it's a practical way to hone your Linux command-line skills, which are essential for any aspiring DevOps engineer. Think of it as an adventure with real-world applications.</p> <p></p>"},{"location":"projects/2025/03/02/linux-treasure-hunt/#the-challenge","title":"The Challenge:","text":""},{"location":"projects/2025/03/02/linux-treasure-hunt/#1-bury-the-treasure","title":"1. Bury the Treasure:","text":"<p>Create a file with a \"secret message\" (e.g., a fake API key, a server configuration setting, or even a fun message). Hide this file deep within your Linux file system. Get creative with the file name and location!</p>"},{"location":"projects/2025/03/02/linux-treasure-hunt/#2-craft-the-script","title":"2. Craft the Script:","text":"<p>Write a shell script that uses the find command, along with other Linux commands, to locate your hidden treasure. Consider using:</p> <ul> <li>find with various options (e.g., -name, -type, -mtime)</li> <li>grep to search for specific content within files</li> <li>awk or sed for more advanced text processing</li> <li>Control flow (e.g., if, else) to handle different scenarios</li> </ul>"},{"location":"projects/2025/03/02/linux-treasure-hunt/#3-level-up","title":"3. Level Up:","text":"<ul> <li>Add a timer to your script to track how long it takes to find the treasure.</li> <li>Modify the script to search for multiple treasures.</li> <li>Create a \"treasure map\" (a text file with clues) that your script can decipher to find the treasure.</li> </ul>"},{"location":"projects/2025/03/02/linux-treasure-hunt/#why-this-matters-for-devops","title":"Why This Matters for DevOps:","text":"<ul> <li>File System Mastery: DevOps engineers often work with complex file systems and need to locate and manage files efficiently.</li> <li>Automation: Automating tasks with shell scripts is a core DevOps skill. This project gives you hands-on practice.</li> <li>Problem-Solving: This challenge encourages you to think creatively and use Linux commands in new ways to solve a problem.</li> <li>Security Awareness: By hiding and finding files, you gain a better understanding of file permissions and security implications, which are crucial in DevOps.</li> </ul> <p>Example</p> <p>cat my_hidden_treasure.txt<pre><code>super super secret\n</code></pre> treasure_hunt.sh<pre><code>#!/bin/bash\n\n# Start the timer\nstart_time=$(date +%s)\n\n# Use find to locate the treasure file\ntreasure_file=$(find / -name \"my_hidden_treasure.txt\" 2&gt;/dev/null)\n\n# Check if the treasure was found\nif [ -n \"$treasure_file\" ]; then\n  echo \"Treasure found: $treasure_file\"\n  cat \"$treasure_file\"\nelse\n  echo \"Treasure not found!\"\nfi\n\n# Calculate and display the elapsed time\nend_time=$(date +%s)\nelapsed_time=$((end_time - start_time))\necho \"Elapsed time: $elapsed_time seconds\"\n</code></pre> chmod +x treasure_hunt.sh<pre><code>\n</code></pre> ./treasure_hunt.sh<pre><code>Treasure found: /home/chanvi/learn-devops/learn-linux-sensitive-variables/my_hidden_treasure.txt\nsuper super secret\nElapsed time: 5 seconds\n</code></pre></p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/","title":"Mastering AWS Networking: VPCs, Subnets, and Beyond (Guide to the Cloud Network Jungle)","text":"<p>So, you're ready to conquer the world of AWS networking, huh? That's fantastic! But let's be honest, it can sometimes feel like navigating a dense jungle with hidden trails and exotic creatures. Don't worry, I'm here to be your experienced guide, equipped with the knowledge and tools to help you navigate this exciting terrain.</p> <p></p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#1-vpcs-your-private-cloud-sanctuary","title":"1. VPCs: Your Private Cloud Sanctuary","text":"<p>Think of a Virtual Private Cloud (VPC) as your own personal sanctuary within the vast AWS cloud. It's like having your own private island where you can build and customize your network infrastructure to your liking. You get to decide who has access, how traffic flows, and what resources are available.</p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#2-subnets-dividing-your-kingdom","title":"2. Subnets: Dividing Your Kingdom","text":"<p>Now, imagine dividing your private island into smaller regions with specific purposes. That's where subnets come in. They allow you to segment your VPC into smaller, isolated networks. Think of it like creating different zones for your palace, gardens, and guest houses.</p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#3-route-tables-your-network-traffic-controllers","title":"3. Route Tables: Your Network Traffic Controllers","text":"<p>Just like traffic signs and signals guide vehicles on roads, route tables direct network traffic within your VPC. They act as a set of rules, determining where traffic should go based on its destination. It's like having your own traffic control system to ensure smooth and efficient flow.</p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#4-internet-gateway-your-gateway-to-the-world","title":"4. Internet Gateway: Your Gateway to the World","text":"<p>Want to connect your private island to the outside world? That's where the Internet Gateway comes in. It's like building a bridge that connects your VPC to the vast internet, allowing your resources to communicate with the rest of the world.</p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#5-nat-gateway-your-privacy-protector","title":"5. NAT Gateway: Your Privacy Protector","text":"<p>Sometimes, you want your resources to access the internet without revealing their private IP addresses. That's where the NAT Gateway steps in. It acts as a middleman, allowing your resources to send and receive traffic while keeping their identities hidden. It's like having a masked messenger deliver your messages to the outside world.</p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#6-security-groups-and-network-acls-your-security-guards","title":"6. Security Groups and Network ACLs: Your Security Guards","text":"<p>Of course, you want to keep your private island safe from intruders. That's where security groups and network ACLs come in. They act as your security guards, controlling inbound and outbound traffic at the resource and subnet level. Think of them as your gatekeepers, ensuring only authorized visitors can enter your kingdom.</p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#7-vpc-peering-building-bridges-with-other-islands","title":"7. VPC Peering: Building Bridges with Other Islands","text":"<p>Want to connect your private island to other VPCs, either within your own AWS account or belonging to other adventurers? That's where VPC peering comes in. It's like building bridges between islands, allowing resources in different VPCs to communicate with each other securely and privately.</p>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#8-beyond-the-basics-advanced-networking-adventures","title":"8. Beyond the Basics: Advanced Networking Adventures","text":"<p>Once you've mastered the basics, there's a whole world of advanced networking features to explore. You can delve into:</p> <ul> <li>Transit Gateway: Your central hub for connecting multiple VPCs and on-premises networks.</li> <li>VPN Connections: Securely connect your private island to your on-premises headquarters.</li> <li>Direct Connect: Establish a dedicated, private connection between your island and the AWS mainland.</li> <li>AWS PrivateLink: Access AWS services privately, without traversing the public internet.</li> </ul>"},{"location":"projects/2024/12/15/mastering-aws-networking-vpcs-subnets-and-beyond-guide-to-the-cloud-network-jungle/#9-charting-your-networking-journey","title":"9. Charting Your Networking Journey","text":"<p>Mastering AWS networking is an ongoing adventure. Start with the foundational concepts, build your VPC, segment it with subnets, and control traffic with route tables. Then, gradually explore the more advanced features as your networking needs evolve. With patience, practice, and a bit of guidance, you'll become a seasoned navigator of the AWS networking jungle.</p> <p>So, what are you waiting for? Let's embark on this exciting journey together!</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/","title":"Network Security Best Practices in Cloud Environments: Building Your Fortress in the Cloud","text":"<p>So, you're venturing into the cloud, and you want to make sure your network is secure, right? That's awesome! Think of the cloud as a vast and open sky, with your data and applications floating among the clouds. Now, how do you protect your valuable assets from those pesky cyber villains who are always lurking around, trying to steal your data or disrupt your operations? Don't worry, securing your network in the cloud isn't about building an impenetrable fortress, but it's definitely more than just a flimsy tent. Let's explore some best practices to build a strong and resilient fortress in the cloud.</p> <p></p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#1-laying-the-foundation-secure-your-virtual-private-cloud-vpc","title":"1. Laying the Foundation: Secure Your Virtual Private Cloud (VPC)","text":"<p>Think of your VPC as your own private kingdom in the cloud. It's like having your own plot of land where you can build your fortress and control who has access. Make sure you configure your VPC with strong security groups and network access control lists (ACLs), acting as your gatekeepers, controlling inbound and outbound traffic. It's like building a sturdy wall around your kingdom, with guarded gates and checkpoints.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#2-guarding-the-gates-secure-your-ingress-and-egress-points","title":"2. Guarding the Gates: Secure Your Ingress and Egress Points","text":"<p>Imagine your fortress has multiple gates and entrances. You want to make sure each one is well-guarded, right? Same goes for your network. Secure your ingress and egress points, such as your internet gateways, load balancers, and VPN connections. It's like having vigilant guards at every entrance, checking the credentials of everyone who enters or leaves your fortress.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#3-segmenting-your-kingdom-subnet-segmentation","title":"3. Segmenting Your Kingdom: Subnet Segmentation","text":"<p>Imagine your fortress has different zones for different purposes, like a treasury, barracks, and living quarters. You wouldn't want everyone to have access to every zone, right? Same goes for your network. Segment your network into smaller, isolated subnets, each with its own security controls. It's like dividing your kingdom into smaller, manageable territories, each with its own set of defenses.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#4-protecting-your-secrets-secrets-management","title":"4. Protecting Your Secrets: Secrets Management","text":"<p>Every kingdom has its secrets, right? Those secret recipes, hidden treasures, and confidential plans. In the cloud world, secrets are things like passwords, API keys, and certificates. Don't leave them exposed in your code or configuration files! Use secrets management tools like HashiCorp Vault or AWS Secrets Manager to store and manage your secrets securely. It's like having a royal vault for your most sensitive information, with strict access control and encryption.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#5-keeping-watch-monitoring-and-logging","title":"5. Keeping Watch: Monitoring and Logging","text":"<p>Imagine your fortress has no watchtowers or guards patrolling the walls. You'd be vulnerable to surprise attacks, right? Same goes for your network. Monitor your network traffic for suspicious activity, performance issues, or potential breaches. Use monitoring and logging tools like Datadog, Prometheus, or AWS CloudWatch to get a clear view of what's happening in your kingdom.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#6-defending-against-invaders-intrusion-detection-and-prevention","title":"6. Defending Against Invaders: Intrusion Detection and Prevention","text":"<p>Even with strong walls and vigilant guards, you might still encounter those pesky invaders who try to sneak into your kingdom. That's where intrusion detection and prevention systems (IDPS) come in. They act like your security alarms and defense mechanisms, detecting and responding to potential attacks in real-time. It's like having a network of sensors and traps, ready to alert you and neutralize any threats.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#7-staying-vigilant-continuous-security-updates","title":"7. Staying Vigilant: Continuous Security Updates","text":"<p>Just like any fortress, your network security needs regular maintenance and updates to stay strong and resilient. Keep your software, operating systems, and security tools up-to-date with the latest patches and security fixes. It's like reinforcing your walls, repairing any cracks, and upgrading your defenses to stay ahead of those evolving threats.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#8-building-a-culture-of-security-shared-responsibility","title":"8. Building a Culture of Security: Shared Responsibility","text":"<p>Securing your network in the cloud is not just the responsibility of your IT team. It's a shared responsibility that involves everyone in your organization. Educate your users about security best practices, implement strong password policies, and foster a culture of security awareness. It's like having every citizen in your kingdom trained and prepared to defend their home.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#9-building-a-resilient-fortress-disaster-recovery-and-business-continuity","title":"9. Building a Resilient Fortress: Disaster Recovery and Business Continuity","text":"<p>Even the strongest fortresses can face unexpected challenges, like natural disasters or cyberattacks. That's why it's crucial to have a disaster recovery and business continuity plan in place. It's like having a backup plan, ensuring you can quickly recover your kingdom and resume operations in case of any unforeseen events.</p>"},{"location":"projects/2025/02/16/network-security-best-practices-in-cloud-environments-building-your-fortress-in-the-cloud/#10-protecting-your-kingdom-in-the-cloud","title":"10. Protecting Your Kingdom in the Cloud","text":"<p>Securing your network in the cloud is an ongoing journey, not a destination. By following these best practices, you can build a strong and resilient fortress in the sky, protecting your valuable data and applications from those pesky cyber villains. Remember, it's not about building an impenetrable fortress, but about creating a multi-layered defense system that adapts to your evolving needs and keeps your kingdom safe and sound.</p>"},{"location":"projects/2025/02/23/securing-api-gateways-and-cloudfront-distributions-guarding-your-castle-and-welcoming-your-guests/","title":"Securing API Gateways and CloudFront Distributions: Guarding Your Castle and Welcoming Your Guests","text":"<p>So, you're building this magnificent castle in the cloud, with API gateways and CloudFront distributions as your grand entrances, right? That's fantastic! But here's the thing: just like any castle, you need to protect your gates and ensure only authorized guests can enter, while also providing a smooth and welcoming experience for those you welcome. Don't worry, securing your API gateways and CloudFront distributions isn't about building an impenetrable fortress, but it's definitely more than just a flimsy drawbridge. Let's explore some best practices to guard your castle and welcome your guests.</p> <p></p>"},{"location":"projects/2025/02/23/securing-api-gateways-and-cloudfront-distributions-guarding-your-castle-and-welcoming-your-guests/#1-api-gateways-your-castle-gates","title":"1. API Gateways: Your Castle Gates","text":"<p>Think of your API gateway as the main gate to your castle, controlling access to your precious resources and services. It's like having a vigilant gatekeeper who checks the credentials of everyone who wants to enter your castle. Make sure you configure your API gateway with strong authentication and authorization mechanisms, such as API keys, JWT tokens, or OAuth 2.0. It's like having a strict doorman who only allows those with the right credentials to pass through.</p>"},{"location":"projects/2025/02/23/securing-api-gateways-and-cloudfront-distributions-guarding-your-castle-and-welcoming-your-guests/#2-cloudfront-distributions-your-welcoming-courtyard","title":"2. CloudFront Distributions: Your Welcoming Courtyard","text":"<p>Now, imagine your CloudFront distribution as the welcoming courtyard in front of your castle. It's where your guests arrive and get their first impression of your kingdom. You want to make sure it's a smooth and pleasant experience, right? CloudFront helps you deliver your content quickly and efficiently, using a global network of edge locations. It's like having a well-maintained courtyard with clear pathways and helpful signs, guiding your guests to their desired destinations.</p>"},{"location":"projects/2025/02/23/securing-api-gateways-and-cloudfront-distributions-guarding-your-castle-and-welcoming-your-guests/#3-protecting-your-gates-security-best-practices-for-api-gateways","title":"3. Protecting Your Gates: Security Best Practices for API Gateways","text":"<ul> <li>Authentication and Authorization: Make sure you have strong authentication and authorization mechanisms in place to verify the identity of your guests and ensure they have the right permissions to access your resources.</li> <li>Rate Limiting and Throttling: Prevent those pesky attackers from overwhelming your castle gates by implementing rate limiting and throttling. It's like having a queueing system that controls the flow of guests, preventing overcrowding and ensuring everyone gets a fair chance to enter.</li> <li>Input Validation and Sanitization: Don't let those sneaky attackers slip through your gates with malicious data. Validate and sanitize all incoming requests to prevent injection attacks and other vulnerabilities. It's like having a security checkpoint that scans all incoming packages for dangerous items.</li> <li>Web Application Firewall (WAF): Add an extra layer of protection by deploying a WAF in front of your API gateway. It's like having a moat around your castle, filtering out malicious traffic and protecting your gates from attacks.</li> </ul>"},{"location":"projects/2025/02/23/securing-api-gateways-and-cloudfront-distributions-guarding-your-castle-and-welcoming-your-guests/#4-welcoming-your-guests-security-best-practices-for-cloudfront-distributions","title":"4. Welcoming Your Guests: Security Best Practices for CloudFront Distributions","text":"<ul> <li>HTTPS Everywhere: Encrypt your traffic with HTTPS to protect your guests' data from eavesdropping and tampering. It's like providing a secure tunnel for your guests to travel through, ensuring their privacy and safety.</li> <li>Content Security Policy (CSP): Define a CSP to control the resources that your guests' browsers can load, preventing cross-site scripting (XSS) attacks. It's like having a guest list that specifies who is allowed to enter your castle and what they are allowed to bring.</li> <li>Origin Access Identity (OAI): Restrict access to your origin servers by using an OAI. It's like having a VIP pass that only allows authorized personnel to enter your castle's inner chambers.</li> <li>Field-Level Encryption: Protect sensitive data, such as credit card numbers or personal information, by encrypting it at the field level. It's like having a secure vault for your most valuable treasures, ensuring they are protected from prying eyes.</li> </ul>"},{"location":"projects/2025/02/23/securing-api-gateways-and-cloudfront-distributions-guarding-your-castle-and-welcoming-your-guests/#5-guarding-your-castle-and-welcoming-your-guests","title":"5. Guarding Your Castle and Welcoming Your Guests","text":"<p>Securing your API gateways and CloudFront distributions is like guarding your castle gates and welcoming your guests. By implementing these best practices, you can ensure that your resources are protected from unauthorized access, while also providing a smooth and enjoyable experience for your legitimate users. Remember, security is not just about building walls and defenses; it's also about creating a welcoming and trustworthy environment for your guests.</p> <p>So, are you ready to guard your castle and welcome your guests in the cloud?</p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/","title":"Securing Your Infrastructure with IaC Best Practices: Building Fortresses, Not Sandcastles","text":"<p>So, you're building your infrastructure with IaC, which is awesome! It's like having a blueprint for your digital kingdom. But here's the thing: just like any kingdom, you need strong defenses to keep those pesky invaders out. Don't worry, securing your IaC isn't about building impenetrable fortresses, but it's definitely more than just sandcastles. Let's explore some best practices to keep your kingdom safe and sound.</p> <p></p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/#1-treat-your-code-like-jewels-version-control-and-access-control","title":"1. Treat Your Code Like Jewels: Version Control and Access Control","text":"<p>Your IaC code is precious, like a collection of valuable jewels. You wouldn't leave them lying around, right? Same goes for your code. Use version control systems like Git to track changes, collaborate securely, and roll back if needed. It's like having a royal vault for your code, with strict access control and a detailed history of every modification.</p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/#2-scan-for-weak-spots-static-code-analysis","title":"2. Scan for Weak Spots: Static Code Analysis","text":"<p>Imagine your kingdom has hidden tunnels and secret passages. You'd want to find them before the invaders do, right? That's where static code analysis comes in. Use tools like Checkov, Terrascan, or tfsec to scan your IaC code for potential vulnerabilities, misconfigurations, and security risks. It's like having a team of expert scouts inspecting your kingdom for weaknesses.</p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/#3-test-your-defenses-policy-as-code","title":"3. Test Your Defenses: Policy as Code","text":"<p>You wouldn't just build a wall and hope for the best, right? You'd test its strength and resilience. Same goes for your IaC security. Use policy-as-code tools like Open Policy Agent (OPA) or HashiCorp Sentinel to define and enforce security policies. It's like having a set of strict building codes that ensure every part of your kingdom meets the highest security standards.</p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/#4-secure-your-secrets-secrets-management","title":"4. Secure Your Secrets: Secrets Management","text":"<p>Every kingdom has its secrets, right? Those secret recipes, hidden treasures, and confidential plans. In the IaC world, secrets are things like passwords, API keys, and certificates. Don't leave them exposed in your code! Use secrets management tools like HashiCorp Vault or AWS Secrets Manager to store and manage your secrets securely. It's like having a royal vault for your most sensitive information, with strict access control and encryption.</p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/#5-keep-watch-monitoring-and-alerting","title":"5. Keep Watch: Monitoring and Alerting","text":"<p>Even with strong defenses, you need vigilant guards to keep watch. Monitor your infrastructure for suspicious activity, configuration changes, and potential breaches. Use monitoring and alerting tools like Datadog, Prometheus, or AWS CloudWatch to get notified of any unusual events. It's like having a network of watchtowers and alarm bells, ready to alert you at the first sign of trouble.</p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/#6-learn-from-mistakes-continuous-improvement","title":"6. Learn from Mistakes: Continuous Improvement","text":"<p>Even the best fortresses can be breached. The key is to learn from your mistakes and continuously improve your defenses. Regularly review your security practices, update your tools, and stay informed about new threats and vulnerabilities. It's like having a council of advisors constantly analyzing your defenses and suggesting improvements.</p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/#7-teamwork-makes-the-dream-work-collaboration-and-communication","title":"7. Teamwork Makes the Dream Work: Collaboration and Communication","text":"<p>Securing your IaC isn't a solo mission. Foster a culture of collaboration and communication between your development, security, and operations teams. Share knowledge, best practices, and security updates. It's like having a united kingdom where everyone works together to protect its borders.</p>"},{"location":"projects/2024/12/29/securing-your-infrastructure-with-iac-best-practices-building-fortresses-not-sandcastles/#8-building-a-secure-and-resilient-kingdom","title":"8. Building a Secure and Resilient Kingdom","text":"<p>Securing your infrastructure with IaC best practices is an ongoing journey, not a destination. By following these guidelines, you can build a secure and resilient digital kingdom that can withstand the test of time and protect your valuable assets. Remember, it's not about building impenetrable fortresses, but about creating a strong and adaptable defense system that evolves with your needs.</p> <p>So, are you ready to fortify your kingdom?</p>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/","title":"Terraform State Management: A Practical Guide with Real-World Scenarios","text":"<p>Alright, picture this: You're building a digital world, right? Servers, databases, the whole shebang. Terraform's your trusty construction crew, and state? That's the blueprint, the project diary, the memory bank \u2013 basically, the thing that keeps everything from turning into a digital demolition derby.</p> <p>Let's dive into some real-life \"oops\" moments and how state swoops in to save the day, shall we?</p> <p></p> <ul> <li>Thanks to  for supporting this content.</li> </ul>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#why-state-matters-and-why-you-should-care","title":"Why State Matters (and Why You Should Care)","text":"<p>Imagine building a complex LEGO city. You've got skyscrapers, roads, and even a tiny airport. The state file is like your master blueprint, showing exactly where each brick is placed. If you lose that blueprint, you're left with a pile of LEGOs and no clue how to rebuild your city.</p> <p>In the real world, losing your state file can lead to:</p> <ul> <li>Infrastructure drift: Terraform loses track of what it's managing, leading to inconsistencies.</li> <li>Data loss: Accidental deletions or modifications can occur without a reliable state record.</li> <li>Team chaos: Multiple engineers making changes without a centralized state file can lead to conflicts and errors.</li> </ul>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#the-state-file-a-peek-under-the-hood","title":"The State File: A Peek Under the Hood","text":"<p>The state file is a JSON file that stores information about your infrastructure. It includes resource IDs, attributes, and dependencies. It's like a detailed inventory of your digital assets.</p> <p>Here's an example (EC2 instance and SSH security group) of what a state file might look like:</p> terraform.tfstate<pre><code>{\n  \"version\": 4,\n  \"terraform_version\": \"1.5.7\",\n  \"serial\": 6,\n  \"lineage\": \"609b2913-6ec3-9b1f-7551-1ad53f171490\",\n  \"outputs\": {\n    \"public_ip\": {\n      \"value\": \"13.37.220.7\",\n      \"type\": \"string\"\n    }\n  },\n  \"resources\": [\n    {\n      \"mode\": \"managed\",\n      \"type\": \"aws_instance\",\n      \"name\": \"web\",\n      \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n      \"instances\": [\n        {\n          \"schema_version\": 1,\n          \"attributes\": {\n            \"ami\": \"ami-0076ac74e7710cd06\",\n            \"arn\": \"arn:aws:ec2:eu-west-3:842445166689:instance/i-0343344212a5a2b7d\",\n            \"associate_public_ip_address\": true,\n            \"availability_zone\": \"eu-west-3c\",\n            \"capacity_reservation_specification\": [\n              {\n                \"capacity_reservation_preference\": \"open\",\n                \"capacity_reservation_target\": []\n              }\n            ],\n            \"cpu_core_count\": 1,\n            \"cpu_options\": [\n              {\n                \"amd_sev_snp\": \"\",\n                \"core_count\": 1,\n                \"threads_per_core\": 2\n              }\n            ],\n            \"cpu_threads_per_core\": 2,\n            \"credit_specification\": [\n              {\n                \"cpu_credits\": \"unlimited\"\n              }\n            ],\n            \"disable_api_stop\": false,\n            \"disable_api_termination\": false,\n            \"ebs_block_device\": [],\n            \"ebs_optimized\": false,\n            \"enable_primary_ipv6\": null,\n            \"enclave_options\": [\n              {\n                \"enabled\": false\n              }\n            ],\n            \"ephemeral_block_device\": [],\n            \"get_password_data\": false,\n            \"hibernation\": false,\n            \"host_id\": \"\",\n            \"host_resource_group_arn\": null,\n            \"iam_instance_profile\": \"\",\n            \"id\": \"i-0343344212a5a2b7d\",\n            \"instance_initiated_shutdown_behavior\": \"stop\",\n            \"instance_lifecycle\": \"\",\n            \"instance_market_options\": [],\n            \"instance_state\": \"running\",\n            \"instance_type\": \"t3.micro\",\n            \"ipv6_address_count\": 0,\n            \"ipv6_addresses\": [],\n            \"key_name\": \"\",\n            \"launch_template\": [],\n            \"maintenance_options\": [\n              {\n                \"auto_recovery\": \"default\"\n              }\n            ],\n            \"metadata_options\": [\n              {\n                \"http_endpoint\": \"enabled\",\n                \"http_protocol_ipv6\": \"disabled\",\n                \"http_put_response_hop_limit\": 1,\n                \"http_tokens\": \"optional\",\n                \"instance_metadata_tags\": \"disabled\"\n              }\n            ],\n            \"monitoring\": false,\n            \"network_interface\": [],\n            \"outpost_arn\": \"\",\n            \"password_data\": \"\",\n            \"placement_group\": \"\",\n            \"placement_partition_number\": 0,\n            \"primary_network_interface_id\": \"eni-019b97d38ad8bbc1a\",\n            \"private_dns\": \"ip-172-31-46-161.eu-west-3.compute.internal\",\n            \"private_dns_name_options\": [\n              {\n                \"enable_resource_name_dns_a_record\": false,\n                \"enable_resource_name_dns_aaaa_record\": false,\n                \"hostname_type\": \"ip-name\"\n              }\n            ],\n            \"private_ip\": \"172.31.46.161\",\n            \"public_dns\": \"ec2-13-37-220-7.eu-west-3.compute.amazonaws.com\",\n            \"public_ip\": \"13.37.220.7\",\n            \"root_block_device\": [\n              {\n                \"delete_on_termination\": true,\n                \"device_name\": \"/dev/xvda\",\n                \"encrypted\": false,\n                \"iops\": 3000,\n                \"kms_key_id\": \"\",\n                \"tags\": {},\n                \"tags_all\": {},\n                \"throughput\": 125,\n                \"volume_id\": \"vol-0cae9505d90a3918b\",\n                \"volume_size\": 8,\n                \"volume_type\": \"gp3\"\n              }\n            ],\n            \"secondary_private_ips\": [],\n            \"security_groups\": [\"default\"],\n            \"source_dest_check\": true,\n            \"spot_instance_request_id\": \"\",\n            \"subnet_id\": \"subnet-051cb59940ea1c15e\",\n            \"tags\": {\n              \"Name\": \"HelloWorld\"\n            },\n            \"tags_all\": {\n              \"Name\": \"HelloWorld\"\n            },\n            \"tenancy\": \"default\",\n            \"timeouts\": null,\n            \"user_data\": null,\n            \"user_data_base64\": null,\n            \"user_data_replace_on_change\": false,\n            \"volume_tags\": null,\n            \"vpc_security_group_ids\": [\"sg-07c5de6c1a356fd8f\"]\n          },\n          \"sensitive_attributes\": [],\n          \"private\": \"xxxxxxxxxxxxxxxxxxxxxxxxx\",\n          \"dependencies\": [\"aws_security_group.allow_ssh\"]\n        }\n      ]\n    },\n    {\n      \"mode\": \"managed\",\n      \"type\": \"aws_security_group\",\n      \"name\": \"allow_ssh\",\n      \"provider\": \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\",\n      \"instances\": [\n        {\n          \"schema_version\": 1,\n          \"attributes\": {\n            \"arn\": \"arn:aws:ec2:eu-west-3:842445166689:security-group/sg-07c5de6c1a356fd8f\",\n            \"description\": \"Allow SSH inbound traffic\",\n            \"egress\": [\n              {\n                \"cidr_blocks\": [\"0.0.0.0/0\"],\n                \"description\": \"\",\n                \"from_port\": 0,\n                \"ipv6_cidr_blocks\": [],\n                \"prefix_list_ids\": [],\n                \"protocol\": \"-1\",\n                \"security_groups\": [],\n                \"self\": false,\n                \"to_port\": 0\n              }\n            ],\n            \"id\": \"sg-07c5de6c1a356fd8f\",\n            \"ingress\": [\n              {\n                \"cidr_blocks\": [\"0.0.0.0/0\"],\n                \"description\": \"SSH from anywhere\",\n                \"from_port\": 22,\n                \"ipv6_cidr_blocks\": [],\n                \"prefix_list_ids\": [],\n                \"protocol\": \"tcp\",\n                \"security_groups\": [],\n                \"self\": false,\n                \"to_port\": 22\n              }\n            ],\n            \"name\": \"terraform-20250310103052126100000001\",\n            \"name_prefix\": \"terraform-\",\n            \"owner_id\": \"842445166689\",\n            \"revoke_rules_on_delete\": false,\n            \"tags\": {\n              \"Name\": \"allow-ssh\"\n            },\n            \"tags_all\": {\n              \"Name\": \"allow-ssh\"\n            },\n            \"timeouts\": null,\n            \"vpc_id\": \"vpc-08fd73e2c03c3f90b\"\n          },\n          \"sensitive_attributes\": [],\n          \"private\": \"xxxxxxxxxxxxxxxxxxxxxxxxx\"\n        }\n      ]\n    }\n  ],\n  \"check_results\": null\n}\n</code></pre>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#remote-backends-sharing-the-memory","title":"Remote Backends: Sharing the Memory","text":"<p>For solo projects, a local state file might suffice. But for teams or critical infrastructure, you need a remote backend. This is like storing your master blueprint in a secure, shared location.</p> <p>Popular remote backends include:</p> <ul> <li>Amazon S3: Store your state file in a secure, scalable object storage service.</li> <li>Azure Storage: Leverage Azure's storage capabilities for your state file.</li> <li>Terraform Cloud: HashiCorp's managed service for state storage, collaboration, and more.</li> </ul> backend.tf<pre><code>terraform {\n  backend \"s3\" {\n    bucket         = \"&lt;%= expansion('tekos-terraform-tfstate-:PROJECT-:ENV') %&gt;\"\n    key            = \"&lt;%= expansion(':TYPE_DIR/:APP/:ROLE/:MOD_NAME/:ENV/:EXTRA/:REGION/terraform.tfstate') %&gt;\"\n    region         = \"&lt;%= expansion(':REGION') %&gt;\"\n    encrypt        = true\n    dynamodb_table = \"terraform_locks\"\n    role_arn       = \"arn:aws:iam::&lt;%= account_ids_map %&gt;:role/deploy-role\"\n  }\n}\n</code></pre>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#state-locking-preventing-conflicts","title":"State Locking: Preventing Conflicts","text":"<p>Imagine two builders trying to modify the same section of your LEGO city at the same time. Chaos ensues. State locking prevents this by ensuring that only one person can modify the state file at a time.</p> <p>This is typically achieved using a locking mechanism provided by your remote backend, such as DynamoDB for S3.</p> backend.tf<pre><code>terraform {\n  backend \"s3\" {\n    bucket         = \"&lt;%= expansion('tekos-terraform-tfstate-:PROJECT-:ENV') %&gt;\"\n    key            = \"&lt;%= expansion(':TYPE_DIR/:APP/:ROLE/:MOD_NAME/:ENV/:EXTRA/:REGION/terraform.tfstate') %&gt;\"\n    region         = \"&lt;%= expansion(':REGION') %&gt;\"\n    encrypt        = true\n    dynamodb_table = \"terraform_locks\"\n    role_arn       = \"arn:aws:iam::&lt;%= account_ids_map %&gt;:role/deploy-role\"\n  }\n}\n</code></pre>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#workspaces-managing-multiple-environments","title":"Workspaces: Managing Multiple Environments","text":"<p>If you're managing development, staging, and production environments, Terraform workspaces are your friend. They allow you to maintain separate state files for each environment within the same configuration.</p> <p>It's like having separate building sites for each district of your LEGO city.</p> app.rb<pre><code># Docs: https://terraspace.cloud/docs/config/reference/\nTerraspace.configure do |config|\n  config.logger.level = :info\n  config.build.cache_dir = \":ENV/:BUILD_DIR\"\n  config.allow.envs = [\"shared\",\"dev\",\"stage\",\"prod\"] \n  config.test_framework = \"rspec\"\n  config.all.concurrency = 5\n  config.all.exit_on_fail.plan = false\n  config.all.exit_on_fail.up = true\n  config.build.clean_cache = false\n  config.build.copy_modules = true\nend\n</code></pre>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#real-world-scenario-1-the-whoops-i-deleted-production-moment","title":"Real-World Scenario 1: The \"Whoops, I Deleted Production\" Moment","text":"<p>We've all been there, right? You're tinkering with your dev environment, maybe a little late-night coding after a full, hardworking day, and BAM! You accidentally <code>terraform destroy</code> your production database. It's like accidentally hitting \"delete all\" on your family photo album folder.</p> <ul> <li>The \"Oh Crap\" Moment: Your heart's pounding, you're sweating a little, and you're picturing your boss's face.</li> <li>State to the Rescue: If you're using a remote backend with versioning (like, say, an S3 bucket with versioning turned on), you can rewind time. You grab a previous version of your state file, like finding a backup of your photo album.</li> <li>The \"Phew\" Moment: You run terraform apply with the restored state, and your database is back like nothing ever happened.</li> </ul> <p>Example State Snippet (Before the 'Oops') terraform.tfstate<pre><code>{\n  \"resources\": [\n    {\n      \"mode\": \"managed\",\n      \"type\": \"aws_db_instance\",\n      \"name\": \"prod_database\",\n      \"instances\": [\n        {\n          \"attributes\": {\n            \"allocated_storage\": 50,\n            \"db_name\": \"production_data\",\n            \"id\": \"arn:aws:rds:us-east-1:your-db-id\",\n            \"instance_class\": \"db.m5.large\"\n          }\n        }\n      ]\n    }\n  ]\n}\n</code></pre></p>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#real-world-scenario-2-the-teamwork-tango-that-goes-wrong","title":"Real-World Scenario 2: The Teamwork Tango (That Goes Wrong)","text":"<p>You're working with a team, everyone's making changes, and suddenly, things start getting weird. It's like trying to cook a meal with too many cooks in the kitchen.</p> <ul> <li>The \"Wait, What?\" Moment: Two people run terraform apply at the same time, and someone's changes get overwritten. It's like someone changing the recipe mid-cook.</li> <li>State Locking Saves the Day: With DynamoDB state locking, it's like putting a \"Reserved\" sign on the recipe. Only one person can make changes at a time.</li> <li>The \"Smooth Sailing\" Moment: Conflicts are avoided, and everyone's happy.</li> </ul> <p>DynamoDB Lock Example (Simplified) terraform.tfstate<pre><code>{\n  \"LockID\": \"terraform/state\",\n  \"Locked\": true,\n  \"Owner\": \"Alice\",\n  \"Version\": 1\n}\n</code></pre></p>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#real-world-scenario-3-the-multi-environment-muddle","title":"Real-World Scenario 3: The Multi-Environment Muddle","text":"<p>You've got dev, staging, and prod environments, and you're trying to keep them separate. It's like trying to keep your socks and underwear separate in the laundry.</p> <ul> <li>The \"Uh Oh\" Moment: Changes in dev start affecting prod. It's like accidentally washing your red socks with your white shirts.</li> <li>Workspaces to the Rescue: Workspaces are like separate laundry baskets for each environment.</li> <li>The \"Organized Laundry\" Moment: Each environment gets its own state file, and everyone's happy.</li> </ul> <p>Example S3 Structure  tree terraform-state-aws-projectx<pre><code>terraform-state-aws-projectx/\n\u251c\u2500\u2500 terraform/\n\u2502   \u251c\u2500\u2500 dev/\n\u2502   \u2502   \u2514\u2500\u2500 eu-west-3/\n\u2502   \u2502       \u2514\u2500\u2500 terraform.tfstate\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2502   \u2514\u2500\u2500 eu-west-3/\n\u2502   \u2502       \u2514\u2500\u2500 terraform.tfstate\n\u2502   \u2514\u2500\u2500 prod/\n\u2502       \u2514\u2500\u2500 eu-west-3/\n\u2502           \u2514\u2500\u2500 terraform.tfstate\n</code></pre></p>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#real-world-scenario-4-the-cloud-migration-shuffle","title":"Real-World Scenario 4: The Cloud Migration Shuffle","text":"<p>You're moving your stuff from one cloud to another. It's like moving houses, but with servers.</p> <ul> <li>The \"Where Did I Put That?\" Moment: Keeping track of everything manually is a nightmare.</li> <li>State as Your Moving Checklist: You import your old resources into Terraform and gradually migrate them.</li> <li>The \"Smooth Move\" Moment: Everything's tracked and organized.</li> </ul> <p>Example State Snippet (After Import) terraform.tfstate<pre><code>{\n  \"resources\": [\n    {\n      \"mode\": \"imported\",\n      \"type\": \"legacy_server\",\n      \"name\": \"old_server\",\n      \"instances\": [\n        {\n          \"attributes\": {\n            \"id\": \"old-server-id\",\n            \"legacy_attribute\": \"value\"\n          }\n        }\n      ]\n    },\n    {\n      \"mode\": \"managed\",\n      \"type\": \"aws_instance\",\n      \"name\": \"new_server\",\n      \"instances\": []\n    }\n  ]\n}\n</code></pre></p>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#real-world-scenario-5-the-security-audit-showdown","title":"Real-World Scenario 5: The Security Audit Showdown","text":"<p>The auditors are coming, and you need to show them you're doing things right. It's like getting your house ready for inspection.</p> <ul> <li>The \"Nervous Sweats\" Moment: Manually gathering compliance info is a pain.</li> <li>State as Your Compliance Record: It's got all the details the auditors need.</li> <li>The \"Passed Inspection\" Moment: You generate reports from your state, and everyone's happy.</li> </ul> <p>Example State Snippet (Security Group) terraform.tfstate<pre><code>{\n  \"resources\": [\n    {\n      \"mode\": \"managed\",\n      \"type\": \"aws_security_group\",\n      \"name\": \"web_sg\",\n      \"instances\": [\n        {\n          \"attributes\": {\n            \"ingress\": [\n              {\n                \"cidr_blocks\": [\"0.0.0.0/0\"],\n                \"from_port\": 80,\n                \"protocol\": \"tcp\",\n                \"to_port\": 80\n              }\n            ],\n            \"egress\": [\n              {\n                \"cidr_blocks\": [\"0.0.0.0/0\"],\n                \"from_port\": 0,\n                \"protocol\": \"-1\",\n                \"to_port\": 0\n              }\n            ]\n          }\n        }\n      ]\n    }\n  ]\n}\n</code></pre></p> <p>So, yeah, the Terraform state might not be the most glamorous part of your job, but it's the unsung hero that keeps your digital world from falling apart. Treat it right, and it'll treat you right. It's like having a good friend who always remembers where you left your keys.</p>"},{"location":"projects/2025/03/16/terraform-state-management-a-practical-guide-with-real-world-scenarios/#conclusion","title":"Conclusion","text":"<p>So, in the end, the Terraform state is like that trusty sidekick you never knew you needed. It's not the flashy superhero, but it's the one who keeps everything running smoothly behind the scenes. It's the memory, the blueprint, the safety net, and the ultimate peace of mind for any infrastructure architect. Treat it right, and it'll keep your digital world spinning happily, no matter how complex your creations become. Think of it as your infrastructure's best friend, always there to lend a helping hand (or a backup file).</p>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/","title":"The Architect's Guide: Terraform Lifecycle Management Explained","text":"<p>Imagine your Terraform project is a grand building construction. You're not just throwing bricks together; you're meticulously designing a complex structure, a testament to your infrastructure-as-code expertise.</p> <p></p> <ul> <li>Thanks to  for supporting this content.</li> </ul>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#1-the-architectural-blueprint-terraform-init","title":"1. The Architectural Blueprint: <code>terraform init</code>","text":"<p>This is like the initial architectural planning phase. You're gathering all the necessary resources and tools before construction begins.</p> <p>You're downloading the specialized construction materials (providers) that enable you to build specific components of your building (e.g., steel beams for skyscrapers, plumbing for water systems). You're setting up the site office (remote backend), where all the blueprints and important documents (state) are stored. You're ensuring all the necessary tools and equipment are available (initializing the working directory).</p> terraform init<pre><code>    Initializing the backend...\n\n    Initializing provider plugins...\n    - Finding latest version of hashicorp/aws...\n    - Installing hashicorp/aws v5.90.0...\n    - Installed hashicorp/aws v5.90.0 (signed by HashiCorp)\n\n    Terraform has created a lock file .terraform.lock.hcl to record the provider\n    selections it made above. Include this file in your version control repository\n    so that Terraform can guarantee to make the same selections by default when\n    you run \"terraform init\" in the future.\n\n    Terraform has been successfully initialized!\n\n    You may now begin working with Terraform. Try running \"terraform plan\" to see\n    any changes that are required for your infrastructure. All Terraform commands\n    should now work.\n\n    If you ever set or change modules or backend configuration for Terraform,\n    rerun this command to reinitialize your working directory. If you forget, other\n    commands will detect it and remind you to do so if necessary.\n</code></pre>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#2-the-foundation-laying-terraform-apply-initial-deployment","title":"2. The Foundation Laying: <code>terraform apply</code> (Initial Deployment)","text":"<p>This is the initial construction phase, where you're laying the foundation and erecting the main structure.</p> <p>You're following the architectural blueprints (your code) to build the core components of your building. You're ensuring that the foundation is solid and that the main structure is stable. Terraform is actively creating resources, such as Virtual Machines, networks, and databases, which are the building blocks of your digital building.</p> terraform apply<pre><code>Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # aws_instance.web will be created\n  + resource \"aws_instance\" \"web\" {\n      + ami                                  = \"ami-0076ac74e7710cd06\"\n      + arn                                  = (known after apply)\n      + associate_public_ip_address          = (known after apply)\n      + availability_zone                    = (known after apply)\n      + cpu_core_count                       = (known after apply)\n      + cpu_threads_per_core                 = (known after apply)\n      + disable_api_stop                     = (known after apply)\n      + disable_api_termination              = (known after apply)\n      + ebs_optimized                        = (known after apply)\n      + enable_primary_ipv6                  = (known after apply)\n      + get_password_data                    = false\n      + host_id                              = (known after apply)\n      + host_resource_group_arn              = (known after apply)\n      + iam_instance_profile                 = (known after apply)\n      + id                                   = (known after apply)\n      + instance_initiated_shutdown_behavior = (known after apply)\n      + instance_lifecycle                   = (known after apply)\n      + instance_state                       = (known after apply)\n      + instance_type                        = \"t3.micro\"\n      + ipv6_address_count                   = (known after apply)\n      + ipv6_addresses                       = (known after apply)\n      + key_name                             = (known after apply)\n      + monitoring                           = (known after apply)\n      + outpost_arn                          = (known after apply)\n      + password_data                        = (known after apply)\n      + placement_group                      = (known after apply)\n      + placement_partition_number           = (known after apply)\n      + primary_network_interface_id         = (known after apply)\n      + private_dns                          = (known after apply)\n      + private_ip                           = (known after apply)\n      + public_dns                           = (known after apply)\n      + public_ip                            = (known after apply)\n      + secondary_private_ips                = (known after apply)\n      + security_groups                      = (known after apply)\n      + source_dest_check                    = true\n      + spot_instance_request_id             = (known after apply)\n      + subnet_id                            = (known after apply)\n      + tags                                 = {\n          + \"Name\" = \"HelloWorld\"\n        }\n      + tags_all                             = {\n          + \"Name\" = \"HelloWorld\"\n        }\n      + tenancy                              = (known after apply)\n      + user_data                            = (known after apply)\n      + user_data_base64                     = (known after apply)\n      + user_data_replace_on_change          = false\n      + vpc_security_group_ids               = (known after apply)\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nChanges to Outputs:\n  + public_ip = (known after apply)\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value: yes\n\naws_instance.web: Creating...\naws_instance.web: Still creating... [10s elapsed]\naws_instance.web: Still creating... [20s elapsed]\naws_instance.web: Creation complete after 22s [id=i-0343344212a5a2b7d]\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n\nOutputs:\n\npublic_ip = \"13.37.220.7\"\n</code></pre>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#3-the-inspection-and-planning-terraform-plan-change-preview","title":"3. The Inspection and Planning: <code>terraform plan</code> (Change Preview)","text":"<p>This is like an inspection phase, where you're reviewing the blueprints and planning any modifications.</p> <p>You're examining the proposed changes to your building before implementing them. You're identifying any potential issues or conflicts that may arise from the changes. Terraform compares the current state of your infrastructure with the desired state, showing you the changes it will make.</p> <p>First, imagine that you want to allow SSH inbound traffic to the instance; update the Terraform code main.tf<pre><code># main.tf - Example Terraform Configuration\n\n# Configure the AWS Provider\nprovider \"aws\" {\n  region = \"eu-west-3\"\n}\n\n# Create a Security Group\nresource \"aws_security_group\" \"allow_ssh\" {\n  description = \"Allow SSH inbound traffic\"\n  ingress {\n    description = \"SSH from anywhere\"\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  tags = {\n    Name = \"allow-ssh\"\n  }\n}\n\n# Create an EC2 Instance\nresource \"aws_instance\" \"web\" {\n  ami                    = \"ami-0076ac74e7710cd06\"\n  instance_type          = \"t3.micro\"\n  vpc_security_group_ids = [aws_security_group.allow_ssh.id]\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n\n# Output the Public IP of the EC2 Instance\noutput \"public_ip\" {\n  value = aws_instance.web.public_ip\n}\n</code></pre></p> <p>Second, <code>terraform plan</code> to review the changes (if any) terraform plan<pre><code>aws_instance.web: Refreshing state... [id=i-0343344212a5a2b7d]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n  ~ update in-place\n\nTerraform will perform the following actions:\n\n  # aws_instance.web will be updated in-place\n  ~ resource \"aws_instance\" \"web\" {\n        id                                   = \"i-0343344212a5a2b7d\"\n        tags                                 = {\n            \"Name\" = \"HelloWorld\"\n        }\n      ~ vpc_security_group_ids               = [\n          - \"sg-0a64bc766f1a92470\",\n        ] -&gt; (known after apply)\n        # (30 unchanged attributes hidden)\n\n        # (8 unchanged blocks hidden)\n    }\n\n  # aws_security_group.allow_ssh will be created\n  + resource \"aws_security_group\" \"allow_ssh\" {\n      + arn                    = (known after apply)\n      + description            = \"Allow SSH inbound traffic\"\n      + egress                 = [\n          + {\n              + cidr_blocks      = [\n                  + \"0.0.0.0/0\",\n                ]\n              + description      = \"\"\n              + from_port        = 0\n              + ipv6_cidr_blocks = []\n              + prefix_list_ids  = []\n              + protocol         = \"-1\"\n              + security_groups  = []\n              + self             = false\n              + to_port          = 0\n            },\n        ]\n      + id                     = (known after apply)\n      + ingress                = [\n          + {\n              + cidr_blocks      = [\n                  + \"0.0.0.0/0\",\n                ]\n              + description      = \"SSH from anywhere\"\n              + from_port        = 22\n              + ipv6_cidr_blocks = []\n              + prefix_list_ids  = []\n              + protocol         = \"tcp\"\n              + security_groups  = []\n              + self             = false\n              + to_port          = 22\n            },\n        ]\n      + name                   = (known after apply)\n      + name_prefix            = (known after apply)\n      + owner_id               = (known after apply)\n      + revoke_rules_on_delete = false\n      + tags                   = {\n          + \"Name\" = \"allow-ssh\"\n        }\n      + tags_all               = {\n          + \"Name\" = \"allow-ssh\"\n        }\n      + vpc_id                 = (known after apply)\n    }\n\nPlan: 1 to add, 1 to change, 0 to destroy.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nNote: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run \"terraform apply\" now.\n</code></pre></p>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#4-the-ongoing-construction-terraform-apply-changes","title":"4. The Ongoing Construction: <code>terraform apply</code> (Changes)","text":"<p>This is the ongoing construction phase, where you're implementing the planned modifications.</p> <p>You're implementing the changes that were identified in the inspection phase. You're ensuring that the modifications are integrated seamlessly with the existing structure. Terraform is making the required changes to your infrastructure.</p> terraform apply<pre><code>aws_instance.web: Refreshing state... [id=i-0343344212a5a2b7d]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n  ~ update in-place\n\nTerraform will perform the following actions:\n\n  # aws_instance.web will be updated in-place\n  ~ resource \"aws_instance\" \"web\" {\n        id                                   = \"i-0343344212a5a2b7d\"\n        tags                                 = {\n            \"Name\" = \"HelloWorld\"\n        }\n      ~ vpc_security_group_ids               = [\n          - \"sg-0a64bc766f1a92470\",\n        ] -&gt; (known after apply)\n        # (30 unchanged attributes hidden)\n\n        # (8 unchanged blocks hidden)\n    }\n\n  # aws_security_group.allow_ssh will be created\n  + resource \"aws_security_group\" \"allow_ssh\" {\n      + arn                    = (known after apply)\n      + description            = \"Allow SSH inbound traffic\"\n      + egress                 = [\n          + {\n              + cidr_blocks      = [\n                  + \"0.0.0.0/0\",\n                ]\n              + description      = \"\"\n              + from_port        = 0\n              + ipv6_cidr_blocks = []\n              + prefix_list_ids  = []\n              + protocol         = \"-1\"\n              + security_groups  = []\n              + self             = false\n              + to_port          = 0\n            },\n        ]\n      + id                     = (known after apply)\n      + ingress                = [\n          + {\n              + cidr_blocks      = [\n                  + \"0.0.0.0/0\",\n                ]\n              + description      = \"SSH from anywhere\"\n              + from_port        = 22\n              + ipv6_cidr_blocks = []\n              + prefix_list_ids  = []\n              + protocol         = \"tcp\"\n              + security_groups  = []\n              + self             = false\n              + to_port          = 22\n            },\n        ]\n      + name                   = (known after apply)\n      + name_prefix            = (known after apply)\n      + owner_id               = (known after apply)\n      + revoke_rules_on_delete = false\n      + tags                   = {\n          + \"Name\" = \"allow-ssh\"\n        }\n      + tags_all               = {\n          + \"Name\" = \"allow-ssh\"\n        }\n      + vpc_id                 = (known after apply)\n    }\n\nPlan: 1 to add, 1 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value: yes\n\naws_security_group.allow_ssh: Creating...\naws_security_group.allow_ssh: Creation complete after 5s [id=sg-07c5de6c1a356fd8f]\naws_instance.web: Modifying... [id=i-0343344212a5a2b7d]\naws_instance.web: Modifications complete after 5s [id=i-0343344212a5a2b7d]\n\nApply complete! Resources: 1 added, 1 changed, 0 destroyed.\n\nOutputs:\n\npublic_ip = \"13.37.220.7\"\n</code></pre>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#5-the-buildings-memory-terraform-state-list","title":"5. The Building's Memory: <code>terraform state list</code>","text":"<p>This is like the building's maintenance log, recording every change and modification.</p> <p>The state file stores the current state of your building, including all its components and configurations. It allows Terraform to track changes and ensure that the building remains consistent with the blueprints. Using a remote backend is like storing the maintenance log in a secure, centralized location.</p> terraform state list<pre><code>aws_instance.web\naws_security_group.allow_ssh\n</code></pre> <p>Info</p> <p>Terraform State Management is out of the scope of this project; please patient, you can read more at the end of this article</p>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#6-the-demolition-terraform-destroy","title":"6. The Demolition: <code>terraform destroy</code>","text":"<p>This is the demolition phase, where you're tearing down the building.</p> <p>You're removing all the components of your building in a controlled and orderly manner. You're ensuring that the site is cleared and ready for future projects. Terraform removes all the resources that it manages.</p> terraform destroy<pre><code>aws_security_group.allow_ssh: Refreshing state... [id=sg-07c5de6c1a356fd8f]\naws_instance.web: Refreshing state... [id=i-0343344212a5a2b7d]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  - destroy\n\nTerraform will perform the following actions:\n\n  # aws_instance.web will be destroyed\n  - resource \"aws_instance\" \"web\" {\n      - ami                                  = \"ami-0076ac74e7710cd06\" -&gt; null\n      - arn                                  = \"arn:aws:ec2:eu-west-3:842445166689:instance/i-0343344212a5a2b7d\" -&gt; null\n      - associate_public_ip_address          = true -&gt; null\n      - availability_zone                    = \"eu-west-3c\" -&gt; null\n      - cpu_core_count                       = 1 -&gt; null\n      - cpu_threads_per_core                 = 2 -&gt; null\n      - disable_api_stop                     = false -&gt; null\n      - disable_api_termination              = false -&gt; null\n      - ebs_optimized                        = false -&gt; null\n      - get_password_data                    = false -&gt; null\n      - hibernation                          = false -&gt; null\n      - id                                   = \"i-0343344212a5a2b7d\" -&gt; null\n      - instance_initiated_shutdown_behavior = \"stop\" -&gt; null\n      - instance_state                       = \"running\" -&gt; null\n      - instance_type                        = \"t3.micro\" -&gt; null\n      - ipv6_address_count                   = 0 -&gt; null\n      - ipv6_addresses                       = [] -&gt; null\n      - monitoring                           = false -&gt; null\n      - placement_partition_number           = 0 -&gt; null\n      - primary_network_interface_id         = \"eni-019b97d38ad8bbc1a\" -&gt; null\n      - private_dns                          = \"ip-172-31-46-161.eu-west-3.compute.internal\" -&gt; null\n      - private_ip                           = \"172.31.46.161\" -&gt; null\n      - public_dns                           = \"ec2-13-37-220-7.eu-west-3.compute.amazonaws.com\" -&gt; null\n      - public_ip                            = \"13.37.220.7\" -&gt; null\n      - secondary_private_ips                = [] -&gt; null\n      - security_groups                      = [\n          - \"terraform-20250310103052126100000001\",\n        ] -&gt; null\n      - source_dest_check                    = true -&gt; null\n      - subnet_id                            = \"subnet-051cb59940ea1c15e\" -&gt; null\n      - tags                                 = {\n          - \"Name\" = \"HelloWorld\"\n        } -&gt; null\n      - tags_all                             = {\n          - \"Name\" = \"HelloWorld\"\n        } -&gt; null\n      - tenancy                              = \"default\" -&gt; null\n      - user_data_replace_on_change          = false -&gt; null\n      - vpc_security_group_ids               = [\n          - \"sg-07c5de6c1a356fd8f\",\n        ] -&gt; null\n\n      - capacity_reservation_specification {\n          - capacity_reservation_preference = \"open\" -&gt; null\n        }\n\n      - cpu_options {\n          - core_count       = 1 -&gt; null\n          - threads_per_core = 2 -&gt; null\n        }\n\n      - credit_specification {\n          - cpu_credits = \"unlimited\" -&gt; null\n        }\n\n      - enclave_options {\n          - enabled = false -&gt; null\n        }\n\n      - maintenance_options {\n          - auto_recovery = \"default\" -&gt; null\n        }\n\n      - metadata_options {\n          - http_endpoint               = \"enabled\" -&gt; null\n          - http_protocol_ipv6          = \"disabled\" -&gt; null\n          - http_put_response_hop_limit = 1 -&gt; null\n          - http_tokens                 = \"optional\" -&gt; null\n          - instance_metadata_tags      = \"disabled\" -&gt; null\n        }\n\n      - private_dns_name_options {\n          - enable_resource_name_dns_a_record    = false -&gt; null\n          - enable_resource_name_dns_aaaa_record = false -&gt; null\n          - hostname_type                        = \"ip-name\" -&gt; null\n        }\n\n      - root_block_device {\n          - delete_on_termination = true -&gt; null\n          - device_name           = \"/dev/xvda\" -&gt; null\n          - encrypted             = false -&gt; null\n          - iops                  = 3000 -&gt; null\n          - tags                  = {} -&gt; null\n          - tags_all              = {} -&gt; null\n          - throughput            = 125 -&gt; null\n          - volume_id             = \"vol-0cae9505d90a3918b\" -&gt; null\n          - volume_size           = 8 -&gt; null\n          - volume_type           = \"gp3\" -&gt; null\n        }\n    }\n\n  # aws_security_group.allow_ssh will be destroyed\n  - resource \"aws_security_group\" \"allow_ssh\" {\n      - arn                    = \"arn:aws:ec2:eu-west-3:842445166689:security-group/sg-07c5de6c1a356fd8f\" -&gt; null\n      - description            = \"Allow SSH inbound traffic\" -&gt; null\n      - egress                 = [\n          - {\n              - cidr_blocks      = [\n                  - \"0.0.0.0/0\",\n                ]\n              - description      = \"\"\n              - from_port        = 0\n              - ipv6_cidr_blocks = []\n              - prefix_list_ids  = []\n              - protocol         = \"-1\"\n              - security_groups  = []\n              - self             = false\n              - to_port          = 0\n            },\n        ] -&gt; null\n      - id                     = \"sg-07c5de6c1a356fd8f\" -&gt; null\n      - ingress                = [\n          - {\n              - cidr_blocks      = [\n                  - \"0.0.0.0/0\",\n                ]\n              - description      = \"SSH from anywhere\"\n              - from_port        = 22\n              - ipv6_cidr_blocks = []\n              - prefix_list_ids  = []\n              - protocol         = \"tcp\"\n              - security_groups  = []\n              - self             = false\n              - to_port          = 22\n            },\n        ] -&gt; null\n      - name                   = \"terraform-20250310103052126100000001\" -&gt; null\n      - name_prefix            = \"terraform-\" -&gt; null\n      - owner_id               = \"842445166689\" -&gt; null\n      - revoke_rules_on_delete = false -&gt; null\n      - tags                   = {\n          - \"Name\" = \"allow-ssh\"\n        } -&gt; null\n      - tags_all               = {\n          - \"Name\" = \"allow-ssh\"\n        } -&gt; null\n      - vpc_id                 = \"vpc-08fd73e2c03c3f90b\" -&gt; null\n    }\n\nPlan: 0 to add, 0 to change, 2 to destroy.\n\nChanges to Outputs:\n  - public_ip = \"13.37.220.7\" -&gt; null\n\nDo you really want to destroy all resources?\n  Terraform will destroy all your managed infrastructure, as shown above.\n  There is no undo. Only 'yes' will be accepted to confirm.\n\n  Enter a value: yes\n\naws_instance.web: Destroying... [id=i-0343344212a5a2b7d]\naws_instance.web: Still destroying... [id=i-0343344212a5a2b7d, 10s elapsed]\naws_instance.web: Still destroying... [id=i-0343344212a5a2b7d, 20s elapsed]\naws_instance.web: Still destroying... [id=i-0343344212a5a2b7d, 30s elapsed]\naws_instance.web: Still destroying... [id=i-0343344212a5a2b7d, 40s elapsed]\naws_instance.web: Destruction complete after 43s\naws_security_group.allow_ssh: Destroying... [id=sg-07c5de6c1a356fd8f]\naws_security_group.allow_ssh: Destruction complete after 1s\n\nDestroy complete! Resources: 2 destroyed.\n</code></pre> <p>Now, Terraform State is cleared terraform state list<pre><code>\n</code></pre></p>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#7-building-districts-terraform-workspace","title":"7. Building Districts: <code>terraform workspace</code>","text":"<p>This is like having different districts within your city, each with its purpose and configuration.</p> <p>Workspaces allow you to manage multiple environments (e.g., dev, staging, prod) within the same Terraform configuration. Each workspace has its state file, ensuring that environments are isolated and independent. This is like having different building sites for various phases of the project.</p> terraform workspace<pre><code>Usage: terraform [global options] workspace\n\n  new, list, show, select and delete Terraform workspaces.\n\nSubcommands:\n    delete    Delete a workspace\n    list      List Workspaces\n    new       Create a new workspace\n    select    Select a workspace\n    show      Show the name of the current workspace\n</code></pre> <p>Info</p> <p>I will use Terraspace for multiple environments management, so Terraform Workspace may be fitted in some specific cases.</p>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#0-project-code-usage-and-explain","title":"0. Project Code Usage and Explain","text":"<ol> <li>Clone the example code from Github git clone https://github.com/nhamchanvi/project-as-code.git<pre><code>Cloning into 'project-as-code'...\nremote: Enumerating objects: 4, done.\nremote: Counting objects: 100% (4/4), done.\nremote: Compressing objects: 100% (3/3), done.\nremote: Total 4 (delta 0), reused 4 (delta 0), pack-reused 0 (from 0)\nReceiving objects: 100% (4/4), done.\n</code></pre></li> <li>Change the directory to the <code>project-as-code/terraform-lifecycle-management</code> cd project-as-code/terraform-lifecycle-management<pre><code>\n</code></pre></li> <li>List the files/dirs inside the project folder ls -alh<pre><code>total 16K\ndrwxrwxr-x 2 chanvi chanvi 4.0K Mar 10 17:49 .\ndrwxrwxr-x 4 chanvi chanvi 4.0K Mar 10 17:49 ..\n-rw-rw-r-- 1 chanvi chanvi  102 Mar 10 17:49 .gitignore\n-rw-rw-r-- 1 chanvi chanvi  909 Mar 10 17:49 main.tf\n</code></pre></li> <li> <p>Inspect the <code>main.tf</code> main.tf<pre><code># main.tf - Example Terraform Configuration\n\n# Configure the AWS Provider\nprovider \"aws\" {\n  region = \"eu-west-3\"\n}\n\n# Create a Security Group\n# resource \"aws_security_group\" \"allow_ssh\" {\n#   description = \"Allow SSH inbound traffic\"\n#   ingress {\n#     description = \"SSH from anywhere\"\n#     from_port   = 22\n#     to_port     = 22\n#     protocol    = \"tcp\"\n#     cidr_blocks = [\"0.0.0.0/0\"]\n#   }\n#   egress {\n#     from_port   = 0\n#     to_port     = 0\n#     protocol    = \"-1\"\n#     cidr_blocks = [\"0.0.0.0/0\"]\n#   }\n#   tags = {\n#     Name = \"allow-ssh\"\n#   }\n# }\n\n# Create an EC2 Instance\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-0076ac74e7710cd06\"\n  instance_type = \"t3.micro\"\n  # vpc_security_group_ids = [aws_security_group.allow_ssh.id]\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n\n# Output the Public IP of the EC2 Instance\noutput \"public_ip\" {\n  value = aws_instance.web.public_ip\n}\n</code></pre></p> <ul> <li><code>provider \"aws\"</code>: Configures the AWS provider, specifying the region.</li> <li><code>resource \"aws_security_group\" \"allow_ssh\"</code>: Creates a security group that allows SSH access.</li> <li><code>resource \"aws_instance\" \"web\"</code>: This creates an EC2 instance in the subnet, using the security group.</li> <li><code>output \"public_ip\"</code>: Outputs the public IP address of the EC2 instance.</li> </ul> </li> </ol>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#conclusion","title":"Conclusion","text":"<p>Alright, so, we've talked a lot about how Terraform helps you build your digital stuff, right? It's kind of like having an organized construction crew for your servers and networks. You start by getting all your tools ready with <code>terraform init</code>, then you lay down the foundation with <code>terraform apply</code>. You peek at the blueprints with <code>terraform plan</code> before making any big changes, and then you build on top of that foundation, again with <code>terraform apply</code>.</p> <p>And, you know, just like any good construction project, you gotta keep track of everything. That's what the state file is for \u2013 it's like your project diary. And when you're done, or if you need to tear things down, <code>terraform destroy</code> is your wrecking ball.</p> <p>Terraform's lifecycle is just a fancy way of saying it helps you manage your infrastructure from start to finish. It keeps things consistent, so you don't end up with a mess of servers and networks that you can't control. And honestly, it saves you a ton of headaches in the long run. So, whether you're building a tiny website or a massive cloud setup, Terraform's got your back.</p>"},{"location":"projects/2025/03/09/the-architects-guide-terraform-lifecycle-management-explained/#references","title":"References","text":"<ul> <li>Terraform State Management: A Practical Guide with Real-World Scenarios</li> </ul>"},{"location":"questions/advanced-level/","title":"Questions","text":"\ud83c\udf36\ufe0f\ud83c\udf36\ufe0f\ud83c\udf36\ufe0f How would you migrate an existing application to a containerized environment? Recall for longterm memory <p>To migrate an existing application to a containerized environment, I will need to do 2 parts:</p> <ol> <li>Development on local<ol> <li>Figure out any external dependency, such as database, do I need to containerize it?</li> <li>Figure out what parts of the application need to be containerized together. For example, if I have frontend, backend. I will need to see which part I need to containerize, both frontend and backend, or seperated frontend with backend?</li> <li>Create the Dockerfile and define the entire architecture in that configuration, including the interservice dependencies.</li> <li>Build the actual Docker image.</li> <li>Make sure it runs locally.</li> </ol> </li> <li>Deploy to production<ol> <li>Configure the orchestration tool (such as Kubernestes) to manage the containers.</li> <li>If I have dev or staging environment, I could make a test before moving to prod.</li> <li>Once all testings have been passed, I am ready to deploy to production, however, make sure the monitoring and alerting on any problem shortly after the deployment in case I need to roll back.</li> </ol> </li> </ol> \ud83c\udf36\ufe0f\ud83c\udf36\ufe0f\ud83c\udf36\ufe0f Describle your approach to implementing security in a DevOps pipeline (DevSecOps) Recall for longterm memory <p>To implement security in a DevOps pipeline (DevSecOps), I will integrate security practices throughout the development and deployment process, not only about securing the app once it's in production but also about securing the entire app creation process. There are 7 techniques:</p> <ol> <li>Shift Left Security: I perform SAST includes static code analysis, dependency scanning and secret detection during the build phase.</li> <li>Automated Testing: I perform DAST, vulnerability scans to identify potential security issues before they reach production.</li> <li>Continuous Monitoring: after the app reach production, I continue to monitor the pipeline and applications for security incidents using tools like Prometheus, Grafrana, ELK, Datalog and specialized security monitoring tools.</li> <li>Infrastructure as Code - Security: I perform security scans for IaC templates/configuration for any misconfigurations and vulnerabilities (like hardcorded passwords)</li> <li>Access Control: I implement RBAC or ABAC and enforcing the principle of least privilege across the pipeline.</li> <li>Compliance Checks: figure out the compliance requirements and regulations of client industry and integrate those checks to ensure the pipeline adheres to industry standards and regulatory requirements.</li> <li>Incidient Response: figure out a clear incident response plan and integrate security alerts into the pipeline to quickly address potential security breaches.</li> </ol> \ud83c\udf36\ufe0f\ud83c\udf36\ufe0f\ud83c\udf36\ufe0f What are the advantages and disadvantages of using Kubernetes Operators? Recall for longterm memory <ol> <li>Advantages:<ol> <li>Automation of Complex Tasks: automate the management of complex stateful applications (like databases) reducing the need for manual intervention.</li> <li>Consistency: reduce human error and increase reliability by ensuring consistent deployments, scaling, and management of applications across environments.</li> <li>Custom Resource Management: allow I to manage custom resources in Kubernetes, extending its capabilities to support more complex applications and services.</li> <li>Simplified Day-2 Operations: streamline tasks like backup, upgrades, and failure recovery, making it easier to manage applications over time.</li> </ol> </li> <li>Disadvantages:<ol> <li>Complexity: developing and maintaining Operators can be complex and require in-depth knowledge of both Kubernetes and the specific application being managed.</li> <li>Overhead: running Operators adds additional components to your Kubernetes cluster, which can increase resource consumption and operational overhead.</li> <li>Limited Use Cases: not all applications benefit from the complexity of an Operator; for simple stateless applications, Operators might be overkill.</li> <li>Maintenance: Operators need to be regularly maintained and updated, especially as Kubernetes ifselt keeps evolving, which can add to the maintenance burden.</li> </ol> </li> </ol> \ud83c\udf36\ufe0f\ud83c\udf36\ufe0f\ud83c\udf36\ufe0f How would you optimize a CI/CD pipeline for performance and reliability? Recall for longterm memory <p>It all depends highly on the tech stack and my specific context. However, three are some potential solutions:</p> <ol> <li>Parallelize Jobs: I try to run independent jobs in parallel to reduce overall build and test times. The result is faster feedback and speeds up the entire pipeline.</li> <li>Optimizing Build Caching: I use caching mechanisms to avoid redundant work (like re-downloading dependencies or rebuilding unchanged components). This can significantly reduce build times.</li> <li>Incremental Builds: I implement incremental builds that only rebuild parts of the codebase that have changed, rather than the entire project. It is useful for large projects with big codebases.</li> <li>Efficient Testing: prioritize and parallelize tests, running faster unit tests early and reserving more intensive integration or end-to-end tests for later stages. I use test impact analysis to only run test affected by recent code changes.</li> <li>Monitor Pipeline Health: continuosly monitor the pipeline for bottlenecks, failures, and performance issues. Use metrics and logs to identify and address inefficiencies.</li> <li>Environment Consistency: I use containerization and/or Infrastructure as Code (IaC) to maintain environment parity. My code works in all environments.</li> <li>Pipeline Stages: I use pipeline stages to catch issues early (for example, fail fast on linting or static code analysis before moving on to more resource-intensive stages)</li> </ol>"},{"location":"tutorials/","title":"Index","text":"<ul> <li> <p> Automated LEMP Stack</p> <p>Deploying a LEMP Stack in Minutes with OpenTofu and Terraspace on AWS</p> <p> Getting started</p> </li> </ul>"},{"location":"tutorials/creating-a-hosted-zone-and-records-in-route53-with-opentofu/","title":"Creating a hosted zone and records in route53 with opentofu","text":"<p>Managing DNS with OpenTofu: Creating a Hosted Zone and Records in Route 53 In this tutorial, we'll explore Route 53, Amazon's scalable and reliable DNS service. We'll create a hosted zone and configure DNS records to manage your domain names.</p> <p>Why Route 53? Route 53 provides a highly available and scalable DNS service, allowing you to route traffic to your applications and resources. It offers features like health checks, traffic policies, and domain registration.</p> <p>Step 1: Define the Hosted Zone Create a file named route53.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_route53_zone\" \"main\" {   name = \"example.com\"  # Replace with your domain name</p> <p>tags = {     Name = \"My Hosted Zone\"   } } This defines a hosted zone for the domain example.com. Replace this with your actual domain name.</p> <p>Step 2: Define DNS Records Now, let's add some DNS records to our hosted zone. Add the following code to route53.tf:</p> <p>Terraform</p> <p>resource \"aws_route53_record\" \"www\" {   zone_id = aws_route53_zone.main.zone_id   name    = \"www\"   type    = \"A\"   ttl     = \"300\"   records = [aws_lb.example.dns_name] # Replace with your ALB's DNS name }</p> <p>resource \"aws_route53_record\" \"root\" {   zone_id = aws_route53_zone.main.zone_id   name    = \"example.com\" # Replace with your domain name   type    = \"A\"   ttl     = \"300\"   alias {     name                   = aws_lb.example.dns_name # Replace with your ALB's DNS name     zone_id                = aws_lb.example.zone_id     evaluate_target_health = true   } } This creates two A records:</p> <p>www: Points www.example.com to your Application Load Balancer. root: Points example.com to your Application Load Balancer using an alias record. Step 3: Apply the Changes Run the OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 4: Verify Your Hosted Zone and Records You can verify the creation of your hosted zone and records in the AWS console by navigating to the Route 53 dashboard.</p>"},{"location":"tutorials/creating-a-mysql-database-with-opentofu/","title":"Creating a mysql database with opentofu","text":"<p>Creating a MySQL Database with OpenTofu In this tutorial, we'll provision a MySQL database using Amazon Relational Database Service (RDS).</p> <p>Why RDS? RDS makes it easy to set up, operate, and scale a relational database in the cloud. It handles routine database tasks such as backups, software patching, and automatic failure detection.</p> <p>Step 1: Define the RDS Instance Create a file named database.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_db_instance\" \"default\" {   allocated_storage    = 20   db_name              = \"mydb\"   engine               = \"mysql\"   engine_version       = \"8.0\"   instance_class       = \"db.t3.micro\"   identifier           = \"mydb-instance\"   username             = \"admin\"  # Replace with your desired username   password             = \"password\" # Replace with a strong password   vpc_security_group_ids = [aws_security_group.allow_ssh.id] # Replace with your security group ID   skip_final_snapshot  = true } This defines a MySQL RDS instance with specified parameters like storage, engine version, instance class, and credentials.</p> <p>Step 2: Apply the Changes Run the OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 3: Verify Your Database You can verify the database creation in the AWS console by navigating to the RDS dashboard.</p>"},{"location":"tutorials/creating-a-security-group-with-opentofu/","title":"Creating a security group with opentofu","text":"<p>Securing Your Server: Creating a Security Group with OpenTofu In our previous tutorial, you learned how to launch a Linux server on AWS using OpenTofu. Now, it's time to take a crucial step towards securing your server by creating a security group.</p> <p>Why Security Groups?</p> <p>Think of a security group as a virtual firewall for your server. It controls inbound and outbound traffic, allowing you to specify which ports and protocols are allowed to access your server. This helps protect your server from unauthorized access and malicious attacks.</p> <p>Step 1:  Define the Security Group</p> <p>Let's create an OpenTofu configuration file to define our security group. Create a new file named security_group.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_security_group\" \"allow_ssh\" {   name = \"allow_ssh\"   description = \"Allow SSH inbound traffic\"</p> <p>ingress {     from_port   = 22     to_port     = 22     protocol    = \"tcp\"     cidr_blocks = [\"0.0.0.0/0\"] #  Allow SSH from anywhere (for demonstration purposes)   }</p> <p>egress {     from_port   = 0     to_port     = 0     protocol    = \"-1\"     cidr_blocks = [\"0.0.0.0/0\"]   }</p> <p>tags = {     Name = \"allow_ssh\"   } } Let's break down this code:</p> <p>resource \"aws_security_group\" \"allow_ssh\" block: This defines a security group resource named \"allow_ssh\". name: The name of the security group. description: A brief description of the security group's purpose. ingress: This block defines inbound traffic rules. from_port and to_port: Specify the port range to allow. In this case, we're allowing traffic on port 22 (SSH). protocol: Specifies the protocol to allow (TCP, UDP, ICMP). cidr_blocks: Specifies the IP address ranges allowed to access the port. \"0.0.0.0/0\" allows access from anywhere (for this tutorial, we'll allow SSH from anywhere for simplicity. In a production environment, you would restrict this to your own IP address or a trusted range). egress: This block defines outbound traffic rules. We're allowing all outbound traffic by default. tags: Adds tags to the security group for easy identification. Step 2:  Associate the Security Group with Your Instance</p> <p>Now, let's modify your main.tf file from the previous tutorial to associate this security group with your EC2 instance. Add the following line within the aws_instance resource block:</p> <p>Terraform</p> <p>vpc_security_group_ids = [aws_security_group.allow_ssh.id] Your updated main.tf file should now look like this:</p> <p>Terraform</p> <p>terraform {   required_providers {     aws = {       source  = \"hashicorp/aws\"       version = \"~&gt; 4.0\"     }   } }</p> <p>provider \"aws\" {   region = \"us-west-2\" # Replace with your desired region }</p> <p>resource \"aws_instance\" \"example\" {   ami                    = \"ami-0c94855ba95c574c8\" # Replace with a suitable AMI ID for your region   instance_type          = \"t2.micro\"   vpc_security_group_ids = [aws_security_group.allow_ssh.id] # Associate the security group   tags = {     Name = \"My First Instance\"   } } This line tells OpenTofu to associate the security group we defined in security_group.tf with our EC2 instance.</p> <p>Step 3:  Apply the Changes</p> <p>Open your terminal, navigate to the directory containing your OpenTofu files, and run the following commands:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply OpenTofu will create the security group and associate it with your EC2 instance.</p> <p>Step 4:  Verify Your Security Group</p> <p>You can verify the security group configuration in the AWS console by navigating to the EC2 dashboard and selecting \"Security Groups\". You should see your newly created security group with the inbound rule for SSH.</p> <p>Congratulations! You've successfully secured your server by creating a security group with OpenTofu.</p> <p>Next Steps:</p> <p>Try modifying the security group rules to allow different ports or protocols. Explore other security group features, such as egress rules and network interfaces. Learn how to use security groups to control access to other AWS resources, such as databases and load balancers.</p>"},{"location":"tutorials/creating-a-vpc-and-subnets-with-opentofu/","title":"Creating a vpc and subnets with opentofu","text":"<p>Networking with OpenTofu: Creating a VPC and Subnets In this tutorial, we'll dive into networking with OpenTofu. We'll create a Virtual Private Cloud (VPC) and subnets, the fundamental building blocks of your AWS network infrastructure.</p> <p>Why VPCs and Subnets? A VPC provides an isolated network environment within AWS where you can launch AWS resources. Subnets segment your VPC into smaller, isolated networks, allowing you to control traffic flow and security.</p> <p>Step 1: Define the VPC Create a file named vpc.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_vpc\" \"main\" {   cidr_block = \"10.0.0.0/16\"</p> <p>tags = {     Name = \"My VPC\"   } } This defines a VPC with the CIDR block 10.0.0.0/16, providing a range of private IP addresses for your resources.</p> <p>Step 2: Define Subnets Now, let's create two subnets within our VPC. Add the following code to vpc.tf:</p> <p>Terraform</p> <p>resource \"aws_subnet\" \"public_subnet_1\" {   vpc_id     = aws_vpc.main.id   cidr_block = \"10.0.1.0/24\"   availability_zone = \"us-west-2a\" # Replace with your desired availability zone</p> <p>tags = {     Name = \"Public Subnet 1\"   } }</p> <p>resource \"aws_subnet\" \"public_subnet_2\" {   vpc_id     = aws_vpc.main.id   cidr_block = \"10.0.2.0/24\"   availability_zone = \"us-west-2b\" # Replace with your desired availability zone</p> <p>tags = {     Name = \"Public Subnet 2\"   } } This creates two public subnets in different availability zones for high availability.</p> <p>Step 3: Apply the Changes Run the usual OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 4: Verify Your VPC and Subnets You can verify the creation of your VPC and subnets in the AWS console by navigating to the VPC dashboard.</p>"},{"location":"tutorials/creating-an-application-load-balancer-with-opentofu/","title":"Creating an application load balancer with opentofu","text":"<p>Creating an Application Load Balancer (ALB) with OpenTofu In this tutorial, we'll create an Application Load Balancer (ALB) to distribute incoming traffic across multiple EC2 instances.</p> <p>Why ALBs? ALBs provide high availability and scalability for your applications by distributing traffic across multiple targets, such as EC2 instances.</p> <p>Step 1: Define the ALB Create a file named alb.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_lb\" \"example\" {   name               = \"my-load-balancer\"   internal           = false   load_balancer_type = \"application\"   security_groups    = [aws_security_group.allow_ssh.id] # Replace with your security group ID   subnets            = [aws_subnet.public_subnet_1.id, aws_subnet.public_subnet_2.id]</p> <p>tags = {     Name = \"My ALB\"   } } This defines an ALB with specified parameters like name, type, security groups, and subnets.</p> <p>Step 2: Define a Target Group Create a target group for the ALB to route traffic to. Add the following code to alb.tf:</p> <p>Terraform</p> <p>resource \"aws_lb_target_group\" \"example\" {   name     = \"my-targets\"   port     = 80   protocol = \"HTTP\"   vpc_id   = aws_vpc.main.id } This defines a target group named \"my-targets\" that listens on port 80 for HTTP traffic.</p> <p>Step 3: Define a Listener Define a listener for the ALB to listen for incoming traffic on a specific port and protocol. Add the following code to alb.tf:</p> <p>Terraform</p> <p>resource \"aws_lb_listener\" \"example\" {   load_balancer_arn = aws_lb.example.arn   port              = \"80\"   protocol          = \"HTTP\"</p> <p>default_action {     type             = \"forward\"     target_group_arn = aws_lb_target_group.example.arn   } } This defines a listener that listens on port 80 for HTTP traffic and forwards requests to the target group.</p> <p>Step 4: Apply the Changes Run the OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 5: Verify Your ALB You can verify the ALB creation in the AWS console by navigating to the EC2 dashboard and selecting \"Load Balancers.\"</p>"},{"location":"tutorials/creating-an-eks-cluster-with-opentofu/","title":"Creating an eks cluster with opentofu","text":"<p>Orchestrating Containers with OpenTofu: Creating an EKS Cluster In this tutorial, we'll delve into the world of container orchestration by creating an Amazon Elastic Kubernetes Service (EKS) cluster using OpenTofu.</p> <p>Why EKS? EKS is a managed Kubernetes service that makes it easy to run Kubernetes on AWS without needing to install, operate, and maintain your own 1  Kubernetes control plane. This allows you to focus on building and deploying your applications. \u00a0   1.  medium.com medium.com</p> <p>Step 1: Define the EKS Cluster Create a file named eks.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_eks_cluster\" \"example\" {   name     = \"my-eks-cluster\"   role_arn = aws_iam_role.eks_cluster.arn   version = \"1.24\" # Specify your desired Kubernetes version</p> <p>vpc_config {     subnet_ids              = [aws_subnet.public_subnet_1.id, aws_subnet.public_subnet_2.id]      endpoint_public_access = true     public_access_cidrs    = [\"0.0.0.0/0\"]   } }</p> <p>resource \"aws_iam_role\" \"eks_cluster\" {   name = \"eks-cluster-role\"</p> <p>assume_role_policy = &lt;&lt;POLICY {   \"Version\": \"2012-10-17\",   \"Statement\": [     {       \"Effect\": \"Allow\",       \"Principal\": {         \"Service\": \"eks.amazonaws.com\"       },       \"Action\": \"sts:AssumeRole\"     }   ] } POLICY }</p> <p>resource \"aws_iam_role_policy_attachment\" \"eks-cluster-AmazonEKSClusterPolicy\" {   policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\"   role       = aws_iam_role.eks_cluster.name } This code defines an EKS cluster with a specified version and VPC configuration. It also creates an IAM role with the necessary permissions for the EKS cluster.</p> <p>Step 2: Configure kubectl To interact with your EKS cluster, you'll need to configure kubectl, the Kubernetes command-line tool. You can find instructions on how to install and configure kubectl in the Kubernetes documentation.</p> <p>Once kubectl is installed, you'll need to update your kubeconfig with the cluster information. You can use the aws eks update-kubeconfig command for this.</p> <p>Step 3: Apply the Changes Run the OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 4: Verify Your EKS Cluster You can verify the EKS cluster creation in the AWS console by navigating to the EKS dashboard. You can also use kubectl commands to interact with your cluster and verify its status.</p> <p>Congratulations! You've successfully created an EKS cluster using OpenTofu.</p> <p>Next Steps: Deploy a sample application to your EKS cluster. Explore different EKS features, such as node groups and managed node groups. Learn how to use Kubernetes concepts like deployments, services, and pods.</p>"},{"location":"tutorials/creating-an-elastic-ip-with-opentofu/","title":"Creating an elastic ip with opentofu","text":"<p>Allocating a Static IP with OpenTofu: Creating an Elastic IP (EIP) In this tutorial, we'll learn how to create an Elastic IP (EIP) address using OpenTofu. EIPs provide a static public IP that you can associate with your AWS resources.</p> <p>Why EIPs? EIPs offer several benefits for your cloud infrastructure:</p> <p>Static IP Address: EIPs provide a fixed public IP address that you can associate with your instances or other resources, even if their private IP addresses change. Fault Tolerance: If an instance with an associated EIP fails, you can quickly re-associate the EIP with another instance to maintain connectivity. Accessibility: EIPs make it easier to access your resources from the internet, especially if you have dynamic IP addresses or need a consistent address for DNS records. Step 1: Define the EIP Create a file named eip.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_eip\" \"example\" {   vpc = true</p> <p>tags = {     Name = \"My EIP\"   } } This code defines an EIP with the vpc attribute set to true, which means it will be created in your VPC.</p> <p>Step 2: Associate the EIP with Your Instance To associate the EIP with your EC2 instance, add the following code to your main.tf file within the aws_instance resource block:</p> <p>Terraform</p> <p>associate_public_ip_address = false # Prevent AWS from automatically assigning a public IP</p> <p>public_ip = aws_eip.example.public_ip This code first disables the automatic assignment of a public IP address by AWS. Then, it associates the public IP of your EIP with the instance.</p> <p>Step 3: Apply the Changes Open your terminal, navigate to the directory containing your OpenTofu files, and run the following commands:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply OpenTofu will create the EIP and associate it with your EC2 instance.</p> <p>Step 4: Verify Your EIP You can verify the EIP creation and association in the AWS console by navigating to the EC2 dashboard and selecting your instance. The EIP will be displayed in the instance details.</p> <p>Congratulations! You've successfully created an EIP and associated it with your EC2 instance using OpenTofu.</p> <p>Next Steps: Explore other EIP features, such as associating it with a network interface. Learn how to disassociate and release EIPs. Consider using EIPs with other AWS resources, such as NAT Gateways.</p>"},{"location":"tutorials/creating-an-iam-user-role-and-assume-role-functionality-with-opentofu/","title":"Creating an iam user role and assume role functionality with opentofu","text":"<p>Controlling Access with OpenTofu: Creating an IAM User and Role with Assume Role Functionality In this tutorial, we'll dive deeper into Identity and Access Management (IAM) and learn how to create an IAM user and an IAM role with assume role capabilities using OpenTofu. This powerful combination allows you to delegate access to your AWS resources securely and efficiently.</p> <p>Why IAM Users and Roles with Assume Role? IAM users are identities within your AWS account that you create for people or applications. IAM roles, on the other hand, are identities that you can assign to AWS resources or federated users. The \"assume role\" functionality allows an entity (like an IAM user) to temporarily take on the permissions of an IAM role.</p> <p>This is particularly useful for:</p> <p>Delegating permissions: Granting specific access to users or applications without giving them permanent credentials. Enhancing security: Limiting the scope of access and reducing the risk of credential compromise. Enabling cross-account access: Allowing users from one AWS account to access resources in another account. Step 1: Define the IAM User Create a file named iam.tf and add the following code to define an IAM user:</p> <p>Terraform</p> <p>resource \"aws_iam_user\" \"example\" {   name = \"example-user\"</p> <p>tags = {     Name = \"Example IAM User\"   } } This creates an IAM user named \"example-user.\"</p> <p>Step 2: Define the IAM Role Next, define an IAM role that the user can assume. Add the following code to iam.tf:</p> <p>Terraform</p> <p>resource \"aws_iam_role\" \"example\" {   name = \"example-role\"</p> <p>assume_role_policy = &lt;&lt;EOF {   \"Version\": \"2012-10-17\",   \"Statement\": [     {       \"Effect\": \"Allow\",       \"Principal\": {         \"AWS\": \"arn:aws:iam::YOUR_ACCOUNT_ID:user/example-user\"  # Replace with your account ID       },       \"Action\": \"sts:AssumeRole\"     }   ] } EOF } This defines an IAM role named \"example-role.\" The assume_role_policy explicitly allows the \"example-user\" to assume this role.  Make sure to replace YOUR_ACCOUNT_ID with your actual AWS account ID.</p> <p>Step 3: Define an IAM Policy (Optional) You can optionally create an IAM policy to attach to the role, granting specific permissions. For example, to allow the role to read objects from an S3 bucket, add the following code to iam.tf:</p> <p>Terraform</p> <p>resource \"aws_iam_policy\" \"example\" {   name        = \"example-policy\"   description = \"Example IAM Policy\"</p> <p>policy = &lt;&lt;EOF {   \"Version\": \"2012-10-17\",   \"Statement\": [     {       \"Effect\": \"Allow\",       \"Action\": [         \"s3:GetObject\"       ],       \"Resource\": \"arn:aws:s3:::your-s3-bucket/*\"  # Replace with your S3 bucket name     }   ] } EOF }</p> <p>resource \"aws_iam_role_policy_attachment\" \"example\" {   role       = aws_iam_role.example.name   policy_arn = aws_iam_policy.example.arn } This 1  code defines an IAM policy that allows the role to read objects from the specified S3 bucket.  Replace \"your-s3-bucket\" with the name of your S3 bucket. \u00a0   1.  levelup.gitconnected.com levelup.gitconnected.com</p> <p>Step 4: Apply the Changes Run the OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 5: Verify your IAM User and Role You can verify the creation of your IAM user and role in the AWS console by navigating to the IAM dashboard.</p> <p>Congratulations! You've successfully created an IAM user and role with assume role functionality using OpenTofu.</p> <p>Next Steps: Explore different ways to use assume role, such as cross-account access or delegating permissions to applications. Learn how to use the AWS Security Token Service (STS) to generate temporary credentials for assuming roles. Implement least privilege principles by granting only the necessary permissions to your users and roles.</p>"},{"location":"tutorials/launching-a-linux-server-on-aws-with-opentofu/","title":"Your First Steps with IaC: Launching a Linux Server on AWS with OpenTofu","text":"<p>Welcome to the world of Infrastructure as Code (IaC)! In this tutorial, we'll guide you through your first steps with OpenTofu, a powerful tool that allows you to define and manage your cloud infrastructure using code.</p>"},{"location":"tutorials/launching-a-linux-server-on-aws-with-opentofu/#why-opentofu","title":"Why OpenTofu?","text":"<p>OpenTofu offers several advantages for managing your cloud infrastructure:</p> <ul> <li>Automation: No more clicking through endless menus in the AWS console. OpenTofu automates the process of creating and configuring your cloud resources.</li> <li>Consistency: OpenTofu ensures that your infrastructure is always deployed in a consistent and predictable manner, eliminating manual errors and inconsistencies.</li> <li>Version Control: You can track changes to your infrastructure code using version control systems like Git, making it easy to roll back changes or collaborate with others.</li> <li>Reusability: You can create reusable modules that can be used to deploy similar infrastructure components across different projects.</li> </ul>"},{"location":"tutorials/launching-a-linux-server-on-aws-with-opentofu/#prerequisites","title":"Prerequisites","text":"<p>Before we begin, make sure you have the following:</p> <ul> <li> <p>An AWS Account: You'll need an active AWS account to deploy your infrastructure. If you don't have one already, you can create a free tier account by following the instructions on the AWS Account Creation page.</p> </li> <li> <p>AWS Credentials: Once you have an AWS account, you'll need to configure your AWS credentials on your local machine. This allows OpenTofu to interact with your AWS resources. You can find detailed instructions on how to set up your AWS credentials in the AWS Credentials documentation.</p> </li> <li> <p>OpenTofu Installed: OpenTofu is the IaC tool we'll be using to define and manage our infrastructure.1 You can download and install OpenTofu by following the instructions on the OpenTofu Installation page.</p> </li> </ul>"},{"location":"tutorials/launching-a-linux-server-on-aws-with-opentofu/#step-1-define-your-infrastructure","title":"Step 1: Define Your Infrastructure","text":"<p>Let's start by creating a simple OpenTofu configuration file that defines a Linux EC2 instance on AWS. Create a new file named main.tf and add the following code:</p> <pre><code>terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 4.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = \"us-west-2\" # Replace with your desired region\n}\n\nresource \"aws_instance\" \"example\" {\n  ami           = \"ami-0c94855ba95c574c8\" # Replace with a suitable AMI ID for your region\n  instance_type = \"t2.micro\"\n  tags = {\n    Name = \"My First Instance\"\n  }\n}\n</code></pre> <p>Let's break down this code:</p> <ul> <li><code>terraform</code> block: This block specifies the required providers for our configuration. In this case, we're using the <code>aws</code> provider.</li> <li><code>provider \"aws\"</code> block: This block configures the AWS provider with the desired region. Replace <code>\"us-west-2\"</code> with your preferred AWS region.</li> <li><code>resource \"aws_instance\" \"example\"</code> block: This block defines an EC2 instance resource named \"example\".</li> <li><code>ami</code>: This specifies the Amazon Machine Image (AMI) ID to use for the instance. Replace <code>\"ami-0c94855ba95c574c8\"</code> with an appropriate AMI ID for your region. You can find AMI IDs in the AWS console.</li> <li><code>instance_type</code>: This specifies the instance type, which determines the compute and memory capacity of the instance. We're using a <code>t2.micro</code>instance, which is a free tier eligible instance type.</li> <li><code>tags</code>: This allows you to add tags to your instance for easy identification and organization.</li> </ul>"},{"location":"tutorials/launching-a-linux-server-on-aws-with-opentofu/#step-2-initialize-opentofu","title":"Step 2: Initialize OpenTofu","text":"<p>Open your terminal and navigate to the directory where you saved <code>main.tf</code>. Then run the following command:</p> <pre><code>opentofu init\n</code></pre> <p>This command initializes the working directory and downloads the necessary plugins for the AWS provider.</p>"},{"location":"tutorials/launching-a-linux-server-on-aws-with-opentofu/#step-3-plan-your-infrastructure","title":"Step 3: Plan Your Infrastructure","text":"<p>Before applying your configuration, it's a good practice to run a plan to see what changes OpenTofu will make to your infrastructure. Run the following command:</p> <pre><code>opentofu plan\n</code></pre> <p>OpenTofu will analyze your configuration and display a plan of the resources it will create. This allows you to review the changes before they are applied.</p>"},{"location":"tutorials/launching-a-linux-server-on-aws-with-opentofu/#step-4-apply-your-configuration","title":"Step 4: Apply Your Configuration","text":"<p>If you're happy with the plan, you can apply your configuration and create the EC2 instance. Run the following command:</p> <pre><code>opentofu apply\n</code></pre> <p>OpenTofu will prompt you to confirm the changes. Type <code>yes</code> and press Enter to proceed.</p> <p>OpenTofu will now create the EC2 instance in your AWS account. You can monitor the progress in your terminal.</p>"},{"location":"tutorials/launching-a-linux-server-on-aws-with-opentofu/#step-5-verify-your-instance","title":"Step 5: Verify Your Instance","text":"<p>Once the apply process is complete, you can verify that your instance has been created by logging into the AWS console and navigating to the EC2 dashboard. You should see your newly created instance with the name \"My First Instance\".</p> <p>Congratulations! You've successfully launched your first Linux server on AWS using OpenTofu.</p> <p>Next Steps:</p> <ul> <li>Try modifying your configuration to change the instance type, AMI, or tags.</li> <li>Explore other OpenTofu resources, such as security groups, volumes, and networks.</li> <li>Learn how to destroy your infrastructure using <code>opentofu destroy</code>.</li> </ul>"},{"location":"tutorials/level-up-our-opentofu-code-with-structure-and-reusability/","title":"Level up our opentofu code with structure and reusability","text":"<p>Introducing Terraspace: Level Up Your OpenTofu Code with Structure and Reusability While OpenTofu provides a solid foundation for IaC, managing complex infrastructure can become challenging as your projects grow. That's where Terraspace comes in. It's a powerful framework that enhances OpenTofu with improved structure, modularity, and reusability.</p> <p>Why Terraspace? Terraspace brings order to your OpenTofu code by organizing it into modules and stacks, making it easier to manage, maintain, and scale your infrastructure. Think of it as a blueprint for your IaC, providing a clear structure and promoting best practices.</p> <p>Here's how Terraspace benefits your IaC workflow:</p> <p>Modularity: Break down your infrastructure into reusable modules, promoting code organization and reducing duplication. Structure: Terraspace provides a clear and consistent project structure, making it easy to navigate and understand your code. Reusability: Create modules that can be shared across different projects, saving time and effort. Simplified workflows: Terraspace offers helpful commands and features that streamline your IaC operations. Step 1: Install Terraspace If you haven't already, install Terraspace on your local machine. You can find detailed instructions on the Terraspace Installation page.</p> <p>Step 2: Create a Terraspace Project Initialize a new Terraspace project using the following command:</p> <p>Bash</p> <p>terraspace new project my-infra This will create a new directory named my-infra with the basic Terraspace project structure.</p> <p>Step 3: Define a Module Let's create a simple module to provision our EC2 instance. Navigate to the modules directory within your project and create a new directory named instance. Inside the instance directory, create a file named main.tf with the following code:</p> <p>Terraform</p> <p>resource \"aws_instance\" \"example\" {   ami                    = \"ami-0c94855ba95c574c8\" # Replace with a suitable AMI ID   instance_type          = \"t2.micro\"   vpc_security_group_ids = [aws_security_group.allow_ssh.id] # Assuming you have a security group defined</p> <p>tags = {     Name = \"My Terraspace Instance\"   } } Step 4: Create a Stack Now, let's create a stack to deploy our module. Navigate to the stacks directory and create a new directory named dev. Inside the dev directory, create a file named main.tf with the following code:</p> <p>Terraform</p> <p>module \"instance\" {   source = \"../../modules/instance\" } This code references the instance module we created earlier.</p> <p>Step 5: Deploy the Stack Open your terminal, navigate to the stacks/dev directory, and run the following commands:</p> <p>Bash</p> <p>terraspace up dev  Terraspace will use OpenTofu to provision the EC2 instance based on the configuration defined in your module and stack.</p> <p>Step 6: Verify Your Instance You can verify the instance creation in the AWS console, just like in the previous tutorials.</p> <p>Congratulations! You've successfully deployed your first infrastructure with Terraspace.</p> <p>Next Steps: Explore Terraspace features like variables, environments, and layouts. Create more complex modules and stacks to manage different parts of your infrastructure. Learn how to use Terraspace to deploy to multiple cloud providers.</p>"},{"location":"tutorials/obtaining-an-acm-ssl-certificate-with-opentofu/","title":"Obtaining an acm ssl certificate with opentofu","text":"<p>Securing Your Domain: Obtaining an ACM SSL Certificate with OpenTofu In this tutorial, we'll secure your domain with an SSL certificate using AWS Certificate Manager (ACM).</p> <p>Why ACM? ACM makes it easy to provision, manage, and deploy SSL certificates for your websites and applications. It integrates seamlessly with other AWS services like Application Load Balancers.</p> <p>Step 1: Request a Certificate Create a file named acm.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_acm_certificate\" \"example\" {   domain_name       = \"example.com\" # Replace with your domain name   validation_method = \"DNS\"</p> <p>tags = {     Name = \"My SSL Certificate\"   } }</p> <p>resource \"aws_acm_certificate_validation\" \"example\" {   certificate_arn         = aws_acm_certificate.example.arn   validation_record_fqdns = [aws_route53_record.root.fqdn] }</p> <p>resource \"aws_route53_record\" \"cert_validation\" {   for_each = {     for dvo in aws_acm_certificate.example.domain_validation_options : dvo.domain_name =&gt; {       name   = dvo.resource_record_name       record = dvo.resource_record_value       type   = dvo.resource_record_type     }   }</p> <p>allow_overwrite = true   name            = each.value.name   records         = [each.value.record]   ttl             = 60   type            = each.value.type   zone_id         = aws_route53_zone.main.zone_id } This code requests an SSL certificate for your domain and automatically creates the necessary DNS validation records in Route 53.</p> <p>Step 2: Apply the Changes Run the OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 3: Verify Your Certificate You can verify the certificate issuance in the AWS console by navigating to the ACM dashboard.</p>"},{"location":"tutorials/provisioning-an-ebs-volume-and-attaching-it-to-your-ec2-instance-with-opentofu/","title":"Provisioning an ebs volume and attaching it to your ec2 instance with opentofu","text":"<p>Provisioning an EBS Volume and Attaching it to Your EC2 Instance with OpenTofu In the previous tutorials, you launched a Linux server and secured it with a security group. Now, let's expand your infrastructure by provisioning an Elastic Block Store (EBS) volume and attaching it to your EC2 instance.</p> <p>Why EBS Volumes? EBS volumes provide persistent block storage for your EC2 instances. Think of them as external hard drives that you can attach to your server. This allows you to:</p> <p>Increase storage capacity: Add more storage to your instance as needed. Improve performance: Choose different EBS volume types optimized for various workloads. Enhance data durability: EBS volumes are designed for high availability and durability, protecting your data from loss. Backup and restore data: Easily create snapshots of your EBS volumes for backups and disaster recovery. Step 1: Define the EBS Volume Create a new file named volume.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_ebs_volume\" \"example\" {   availability_zone = \"us-west-2a\" # Replace with your instance's availability zone   size              = 10           # Size in gigabytes   type              = \"gp2\"        # General purpose SSD volume type</p> <p>tags = {     Name = \"My EBS Volume\"   } } Let's break down this code:</p> <p>resource \"aws_ebs_volume\" \"example\" block: This defines an EBS volume resource named \"example\". availability_zone: Specifies the availability zone where the volume will be created. This should match the availability zone of your EC2 instance. size: Specifies the size of the volume in gigabytes. type: Specifies the volume type. We're using \"gp2\", which is a general purpose SSD volume. tags: Adds tags to the volume for identification. Step 2: Attach the EBS Volume to Your Instance Now, let's create another file named attach_volume.tf to attach the EBS volume to your EC2 instance. Add the following code:</p> <p>Terraform</p> <p>resource \"aws_volume_attachment\" \"example\" {   device_name = \"/dev/sdf\"       # Device name to attach the volume to   volume_id   = aws_ebs_volume.example.id   instance_id = aws_instance.example.id } resource \"aws_volume_attachment\" \"example\" block: This defines a volume attachment resource. device_name: Specifies the device name to attach the volume to on the instance. volume_id: References the ID of the EBS volume we created in volume.tf. instance_id: References the ID of the EC2 instance from main.tf. Step 3: Apply the Changes Open your terminal, navigate to the directory containing your OpenTofu files, and run the following commands:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply OpenTofu will create the EBS volume and attach it to your EC2 instance.</p> <p>Step 4: Verify the Volume Attachment You can verify the volume attachment in the AWS console by navigating to the EC2 dashboard, selecting your instance, and then checking the \"Storage\" tab. You should see your newly attached EBS volume.</p> <p>You'll likely need to SSH into your instance and format the volume before you can use it.  (You can find instructions for formatting volumes in the AWS documentation.)</p> <p>Congratulations! You've successfully provisioned an EBS volume and attached it to your EC2 instance using OpenTofu.</p> <p>Next Steps: Explore different EBS volume types and their performance characteristics. Learn how to create snapshots of your EBS volumes for backups. Experiment with resizing your EBS volumes.</p>"},{"location":"tutorials/setting-up-a-web-application-firewall-with-opentofu/","title":"Setting up a web application firewall with opentofu","text":"<p>Protecting Your Applications with OpenTofu: Setting Up a Web Application Firewall (WAF) In this tutorial, we'll enhance your application's security by creating a Web Application Firewall (WAF) using OpenTofu.</p> <p>Why WAF? WAF helps protect your web applications from common web exploits like SQL injection, cross-site scripting (XSS), and malicious bots. It acts as a shield, filtering out harmful traffic before it reaches your application.</p> <p>Step 1: Define the Web ACL Create a file named waf.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_wafv2_web_acl\" \"example\" {   name        = \"my-waf\"   description = \"My WAF\"   scope        = \"REGIONAL\"</p> <p>default_action {     allow {}   }</p> <p>visibility_config {     cloudwatch_metrics_enabled = true     metric_name                = \"my-waf-metrics\"     sampled_requests_enabled   = true   } } This defines a regional web access control list (web ACL) with a default allow action and logging enabled.</p> <p>Step 2: Define a Rule Group Create a rule group to define specific security rules. Add the following code to waf.tf:</p> <p>Terraform</p> <p>resource \"aws_wafv2_rule_group\" \"example\" {   name        = \"my-rule-group\"   description = \"My Rule Group\"   scope        = \"REGIONAL\"   capacity     = 10</p> <p>rule {     name     = \"AWSManagedRulesCommonRuleSet\"     priority = 1     statement {       managed_rule_group_statement {         vendor_name = \"AWS\"         name        = \"AWSManagedRulesCommonRuleSet\"       }     }     visibility_config {       cloudwatch_metrics_enabled = true       metric_name                = \"AWSManagedRulesCommonRuleSet\"       sampled_requests_enabled   = true     }   }</p> <p>visibility_config {     cloudwatch_metrics_enabled = true     metric_name                = \"my-rule-group-metrics\"     sampled_requests_enabled   = true   } } This defines a rule group with a capacity of 10 and includes the AWSManagedRulesCommonRuleSet, a pre-configured set of rules for common web exploits.</p> <p>Step 3: Associate the Web ACL with Your ALB Associate the web ACL with your Application Load Balancer. Add the following code to waf.tf:</p> <p>Terraform</p> <p>resource \"aws_wafv2_web_acl_association\" \"example\" {   resource_arn = aws_lb.example.arn # Replace with your ALB ARN   web_acl_arn  = aws_wafv2_web_acl.example.arn } This associates the web ACL with your ALB, enabling WAF protection for your application.</p> <p>Step 4: Apply the Changes Run the OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 5: Verify Your WAF You can verify the WAF configuration in the AWS console by navigating to the WAF dashboard.</p>"},{"location":"tutorials/setting-up-cloudfront-with-opentofu/","title":"Setting up cloudfront with opentofu","text":"<p>Distributing Content Globally with OpenTofu: Setting Up CloudFront In today's interconnected world, delivering content quickly and efficiently to users across the globe is paramount. That's where CloudFront comes in. This tutorial will guide you through setting up a CloudFront distribution using OpenTofu.</p> <p>Why CloudFront? CloudFront is Amazon's content delivery network (CDN). It caches your content at edge locations around the world, ensuring fast delivery and low latency for your users, regardless of their location.</p> <p>Step 1: Define the CloudFront Distribution Create a file named cloudfront.tf and add the following code:</p> <p>Terraform</p> <p>resource \"aws_cloudfront_distribution\" \"example\" {   origin {     domain_name = aws_lb.example.dns_name # Replace with your ALB's DNS name     origin_id   = \"myS3Origin\"   }</p> <p>enabled             = true   is_ipv6_enabled     = true   comment             = \"My CloudFront Distribution\"   default_root_object = \"index.html\"</p> <p>aliases = [\"example.com\"] # Replace with your domain name</p> <p>default_cache_behavior {     allowed_methods  = [\"GET\", \"HEAD\"]     cached_methods   = [\"GET\", \"HEAD\"]     target_origin_id = \"myS3Origin\"</p> <pre><code>forwarded_values {\n  query_string = false\n  cookies {\n    forward = \"none\"\n  }\n}\n\nviewer_protocol_policy = \"redirect-to-https\"\nmin_ttl                = 0\ndefault_ttl            = 3600\nmax_ttl                = 86400\n</code></pre> <p>}</p> <p>price_class = \"PriceClass_All\"</p> <p>restrictions {     geo_restriction {       restriction_type = \"none\"     }   }</p> <p>viewer_certificate {     acm_certificate_arn = aws_acm_certificate.example.arn # Replace with your ACM certificate ARN     ssl_support_method = \"sni-only\"   } } This code defines a CloudFront distribution with your ALB as the origin. It configures caching behavior, redirects HTTP to HTTPS, and uses your ACM certificate for SSL.</p> <p>Step 2: Apply the Changes Run the OpenTofu commands to apply your changes:</p> <p>Bash</p> <p>opentofu init opentofu plan opentofu apply Step 3: Verify Your Distribution You can verify the CloudFront distribution creation in the AWS console by navigating to the CloudFront dashboard.</p>"},{"location":"projects/category/iac/","title":"IaC","text":""},{"location":"projects/category/linux-/","title":"Linux \ud83c\udf36\ufe0f","text":""},{"location":"projects/category/api-gateways/","title":"API Gateways","text":""},{"location":"projects/category/cloudfront/","title":"CloudFront","text":""},{"location":"projects/category/devsecops/","title":"DevSecOps","text":""},{"location":"projects/category/cloud-networking/","title":"Cloud Networking","text":""},{"location":"projects/category/containerization/","title":"Containerization","text":""},{"location":"projects/category/cicd/","title":"CI/CD","text":""},{"location":"projects/category/orchestration/","title":"Orchestration","text":""},{"location":"projects/category/gitops/","title":"GitOps","text":""},{"location":"projects/category/data--analytics/","title":"Data &amp; Analytics","text":""},{"location":"projects/category/devex/","title":"DevEx","text":""},{"location":"projects/category/terraspace/","title":"Terraspace","text":""},{"location":"projects/page/2/","title":"Projects","text":""}]}